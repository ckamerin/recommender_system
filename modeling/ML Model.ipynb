{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF2.0 Recommender System.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "2.3.0\n"
        }
      ],
      "source": [
        "#Install TensorFlow\n",
        "!pip install -q tensorflow\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmO5csZi7cdr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# More imports\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, Flatten, \\\n",
        "  Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6h0pEt_7lZC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4a410b48-1608-4ea0-b7d5-5bcf12ea065a"
      },
      "source": [
        "df = pd.read_csv('/Users/chriskamerin/Desktop/Shopping_Recommender_System/headphones5.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "df1 = pd.read_csv('/Users/chriskamerin/Desktop/Shopping_Recommender_System/headphones2hp.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "df2 = pd.read_csv('/Users/chriskamerin/Desktop/Shopping_Recommender_System/df2.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "df1 = df1.sample(frac=1).reset_index(drop=True)\n",
        "df2 = df2.sample(frac=1).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbcWAxwa-ZBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We can't trust the userId and movieId to be numbered 0...N-1\n",
        "# Let's just set our own ids\n",
        "\n",
        "# current_user_id = 0\n",
        "# custom_user_map = {} # old user id > new user id\n",
        "# def map_user_id(row):\n",
        "#   global current_user_id, custom_user_map\n",
        "#   old_user_id = row['userId']\n",
        "#   if old_user_id not in custom_user_map:\n",
        "#     custom_user_map[old_user_id] = current_user_id\n",
        "#     current_user_id += 1\n",
        "#   return custom_user_map[old_user_id]\n",
        "\n",
        "# df['new_user_id'] = df.apply(map_user_id, axis=1)\n",
        "\n",
        "df['user_id']  = pd.Categorical(df.user_id).codes\n",
        "df1['user_id']  = pd.Categorical(df1.user_id).codes\n",
        "df2['user_id']  = pd.Categorical(df2.user_id).codes\n",
        "# "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqeRbNRN_g7h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now do the same thing for movie ids\n",
        "# current_movie_id = 0\n",
        "# custom_movie_map = {} # old movie id > new movie id\n",
        "# def map_movie_id(row):\n",
        "#   global current_movie_id, custom_movie_map\n",
        "#   old_movie_id = row['movieId']\n",
        "#   if old_movie_id not in custom_movie_map:\n",
        "#     custom_movie_map[old_movie_id] = current_movie_id\n",
        "#     current_movie_id += 1\n",
        "#   return custom_movie_map[old_movie_id]\n",
        "\n",
        "# df['new_movie_id'] = df.apply(map_movie_id, axis=1)\n",
        "\n",
        "df['headphone_name']  = pd.Categorical(df.headphone_name).codes\n",
        "df1['headphone_name']  = pd.Categorical(df1.headphone_name).codes\n",
        "df2['headphone_name']  = pd.Categorical(df2.headphone_name).codes\n",
        "# "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "cols_to_norm = ['sound_quality_importance', 'positional_importance', 'loud_importance',\n",
        "       'mic_importance', 'wireless_importance','noise_canceling_importance', 'in_ear_importance',\n",
        "       'on_ear_importance', 'over_ear_importance', 'no_pref_oninover', 'recording_quality', 'noise_handling','user_rating',\n",
        "       'Impedance', 'sensitivity(dbv)', 'accuracy',\n",
        "       'weighted_harmonic_distortion', 'soundstage', 'imaging',\n",
        "       'noise_isolation', 'wireless']\n",
        "imp_col = ['sound_quality_importance', 'positional_importance', 'loud_importance',\n",
        "       'mic_importance', 'wireless_importance', \n",
        "       'price_sensitivity']\n",
        "#price_col = ['max_price','price']\n",
        "hp_feat_col = ['recording_quality', 'noise_handling', 'accuracy',\n",
        "       'weighted_harmonic_distortion', 'soundstage', 'imaging',\n",
        "       'noise_isolation', 'wireless']\n",
        "remaining_col = ['Impedance', 'sensitivity(dbv)']\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "feat col min:0.0 feat col max:10.0 rem col min:0 rem col max:300\n"
        }
      ],
      "source": [
        "print('feat col min:' + str(min(df[hp_feat_col].min())),'feat col max:'+ str(max(df[hp_feat_col].max())),\n",
        "'rem col min:'+ str(min(df[remaining_col].min())),'rem col max:'+str(max(df[remaining_col].max())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "df=df.fillna(0)\n",
        "df[imp_col] = df[imp_col].apply(lambda x: (x - 0) / (10 - 0))\n",
        "#df[price_col] = df[price_col].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
        "df[hp_feat_col] = df[hp_feat_col].apply(lambda x: (x - x.min()) / (x.max() - x.min()))   \n",
        "df[remaining_col] = df[remaining_col].apply(lambda x: (x - x.min()) / (x.max() - x.min()))       \n",
        "#df[cols_to_norm] = df[cols_to_norm].apply(lambda x: (x - x.min()) / (x.max() - x.min()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "cols_to_norm = ['sound_quality_importance', 'positional_importance', 'loud_importance',\n",
        "       'mic_importance', 'wireless_importance', \n",
        "        'recording_quality', 'noise_handling','user_rating',\n",
        "       'Impedance', 'sensitivity(dbv)', 'accuracy',\n",
        "       'weighted_harmonic_distortion', 'soundstage', 'imaging',\n",
        "       'noise_isolation', 'wireless']\n",
        "imp_col = ['sound_quality_importance', 'positional_importance', 'loud_importance',\n",
        "       'mic_importance', 'wireless_importance', \n",
        "       'price_sensitivity']\n",
        "#price_col = ['max_price','price']\n",
        "hp_feat_col = ['recording_quality', 'noise_handling', 'accuracy',\n",
        "       'weighted_harmonic_distortion', 'soundstage', 'imaging',\n",
        "       'noise_isolation', 'wireless']\n",
        "remaining_col = ['Impedance', 'sensitivity(dbv)']\n",
        "\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "feat col min:0.0 feat col max:9.2 rem col min:0 rem col max:300\n"
        }
      ],
      "source": [
        "print('feat col min:' + str(min(df1[hp_feat_col].min())),'feat col max:'+ str(max(df1[hp_feat_col].max())),\n",
        "'rem col min:'+ str(min(df1[remaining_col].min())),'rem col max:'+str(max(df1[remaining_col].max())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "df1=df1.fillna(0)\n",
        "df1[imp_col] = df1[imp_col].apply(lambda x: (x - 0) / (10 - 0))\n",
        "#df1[price_col] = df1[price_col].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
        "df1[hp_feat_col] = df1[hp_feat_col].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
        "df1[remaining_col] = df1[remaining_col].apply(lambda x: (x - x.min()) / (x.max() - x.min())) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "cols_to_norm = ['sound_quality_importance', 'positional_importance', 'loud_importance',\n",
        "       'mic_importance', 'wireless_importance', \n",
        "        'recording_quality', 'noise_handling','user_rating',\n",
        "       'Impedance', 'sensitivity(dbv)', 'accuracy',\n",
        "       'weighted_harmonic_distortion', 'soundstage', 'imaging',\n",
        "       'noise_isolation', 'wireless']\n",
        "imp_col = ['sound_quality_importance', 'positional_importance', 'loud_importance',\n",
        "       'mic_importance', 'wireless_importance', \n",
        "       'price_sensitivity']\n",
        "#price_col = ['max_price','price']\n",
        "hp_feat_col = ['recording_quality', 'noise_handling', 'accuracy',\n",
        "       'weighted_harmonic_distortion', 'soundstage', 'imaging',\n",
        "       'noise_isolation', 'wireless']\n",
        "remaining_col = ['Impedance', 'sensitivity(dbv)']\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "feat col min:0.0 feat col max:0.9999972902885731 rem col min:10.0 rem col max:300.0\n"
        }
      ],
      "source": [
        "print('feat col min:' + str(min(df2[hp_feat_col].min())),'feat col max:'+ str(max(df2[hp_feat_col].max())),\n",
        "'rem col min:'+ str(min(df2[remaining_col].min())),'rem col max:'+str(max(df2[remaining_col].max())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "df2=df2.fillna(0)\n",
        "df2[imp_col] = df2[imp_col].apply(lambda x: (x - 0) / (10 - 0))\n",
        "#df2[price_col] = df2[price_col].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
        "df2[hp_feat_col] = df2[hp_feat_col].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
        "df2[remaining_col] = df2[remaining_col].apply(lambda x: (x - x.min()) / (x.max() - x.min()))  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "X=df[['game_use', 'rec_use', 'studio_use', 'exercise_use',\n",
        "       'office_use', 'podcast_use', 'travel_use', 'other_use',\n",
        "       'sound_quality_importance', 'positional_importance', 'loud_importance',\n",
        "       'mic_importance', 'wireless_importance', 'in_ear_importance',\n",
        "       'on_ear_importance', 'over_ear_importance', 'no_pref_oninover']][:70]\n",
        "Y=df[[ 'attached_mic', 'recording_quality',\n",
        "       'noise_handling', 'Impedance', 'sensitivity(dbv)', 'accuracy',\n",
        "       'weighted_harmonic_distortion', 'soundstage', 'imaging',\n",
        "       'noise_isolation', 'wireless', 'over_ear_style', 'on_ear_style',\n",
        "       'in_ear_style', 'open_back', 'close_back', 'semiclosed_back']][:70]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "x=df1[['game_use', 'rec_use', 'studio_use', 'exercise_use',\n",
        "       'office_use', 'podcast_use', 'travel_use', 'other_use',\n",
        "       'sound_quality_importance', 'positional_importance', 'loud_importance',\n",
        "       'mic_importance', 'wireless_importance', 'in_ear_importance',\n",
        "       'on_ear_importance', 'over_ear_importance', 'no_pref_oninover']]\n",
        "y=df1[[ 'attached_mic', 'recording_quality',\n",
        "       'noise_handling', 'Impedance', 'sensitivity(dbv)', 'accuracy',\n",
        "       'weighted_harmonic_distortion', 'soundstage', 'imaging',\n",
        "       'noise_isolation', 'wireless', 'over_ear_style', 'on_ear_style',\n",
        "       'in_ear_style', 'open_back', 'close_back', 'semiclosed_back']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "randx=df2[['game_use', 'rec_use', 'studio_use', 'exercise_use',\n",
        "       'office_use', 'podcast_use', 'travel_use', 'other_use',\n",
        "       'sound_quality_importance', 'positional_importance', 'loud_importance',\n",
        "       'mic_importance', 'wireless_importance', 'in_ear_importance',\n",
        "       'on_ear_importance', 'over_ear_importance', 'no_pref_oninover']][:8000]\n",
        "randy=df2[[ 'attached_mic', 'recording_quality',\n",
        "       'noise_handling', 'Impedance', 'sensitivity(dbv)', 'accuracy',\n",
        "       'weighted_harmonic_distortion', 'soundstage', 'imaging',\n",
        "       'noise_isolation', 'wireless', 'over_ear_style', 'on_ear_style',\n",
        "       'in_ear_style', 'open_back', 'close_back', 'semiclosed_back']][:8000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "lreg = LinearRegression()\n",
        "lreg1 = LinearRegression()\n",
        "lreg2 = LinearRegression()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "lreg.fit(X,Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "lreg1.fit(x,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "lreg2.fit(randx,randy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "xpred = df[['game_use', 'rec_use', 'studio_use', 'exercise_use',\n",
        "       'office_use', 'podcast_use', 'travel_use', 'other_use',\n",
        "       'sound_quality_importance', 'positional_importance', 'loud_importance',\n",
        "       'mic_importance', 'wireless_importance', 'in_ear_importance',\n",
        "       'on_ear_importance', 'over_ear_importance', 'no_pref_oninover']][70:]\n",
        "ypred = df[[ 'attached_mic', 'recording_quality',\n",
        "       'noise_handling', 'Impedance', 'sensitivity(dbv)', 'accuracy',\n",
        "       'weighted_harmonic_distortion', 'soundstage', 'imaging',\n",
        "       'noise_isolation', 'wireless', 'over_ear_style', 'on_ear_style',\n",
        "       'in_ear_style', 'open_back', 'close_back', 'semiclosed_back']][70:]\n",
        "\n",
        "randxpred = df2[['game_use', 'rec_use', 'studio_use', 'exercise_use',\n",
        "       'office_use', 'podcast_use', 'travel_use', 'other_use',\n",
        "       'sound_quality_importance', 'positional_importance', 'loud_importance',\n",
        "       'mic_importance', 'wireless_importance', 'in_ear_importance',\n",
        "       'on_ear_importance', 'over_ear_importance', 'no_pref_oninover']][80:]\n",
        "randypred = df2[[ 'attached_mic', 'recording_quality',\n",
        "       'noise_handling', 'Impedance', 'sensitivity(dbv)', 'accuracy',\n",
        "       'weighted_harmonic_distortion', 'soundstage', 'imaging',\n",
        "       'noise_isolation', 'wireless', 'over_ear_style', 'on_ear_style',\n",
        "       'in_ear_style', 'open_back', 'close_back', 'semiclosed_back']][80:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "ypred = ypred.reset_index()\n",
        "ypred = ypred.drop(\"index\",axis=1)\n",
        "#ypred = ypred.drop(\"level_0\",axis=1)\n",
        "\n",
        "randypred = randypred.reset_index()\n",
        "randypred = randypred.drop(\"index\",axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred_df = pd.DataFrame(data = lreg.predict(xpred),columns=[ 'attached_mic', 'recording_quality',\n",
        "       'noise_handling', 'Impedance', 'sensitivity(dbv)', 'accuracy',\n",
        "       'weighted_harmonic_distortion', 'soundstage', 'imaging',\n",
        "       'noise_isolation', 'wireless', 'over_ear_style', 'on_ear_style',\n",
        "       'in_ear_style', 'open_back', 'close_back', 'semiclosed_back'])\n",
        "pred_df1 = pd.DataFrame(data = lreg1.predict(xpred),columns=[ 'attached_mic', 'recording_quality',\n",
        "       'noise_handling', 'Impedance', 'sensitivity(dbv)', 'accuracy',\n",
        "       'weighted_harmonic_distortion', 'soundstage', 'imaging',\n",
        "       'noise_isolation', 'wireless', 'over_ear_style', 'on_ear_style',\n",
        "       'in_ear_style', 'open_back', 'close_back', 'semiclosed_back'])\n",
        "pred_df2 = pd.DataFrame(data = lreg2.predict(randxpred),columns=[ 'attached_mic', 'recording_quality',\n",
        "       'noise_handling', 'Impedance', 'sensitivity(dbv)', 'accuracy',\n",
        "       'weighted_harmonic_distortion', 'soundstage', 'imaging',\n",
        "       'noise_isolation', 'wireless', 'over_ear_style', 'on_ear_style',\n",
        "       'in_ear_style', 'open_back', 'close_back', 'semiclosed_back'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "mse = np.mean((pred_df - ypred)**2)\n",
        "mse1 = np.mean((pred_df1 - ypred)**2)\n",
        "mse2 = np.mean((pred_df2 - randypred)**2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "(attached_mic                    2.986673e-32\n recording_quality               4.675389e-02\n noise_handling                  4.307722e-02\n Impedance                       2.253106e-02\n sensitivity(dbv)                8.009823e-02\n accuracy                        6.303296e-02\n weighted_harmonic_distortion    6.219930e-02\n soundstage                      2.372190e-02\n imaging                         5.197113e-02\n noise_isolation                 1.546315e-01\n wireless                        5.861593e-02\n over_ear_style                  5.925938e-32\n on_ear_style                    0.000000e+00\n in_ear_style                    1.255345e-31\n open_back                       2.361192e-01\n close_back                      2.375394e-01\n semiclosed_back                 1.719079e-01\n dtype: float64, attached_mic                    0.250000\n recording_quality               0.154690\n noise_handling                  0.141808\n Impedance                       0.099650\n sensitivity(dbv)                0.085569\n accuracy                        0.092107\n weighted_harmonic_distortion    0.088666\n soundstage                      0.078271\n imaging                         0.119483\n noise_isolation                 0.130165\n wireless                        0.121617\n over_ear_style                  0.120192\n on_ear_style                    0.000000\n in_ear_style                    0.120192\n open_back                       0.235577\n close_back                      0.139423\n semiclosed_back                 0.192308\n dtype: float64, attached_mic                    0.160623\n recording_quality               0.074342\n noise_handling                  0.083834\n Impedance                       0.039626\n sensitivity(dbv)                0.083152\n accuracy                        0.083896\n weighted_harmonic_distortion    0.083101\n soundstage                      0.083347\n imaging                         0.082030\n noise_isolation                 0.082428\n wireless                        0.108642\n over_ear_style                  0.249560\n on_ear_style                    0.110481\n in_ear_style                    0.184283\n open_back                       0.127240\n close_back                      0.211256\n semiclosed_back                 0.071133\n dtype: float64)"
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "mse,mse1,mse2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "        game_use       rec_use    studio_use  exercise_use    office_use  \\\n0   2.730136e-01  8.613030e-04 -7.269864e-01 -9.650494e-02 -1.410461e-01   \n1   3.031348e+13 -1.438265e+11  3.031348e+13  3.129573e+13  3.873352e+13   \n2  -1.324480e+13  6.284177e+10 -1.324480e+13 -1.367397e+13 -1.692375e+13   \n3   1.486074e+12 -7.050882e+09  1.486074e+12  1.534227e+12  1.898854e+12   \n4  -4.230820e+13  2.007371e+11 -4.230820e+13 -4.367911e+13 -5.405996e+13   \n5   2.537613e+13 -1.204006e+11  2.537613e+13  2.619840e+13  3.242475e+13   \n6   2.975078e+13 -1.411567e+11  2.975078e+13  3.071479e+13  3.801452e+13   \n7   5.219331e+12 -2.476384e+10  5.219331e+12  5.388454e+12  6.669082e+12   \n8   5.831069e+12 -2.766632e+10  5.831069e+12  6.020014e+12  7.450740e+12   \n9  -6.122808e+13  2.905051e+11 -6.122808e+13 -6.321206e+13 -7.823514e+13   \n10 -2.852125e+12  1.353230e+10 -2.852125e+12 -2.944543e+12 -3.644347e+12   \n11  2.684532e-02  3.039594e-04  2.684532e-02 -2.479578e-01 -2.636767e-01   \n12  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n13  2.915814e-02 -5.696756e-04  2.915814e-02  3.057760e-01  3.352360e-01   \n14  2.879763e+13 -1.366343e+11  2.879763e+13  2.973076e+13  3.679662e+13   \n15 -4.551649e+13  2.159593e+11 -4.551649e+13 -4.699136e+13 -5.815941e+13   \n16  1.671886e+13 -7.932496e+10  1.671886e+13  1.726061e+13  2.136279e+13   \n\n     podcast_use    travel_use     other_use  sound_quality_importance  \\\n0   0.000000e+00 -9.838853e-02 -6.698252e-03              2.046974e-16   \n1   3.417969e-02  3.161026e+13  1.118522e+12              4.553223e-01   \n2  -2.001953e-02 -1.381140e+13 -4.887131e+11              1.706543e-01   \n3   5.401611e-01  1.549647e+12  5.483388e+10              6.942749e-03   \n4   3.417969e-02 -4.411810e+13 -1.561109e+12             -4.150391e-01   \n5  -4.687500e-02  2.646170e+13  9.363411e+11              5.065918e-01   \n6  -4.101562e-02  3.102349e+13  1.097759e+12              1.191406e-01   \n7  -4.870605e-02  5.442610e+12  1.925855e+11              9.387207e-02   \n8   1.452637e-01  6.080518e+12  2.151577e+11              3.671265e-02   \n9   1.699219e-01 -6.384737e+13 -2.259224e+12             -5.268555e-01   \n10  1.025391e-02 -2.974136e+12 -1.052391e+11             -5.439758e-02   \n11 -1.665335e-16 -2.486225e-01 -2.363857e-03             -6.938894e-17   \n12  0.000000e+00  0.000000e+00  0.000000e+00              0.000000e+00   \n13  6.938894e-17  3.070218e-01  4.430300e-03              3.816392e-17   \n14  5.693359e-01  3.002957e+13  1.062589e+12              4.782715e-01   \n15 -3.183594e-01 -4.746365e+13 -1.679490e+12             -7.834473e-01   \n16 -2.661133e-01  1.743408e+13  6.169009e+11              3.082275e-01   \n\n    positional_importance  loud_importance  mic_importance  \\\n0           -4.857226e-16    -2.081668e-16    1.179612e-16   \n1            1.367188e-02    -1.708984e-03   -3.125000e-02   \n2            6.005859e-02     1.562500e-02    2.099609e-02   \n3           -1.368408e-01     2.402496e-02   -1.222229e-01   \n4            1.230469e-01     1.052246e-01    2.343750e-02   \n5            1.142578e-01    -1.179199e-01    8.789062e-02   \n6            5.273438e-02    -1.010742e-01    6.542969e-02   \n7           -7.397461e-02    -1.357422e-01    2.783203e-02   \n8           -8.764648e-02    -2.137146e-01    5.078125e-02   \n9            2.500000e-01    -8.740234e-02    2.539062e-02   \n10           4.516602e-03     1.448822e-01   -1.580811e-02   \n11           1.110223e-16     6.591949e-17    5.551115e-17   \n12           0.000000e+00     0.000000e+00    0.000000e+00   \n13          -4.163336e-17    -3.816392e-17   -2.775558e-17   \n14          -1.308594e-01     8.251953e-02   -4.492188e-02   \n15          -1.132812e-01     5.102539e-02    1.953125e-03   \n16           2.343750e-01    -1.329346e-01    4.345703e-02   \n\n    wireless_importance  in_ear_importance  on_ear_importance  \\\n0         -4.579670e-16       2.947987e-01                0.0   \n1          9.472656e-02      -3.404693e+13                0.0   \n2          3.955078e-02       1.487605e+13                0.0   \n3         -2.081299e-02      -1.669101e+12                0.0   \n4          1.152344e-01       4.751894e+13                0.0   \n5          2.246094e-02      -2.850150e+13                0.0   \n6          5.957031e-02      -3.341493e+13                0.0   \n7          9.643555e-02      -5.862152e+12                0.0   \n8          2.685547e-02      -6.549233e+12                0.0   \n9         -2.519531e-01       6.876902e+13                0.0   \n10        -5.090332e-02       3.203397e+12                0.0   \n11         2.081668e-16      -1.098642e-01                0.0   \n12         0.000000e+00       0.000000e+00                0.0   \n13        -1.387779e-16       4.696329e-02                0.0   \n14         1.611328e-01      -3.234439e+13                0.0   \n15        -2.285156e-01       5.112237e+13                0.0   \n16         7.226562e-02      -1.877798e+13                0.0   \n\n    over_ear_importance  no_pref_oninover  \n0         -3.141545e-01               0.0  \n1          3.727910e+13               0.0  \n2         -1.628827e+13               0.0  \n3          1.827553e+12               0.0  \n4         -5.203004e+13               0.0  \n5          3.120722e+13               0.0  \n6          3.658710e+13               0.0  \n7          6.418662e+12               0.0  \n8          7.170970e+12               0.0  \n9         -7.529746e+13               0.0  \n10        -3.507504e+12               0.0  \n11         1.030334e-01               0.0  \n12         0.000000e+00               0.0  \n13        -3.416114e-02               0.0  \n14         3.541493e+13               0.0  \n15        -5.597556e+13               0.0  \n16         2.056063e+13               0.0  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>game_use</th>\n      <th>rec_use</th>\n      <th>studio_use</th>\n      <th>exercise_use</th>\n      <th>office_use</th>\n      <th>podcast_use</th>\n      <th>travel_use</th>\n      <th>other_use</th>\n      <th>sound_quality_importance</th>\n      <th>positional_importance</th>\n      <th>loud_importance</th>\n      <th>mic_importance</th>\n      <th>wireless_importance</th>\n      <th>in_ear_importance</th>\n      <th>on_ear_importance</th>\n      <th>over_ear_importance</th>\n      <th>no_pref_oninover</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>2.730136e-01</td>\n      <td>8.613030e-04</td>\n      <td>-7.269864e-01</td>\n      <td>-9.650494e-02</td>\n      <td>-1.410461e-01</td>\n      <td>0.000000e+00</td>\n      <td>-9.838853e-02</td>\n      <td>-6.698252e-03</td>\n      <td>2.046974e-16</td>\n      <td>-4.857226e-16</td>\n      <td>-2.081668e-16</td>\n      <td>1.179612e-16</td>\n      <td>-4.579670e-16</td>\n      <td>2.947987e-01</td>\n      <td>0.0</td>\n      <td>-3.141545e-01</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>3.031348e+13</td>\n      <td>-1.438265e+11</td>\n      <td>3.031348e+13</td>\n      <td>3.129573e+13</td>\n      <td>3.873352e+13</td>\n      <td>3.417969e-02</td>\n      <td>3.161026e+13</td>\n      <td>1.118522e+12</td>\n      <td>4.553223e-01</td>\n      <td>1.367188e-02</td>\n      <td>-1.708984e-03</td>\n      <td>-3.125000e-02</td>\n      <td>9.472656e-02</td>\n      <td>-3.404693e+13</td>\n      <td>0.0</td>\n      <td>3.727910e+13</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>-1.324480e+13</td>\n      <td>6.284177e+10</td>\n      <td>-1.324480e+13</td>\n      <td>-1.367397e+13</td>\n      <td>-1.692375e+13</td>\n      <td>-2.001953e-02</td>\n      <td>-1.381140e+13</td>\n      <td>-4.887131e+11</td>\n      <td>1.706543e-01</td>\n      <td>6.005859e-02</td>\n      <td>1.562500e-02</td>\n      <td>2.099609e-02</td>\n      <td>3.955078e-02</td>\n      <td>1.487605e+13</td>\n      <td>0.0</td>\n      <td>-1.628827e+13</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.486074e+12</td>\n      <td>-7.050882e+09</td>\n      <td>1.486074e+12</td>\n      <td>1.534227e+12</td>\n      <td>1.898854e+12</td>\n      <td>5.401611e-01</td>\n      <td>1.549647e+12</td>\n      <td>5.483388e+10</td>\n      <td>6.942749e-03</td>\n      <td>-1.368408e-01</td>\n      <td>2.402496e-02</td>\n      <td>-1.222229e-01</td>\n      <td>-2.081299e-02</td>\n      <td>-1.669101e+12</td>\n      <td>0.0</td>\n      <td>1.827553e+12</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>-4.230820e+13</td>\n      <td>2.007371e+11</td>\n      <td>-4.230820e+13</td>\n      <td>-4.367911e+13</td>\n      <td>-5.405996e+13</td>\n      <td>3.417969e-02</td>\n      <td>-4.411810e+13</td>\n      <td>-1.561109e+12</td>\n      <td>-4.150391e-01</td>\n      <td>1.230469e-01</td>\n      <td>1.052246e-01</td>\n      <td>2.343750e-02</td>\n      <td>1.152344e-01</td>\n      <td>4.751894e+13</td>\n      <td>0.0</td>\n      <td>-5.203004e+13</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>2.537613e+13</td>\n      <td>-1.204006e+11</td>\n      <td>2.537613e+13</td>\n      <td>2.619840e+13</td>\n      <td>3.242475e+13</td>\n      <td>-4.687500e-02</td>\n      <td>2.646170e+13</td>\n      <td>9.363411e+11</td>\n      <td>5.065918e-01</td>\n      <td>1.142578e-01</td>\n      <td>-1.179199e-01</td>\n      <td>8.789062e-02</td>\n      <td>2.246094e-02</td>\n      <td>-2.850150e+13</td>\n      <td>0.0</td>\n      <td>3.120722e+13</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>2.975078e+13</td>\n      <td>-1.411567e+11</td>\n      <td>2.975078e+13</td>\n      <td>3.071479e+13</td>\n      <td>3.801452e+13</td>\n      <td>-4.101562e-02</td>\n      <td>3.102349e+13</td>\n      <td>1.097759e+12</td>\n      <td>1.191406e-01</td>\n      <td>5.273438e-02</td>\n      <td>-1.010742e-01</td>\n      <td>6.542969e-02</td>\n      <td>5.957031e-02</td>\n      <td>-3.341493e+13</td>\n      <td>0.0</td>\n      <td>3.658710e+13</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>5.219331e+12</td>\n      <td>-2.476384e+10</td>\n      <td>5.219331e+12</td>\n      <td>5.388454e+12</td>\n      <td>6.669082e+12</td>\n      <td>-4.870605e-02</td>\n      <td>5.442610e+12</td>\n      <td>1.925855e+11</td>\n      <td>9.387207e-02</td>\n      <td>-7.397461e-02</td>\n      <td>-1.357422e-01</td>\n      <td>2.783203e-02</td>\n      <td>9.643555e-02</td>\n      <td>-5.862152e+12</td>\n      <td>0.0</td>\n      <td>6.418662e+12</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>5.831069e+12</td>\n      <td>-2.766632e+10</td>\n      <td>5.831069e+12</td>\n      <td>6.020014e+12</td>\n      <td>7.450740e+12</td>\n      <td>1.452637e-01</td>\n      <td>6.080518e+12</td>\n      <td>2.151577e+11</td>\n      <td>3.671265e-02</td>\n      <td>-8.764648e-02</td>\n      <td>-2.137146e-01</td>\n      <td>5.078125e-02</td>\n      <td>2.685547e-02</td>\n      <td>-6.549233e+12</td>\n      <td>0.0</td>\n      <td>7.170970e+12</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>-6.122808e+13</td>\n      <td>2.905051e+11</td>\n      <td>-6.122808e+13</td>\n      <td>-6.321206e+13</td>\n      <td>-7.823514e+13</td>\n      <td>1.699219e-01</td>\n      <td>-6.384737e+13</td>\n      <td>-2.259224e+12</td>\n      <td>-5.268555e-01</td>\n      <td>2.500000e-01</td>\n      <td>-8.740234e-02</td>\n      <td>2.539062e-02</td>\n      <td>-2.519531e-01</td>\n      <td>6.876902e+13</td>\n      <td>0.0</td>\n      <td>-7.529746e+13</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>-2.852125e+12</td>\n      <td>1.353230e+10</td>\n      <td>-2.852125e+12</td>\n      <td>-2.944543e+12</td>\n      <td>-3.644347e+12</td>\n      <td>1.025391e-02</td>\n      <td>-2.974136e+12</td>\n      <td>-1.052391e+11</td>\n      <td>-5.439758e-02</td>\n      <td>4.516602e-03</td>\n      <td>1.448822e-01</td>\n      <td>-1.580811e-02</td>\n      <td>-5.090332e-02</td>\n      <td>3.203397e+12</td>\n      <td>0.0</td>\n      <td>-3.507504e+12</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>2.684532e-02</td>\n      <td>3.039594e-04</td>\n      <td>2.684532e-02</td>\n      <td>-2.479578e-01</td>\n      <td>-2.636767e-01</td>\n      <td>-1.665335e-16</td>\n      <td>-2.486225e-01</td>\n      <td>-2.363857e-03</td>\n      <td>-6.938894e-17</td>\n      <td>1.110223e-16</td>\n      <td>6.591949e-17</td>\n      <td>5.551115e-17</td>\n      <td>2.081668e-16</td>\n      <td>-1.098642e-01</td>\n      <td>0.0</td>\n      <td>1.030334e-01</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.0</td>\n      <td>0.000000e+00</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>2.915814e-02</td>\n      <td>-5.696756e-04</td>\n      <td>2.915814e-02</td>\n      <td>3.057760e-01</td>\n      <td>3.352360e-01</td>\n      <td>6.938894e-17</td>\n      <td>3.070218e-01</td>\n      <td>4.430300e-03</td>\n      <td>3.816392e-17</td>\n      <td>-4.163336e-17</td>\n      <td>-3.816392e-17</td>\n      <td>-2.775558e-17</td>\n      <td>-1.387779e-16</td>\n      <td>4.696329e-02</td>\n      <td>0.0</td>\n      <td>-3.416114e-02</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>2.879763e+13</td>\n      <td>-1.366343e+11</td>\n      <td>2.879763e+13</td>\n      <td>2.973076e+13</td>\n      <td>3.679662e+13</td>\n      <td>5.693359e-01</td>\n      <td>3.002957e+13</td>\n      <td>1.062589e+12</td>\n      <td>4.782715e-01</td>\n      <td>-1.308594e-01</td>\n      <td>8.251953e-02</td>\n      <td>-4.492188e-02</td>\n      <td>1.611328e-01</td>\n      <td>-3.234439e+13</td>\n      <td>0.0</td>\n      <td>3.541493e+13</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>-4.551649e+13</td>\n      <td>2.159593e+11</td>\n      <td>-4.551649e+13</td>\n      <td>-4.699136e+13</td>\n      <td>-5.815941e+13</td>\n      <td>-3.183594e-01</td>\n      <td>-4.746365e+13</td>\n      <td>-1.679490e+12</td>\n      <td>-7.834473e-01</td>\n      <td>-1.132812e-01</td>\n      <td>5.102539e-02</td>\n      <td>1.953125e-03</td>\n      <td>-2.285156e-01</td>\n      <td>5.112237e+13</td>\n      <td>0.0</td>\n      <td>-5.597556e+13</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>1.671886e+13</td>\n      <td>-7.932496e+10</td>\n      <td>1.671886e+13</td>\n      <td>1.726061e+13</td>\n      <td>2.136279e+13</td>\n      <td>-2.661133e-01</td>\n      <td>1.743408e+13</td>\n      <td>6.169009e+11</td>\n      <td>3.082275e-01</td>\n      <td>2.343750e-01</td>\n      <td>-1.329346e-01</td>\n      <td>4.345703e-02</td>\n      <td>7.226562e-02</td>\n      <td>-1.877798e+13</td>\n      <td>0.0</td>\n      <td>2.056063e+13</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "coeff = pd.DataFrame(columns= X.columns, data=lreg.coef_)\n",
        "coeff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(256, input_shape=(17,), activation='relu'),\n",
        "  #tf.keras.layers.Dense(516, activation='relu'),\n",
        "  #tf.keras.layers.Dense(256, activation='linear'),\n",
        "  #tf.keras.layers.Dense(256, activation='linear'),\n",
        "  #tf.keras.layers.Dense(256, activation='linear'),\n",
        "  #tf.keras.layers.Dense(256, activation='linear'),\n",
        "  #tf.keras.layers.Dense(256, activation='linear'),\n",
        "  #tf.keras.layers.Dense(256, activation='linear'),\n",
        "  #tf.keras.layers.Dense(256, activation='linear'),\n",
        "  #tf.keras.layers.Dense(256, activation='linear'),\n",
        "  #tf.keras.layers.Dense(256, activation='linear'),\n",
        "  #tf.keras.layers.Dense(256, activation='relu'),\n",
        "  tf.keras.layers.Dense(108, activation='linear'),\n",
        "  tf.keras.layers.Dense(17)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "opt = tf.keras.optimizers.Adam(.001)\n",
        "mae = tf.keras.losses.MeanAbsoluteError()\n",
        "\n",
        "model.compile(optimizer=opt,metrics=['accuracy'],loss=mae)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "ep - loss: 0.2077 - accuracy: 0.1236\nEpoch 203/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2077 - accuracy: 0.1245\nEpoch 204/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2077 - accuracy: 0.1254\nEpoch 205/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2076 - accuracy: 0.1236\nEpoch 206/1000\n250/250 [==============================] - 0s 2ms/step - loss: 0.2076 - accuracy: 0.1269\nEpoch 207/1000\n250/250 [==============================] - 0s 2ms/step - loss: 0.2076 - accuracy: 0.1241\nEpoch 208/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2077 - accuracy: 0.1251\nEpoch 209/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2076 - accuracy: 0.1249\nEpoch 210/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2076 - accuracy: 0.1243\nEpoch 211/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2075 - accuracy: 0.1248\nEpoch 212/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2075 - accuracy: 0.1265\nEpoch 213/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2075 - accuracy: 0.1259\nEpoch 214/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2073 - accuracy: 0.1255\nEpoch 215/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2075 - accuracy: 0.1241\nEpoch 216/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2075 - accuracy: 0.1277\nEpoch 217/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2073 - accuracy: 0.1266\nEpoch 218/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2073 - accuracy: 0.1239\nEpoch 219/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2074 - accuracy: 0.1264\nEpoch 220/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2073 - accuracy: 0.1265\nEpoch 221/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2072 - accuracy: 0.1274\nEpoch 222/1000\n250/250 [==============================] - 0s 2ms/step - loss: 0.2073 - accuracy: 0.1262\nEpoch 223/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2074 - accuracy: 0.1251\nEpoch 224/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2073 - accuracy: 0.1262\nEpoch 225/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2073 - accuracy: 0.1258\nEpoch 226/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2073 - accuracy: 0.1241\nEpoch 227/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2072 - accuracy: 0.1265\nEpoch 228/1000\n250/250 [==============================] - 0s 2ms/step - loss: 0.2073 - accuracy: 0.1270\nEpoch 229/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2072 - accuracy: 0.1264\nEpoch 230/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2071 - accuracy: 0.1279\nEpoch 231/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2072 - accuracy: 0.1275\nEpoch 232/1000\n250/250 [==============================] - 0s 2ms/step - loss: 0.2073 - accuracy: 0.1269\nEpoch 233/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2071 - accuracy: 0.1260\nEpoch 234/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2071 - accuracy: 0.1251\nEpoch 235/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2071 - accuracy: 0.1252\nEpoch 236/1000\n250/250 [==============================] - 0s 2ms/step - loss: 0.2072 - accuracy: 0.1240\nEpoch 237/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2072 - accuracy: 0.1269\nEpoch 238/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2071 - accuracy: 0.1260\nEpoch 239/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2070 - accuracy: 0.1279\nEpoch 240/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2072 - accuracy: 0.1251\nEpoch 241/1000\n250/250 [==============================] - 0s 2ms/step - loss: 0.2070 - accuracy: 0.1254\nEpoch 242/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2070 - accuracy: 0.1261\nEpoch 243/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2070 - accuracy: 0.1277\nEpoch 244/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2069 - accuracy: 0.1258\nEpoch 245/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2070 - accuracy: 0.1255\nEpoch 246/1000\n250/250 [==============================] - 0s 2ms/step - loss: 0.2070 - accuracy: 0.1265\nEpoch 247/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2070 - accuracy: 0.1277\nEpoch 248/1000\n250/250 [==============================] - 0s 2ms/step - loss: 0.2068 - accuracy: 0.1283\nEpoch 249/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2069 - accuracy: 0.1273\nEpoch 250/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2069 - accuracy: 0.1273\nEpoch 251/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2069 - accuracy: 0.1258\nEpoch 252/1000\n250/250 [==============================] - 0s 2ms/step - loss: 0.2069 - accuracy: 0.1261\nEpoch 253/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2069 - accuracy: 0.1268\nEpoch 254/1000\n250/250 [==============================] - 0s 2ms/step - loss: 0.2069 - accuracy: 0.1291\nEpoch 255/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2069 - accuracy: 0.1243\nEpoch 256/1000\n250/250 [==============================] - 0s 2ms/step - loss: 0.2068 - accuracy: 0.1258\nEpoch 257/1000\n250/250 [==============================] - 0s 2ms/step - loss: 0.2068 - accuracy: 0.1268\nEpoch 258/1000\n250/250 [==============================] - 0s 2ms/step - loss: 0.2068 - accuracy: 0.1265\nEpoch 259/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2067 - accuracy: 0.1277\nEpoch 260/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2067 - accuracy: 0.1262\nEpoch 261/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2068 - accuracy: 0.1293\nEpoch 262/1000\n250/250 [==============================] - 0s 2ms/step - loss: 0.2066 - accuracy: 0.1260\nEpoch 263/1000\n250/250 [==============================] - 0s 2ms/step - loss: 0.2067 - accuracy: 0.1293\nEpoch 264/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2068 - accuracy: 0.1275\nEpoch 265/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2067 - accuracy: 0.1286\nEpoch 266/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2066 - accuracy: 0.1269\nEpoch 267/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2066 - accuracy: 0.1277\nEpoch 268/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2067 - accuracy: 0.1254\nEpoch 269/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2067 - accuracy: 0.1269\nEpoch 270/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2067 - accuracy: 0.1283\nEpoch 271/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2066 - accuracy: 0.1261\nEpoch 272/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2067 - accuracy: 0.1264\nEpoch 273/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2066 - accuracy: 0.1277\nEpoch 274/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2065 - accuracy: 0.1275\nEpoch 275/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2065 - accuracy: 0.1283\nEpoch 276/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2065 - accuracy: 0.1287\nEpoch 277/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2066 - accuracy: 0.1275\nEpoch 278/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2067 - accuracy: 0.1285\nEpoch 279/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2066 - accuracy: 0.1284\nEpoch 280/1000\n250/250 [==============================] - 0s 2ms/step - loss: 0.2065 - accuracy: 0.1303\nEpoch 281/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2065 - accuracy: 0.1279\nEpoch 282/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2064 - accuracy: 0.1246\nEpoch 283/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2065 - accuracy: 0.1291\nEpoch 284/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2065 - accuracy: 0.1286\nEpoch 285/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2064 - accuracy: 0.1277\nEpoch 286/1000\n250/250 [==============================] - 0s 2ms/step - loss: 0.2065 - accuracy: 0.1271\nEpoch 287/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2065 - accuracy: 0.1269\nEpoch 288/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2064 - accuracy: 0.1281\nEpoch 289/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2064 - accuracy: 0.1293\nEpoch 290/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2064 - accuracy: 0.1289\nEpoch 291/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2064 - accuracy: 0.1254\nEpoch 292/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2064 - accuracy: 0.1294\nEpoch 293/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2064 - accuracy: 0.1293\nEpoch 294/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2064 - accuracy: 0.1277\nEpoch 295/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2063 - accuracy: 0.1286\nEpoch 296/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2062 - accuracy: 0.1306\nEpoch 297/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2064 - accuracy: 0.1266\nEpoch 298/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2063 - accuracy: 0.1310\nEpoch 299/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2063 - accuracy: 0.1285\nEpoch 300/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2063 - accuracy: 0.1286\nEpoch 301/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2063 - accuracy: 0.1287\nEpoch 302/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2062 - accuracy: 0.1285\nEpoch 303/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2062 - accuracy: 0.1276\nEpoch 304/1000\n250/250 [==============================] - 0s 2ms/step - loss: 0.2063 - accuracy: 0.1285\nEpoch 305/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2063 - accuracy: 0.1303\nEpoch 306/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2063 - accuracy: 0.1273\nEpoch 307/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2062 - accuracy: 0.1294\nEpoch 308/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2061 - accuracy: 0.1312\nEpoch 309/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2061 - accuracy: 0.1301\nEpoch 310/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2062 - accuracy: 0.1284\nEpoch 311/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2061 - accuracy: 0.1295\nEpoch 312/1000\n250/250 [==============================] - 0s 2ms/step - loss: 0.2061 - accuracy: 0.1285\nEpoch 313/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2062 - accuracy: 0.1291\nEpoch 314/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2062 - accuracy: 0.1291\nEpoch 315/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2061 - accuracy: 0.1287\nEpoch 316/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2061 - accuracy: 0.1283\nEpoch 317/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2062 - accuracy: 0.1275\nEpoch 318/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2060 - accuracy: 0.1303\nEpoch 319/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2060 - accuracy: 0.1293\nEpoch 320/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2061 - accuracy: 0.1293\nEpoch 321/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2061 - accuracy: 0.1301\nEpoch 322/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2060 - accuracy: 0.1303\nEpoch 323/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2061 - accuracy: 0.1287\nEpoch 324/1000\n250/250 [==============================] - 0s 2ms/step - loss: 0.2061 - accuracy: 0.1296\nEpoch 325/1000\n250/250 [==============================] - 0s 2ms/step - loss: 0.2061 - accuracy: 0.1287\nEpoch 326/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2060 - accuracy: 0.1308\nEpoch 327/1000\n250/250 [==============================] - 0s 2ms/step - loss: 0.2060 - accuracy: 0.1303\nEpoch 328/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2061 - accuracy: 0.1291\nEpoch 329/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2060 - accuracy: 0.1281\nEpoch 330/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2060 - accuracy: 0.1308\nEpoch 331/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2060 - accuracy: 0.1293\nEpoch 332/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2060 - accuracy: 0.1310\nEpoch 333/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2060 - accuracy: 0.1284\nEpoch 334/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2060 - accuracy: 0.1309\nEpoch 335/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2059 - accuracy: 0.1314\nEpoch 336/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2060 - accuracy: 0.1322\nEpoch 337/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2059 - accuracy: 0.1315\nEpoch 338/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2059 - accuracy: 0.1295\nEpoch 339/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2060 - accuracy: 0.1303\nEpoch 340/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2059 - accuracy: 0.1303\nEpoch 341/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2059 - accuracy: 0.1303\nEpoch 342/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2059 - accuracy: 0.1331\nEpoch 343/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2058 - accuracy: 0.1312\nEpoch 344/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2060 - accuracy: 0.1315\nEpoch 345/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2059 - accuracy: 0.1290\nEpoch 346/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2059 - accuracy: 0.1295\nEpoch 347/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2059 - accuracy: 0.1275\nEpoch 348/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2058 - accuracy: 0.1321\nEpoch 349/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2058 - accuracy: 0.1303\nEpoch 350/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2059 - accuracy: 0.1287\nEpoch 351/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2059 - accuracy: 0.1280\nEpoch 352/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2058 - accuracy: 0.1310\nEpoch 353/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2058 - accuracy: 0.1339\nEpoch 354/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2057 - accuracy: 0.1293\nEpoch 355/1000\n250/250 [==============================] - 0s 2ms/step - loss: 0.2059 - accuracy: 0.1297\nEpoch 356/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2057 - accuracy: 0.1287\nEpoch 357/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2059 - accuracy: 0.1326\nEpoch 358/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2057 - accuracy: 0.1322\nEpoch 359/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2057 - accuracy: 0.1322\nEpoch 360/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2057 - accuracy: 0.1300\nEpoch 361/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2058 - accuracy: 0.1346\nEpoch 362/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2057 - accuracy: 0.1319\nEpoch 363/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2058 - accuracy: 0.1322\nEpoch 364/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2057 - accuracy: 0.1306\nEpoch 365/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2058 - accuracy: 0.1311\nEpoch 366/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2056 - accuracy: 0.1312\nEpoch 367/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2057 - accuracy: 0.1297\nEpoch 368/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2057 - accuracy: 0.1320\nEpoch 369/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2057 - accuracy: 0.1291\nEpoch 370/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2057 - accuracy: 0.1308\nEpoch 371/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2057 - accuracy: 0.1301\nEpoch 372/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2058 - accuracy: 0.1304\nEpoch 373/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2056 - accuracy: 0.1316\nEpoch 374/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2056 - accuracy: 0.1320\nEpoch 375/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2056 - accuracy: 0.1309\nEpoch 376/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2057 - accuracy: 0.1335\nEpoch 377/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2056 - accuracy: 0.1320\nEpoch 378/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2056 - accuracy: 0.1316\nEpoch 379/1000\n250/250 [==============================] - 0s 2ms/step - loss: 0.2054 - accuracy: 0.1320\nEpoch 380/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2057 - accuracy: 0.1306\nEpoch 381/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2056 - accuracy: 0.1290\nEpoch 382/1000\n250/250 [==============================] - 0s 2ms/step - loss: 0.2055 - accuracy: 0.1311\nEpoch 383/1000\n250/250 [==============================] - 0s 2ms/step - loss: 0.2057 - accuracy: 0.1314\nEpoch 384/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2056 - accuracy: 0.1306\nEpoch 385/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2055 - accuracy: 0.1338\nEpoch 386/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2056 - accuracy: 0.1297\nEpoch 387/1000\n250/250 [==============================] - 0s 1ms/step - loss: 0.2055 - accuracy: 0.1334\nEpoch 388/1000\n250/250 [==============================] - 0s 2ms/step - loss: 0.2055 - accuracy: 0.1321\nEpoch 389/1000\n250/250 [==============================] - 0s 2ms/step - loss: 0.2055 - accuracy: 0.1295\nEpoch 390/1000\n250/250 [==============================] - 0s 2ms/step - loss: 0.2056 - accuracy: 0.1334\nEpoch 391/1000\n250/250 [==============================] - 0s 2ms/step - loss: 0.2056 - accuracy: 0.1295\nEpoch 392/1000\n250/250 [==============================] - 0s 2ms/step - loss: 0.2056 - accuracy: 0.1316\nEpoch 393/1000\n250/250 [==============================] - 0s 2ms/step - loss: 0.2055 - accuracy: 0.1319\nEpoch 394/1000\n110/250 [============>.................] - ETA: 0s - loss: 0.2051 - accuracy: 0.1259"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-fc6db771e270>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    784\u001b[0m       \u001b[0mexecution_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"notTraced\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mwithout_tracing\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"traced\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m       tm.set_metadata(tf_function_call=execution_mode + \"-\" + compiler,\n\u001b[0;32m--> 786\u001b[0;31m                       tracing_count=new_tracing_count)\n\u001b[0m\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mset_metadata\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     to measure the entire duration of call()).\n\u001b[1;32m    119\u001b[0m     \"\"\"\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_traceme\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_traceme\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetMetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "r=model.fit(randx,randy, epochs=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'r' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-ea19c2e162ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'r' is not defined"
          ]
        }
      ],
      "source": [
        "# Plot the loss\n",
        "plt.plot(r.history['loss'], label='loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'r' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-b06dd4d4da94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'r' is not defined"
          ]
        }
      ],
      "source": [
        "plt.plot(r.history['accuracy'], label='accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "aanpreds = model.predict(xpred)\n",
        "randaanpreds = model.predict(randxpred)\n",
        "preds = model.predict(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "preddf = pd.DataFrame(data=aanpreds, columns = [ 'attached_mic', 'recording_quality',\n",
        "       'noise_handling', 'Impedance', 'sensitivity(dbv)', 'accuracy',\n",
        "       'weighted_harmonic_distortion', 'soundstage', 'imaging',\n",
        "       'noise_isolation', 'wireless', 'over_ear_style', 'on_ear_style',\n",
        "       'in_ear_style', 'open_back', 'close_back', 'semiclosed_back'])\n",
        "predrand = pd.DataFrame(data=randaanpreds, columns = [ 'attached_mic', 'recording_quality',\n",
        "       'noise_handling', 'Impedance', 'sensitivity(dbv)', 'accuracy',\n",
        "       'weighted_harmonic_distortion', 'soundstage', 'imaging',\n",
        "       'noise_isolation', 'wireless', 'over_ear_style', 'on_ear_style',\n",
        "       'in_ear_style', 'open_back', 'close_back', 'semiclosed_back'])\n",
        "predset = pd.DataFrame(data=preds, columns = [ 'attached_mic', 'recording_quality',\n",
        "       'noise_handling', 'Impedance', 'sensitivity(dbv)', 'accuracy',\n",
        "       'weighted_harmonic_distortion', 'soundstage', 'imaging',\n",
        "       'noise_isolation', 'wireless', 'over_ear_style', 'on_ear_style',\n",
        "       'in_ear_style', 'open_back', 'close_back', 'semiclosed_back'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "    attached_mic  recording_quality  noise_handling  Impedance  \\\n0       0.000307           0.001822        0.419454   0.186553   \n1       0.001906           0.001961        0.499849   0.082434   \n2       0.000255           0.000924        0.467086   0.123498   \n3       0.000193           0.001409        0.443647   0.105776   \n4       0.000193           0.001409        0.443647   0.105776   \n5       0.000193           0.001409        0.443647   0.105776   \n6       0.000307           0.001822        0.419454   0.186553   \n7       0.001906           0.001961        0.499849   0.082434   \n8       0.000255           0.000924        0.467086   0.123498   \n9       0.000193           0.001409        0.443647   0.105776   \n10      0.000255           0.000924        0.467086   0.123498   \n11      0.001906           0.001961        0.499849   0.082434   \n12      0.001906           0.001961        0.499849   0.082434   \n13      0.000307           0.001822        0.419454   0.186553   \n14      0.000255           0.000924        0.467086   0.123498   \n15      0.000307           0.001822        0.419454   0.186553   \n\n    sensitivity(dbv)  accuracy  weighted_harmonic_distortion  soundstage  \\\n0           0.856798  0.688130                      0.433724    0.544512   \n1           0.649965  0.735481                      0.512960    0.817588   \n2           0.402629  0.554614                      0.701856    0.633798   \n3           0.677223  0.429498                      0.669919    0.655458   \n4           0.677223  0.429498                      0.669919    0.655458   \n5           0.677223  0.429498                      0.669919    0.655458   \n6           0.856798  0.688130                      0.433724    0.544512   \n7           0.649965  0.735481                      0.512960    0.817588   \n8           0.402629  0.554614                      0.701856    0.633798   \n9           0.677223  0.429498                      0.669919    0.655458   \n10          0.402629  0.554614                      0.701856    0.633798   \n11          0.649965  0.735481                      0.512960    0.817588   \n12          0.649965  0.735481                      0.512960    0.817588   \n13          0.856798  0.688130                      0.433724    0.544512   \n14          0.402629  0.554614                      0.701856    0.633798   \n15          0.856798  0.688130                      0.433724    0.544512   \n\n     imaging  noise_isolation  wireless  over_ear_style  on_ear_style  \\\n0   0.618112         0.559364  0.002598        0.024724      0.000173   \n1   0.340001         0.749867  0.002586        1.214768      0.000115   \n2   0.515059         0.389046  0.000613        0.439493      0.000845   \n3   0.678164         0.224511  0.001834        0.441222      0.000734   \n4   0.678164         0.224511  0.001834        0.441222      0.000734   \n5   0.678164         0.224511  0.001834        0.441222      0.000734   \n6   0.618112         0.559364  0.002598        0.024724      0.000173   \n7   0.340001         0.749867  0.002586        1.214768      0.000115   \n8   0.515059         0.389046  0.000613        0.439493      0.000845   \n9   0.678164         0.224511  0.001834        0.441222      0.000734   \n10  0.515059         0.389046  0.000613        0.439493      0.000845   \n11  0.340001         0.749867  0.002586        1.214768      0.000115   \n12  0.340001         0.749867  0.002586        1.214768      0.000115   \n13  0.618112         0.559364  0.002598        0.024724      0.000173   \n14  0.515059         0.389046  0.000613        0.439493      0.000845   \n15  0.618112         0.559364  0.002598        0.024724      0.000173   \n\n    in_ear_style  open_back  close_back  semiclosed_back  \n0       0.001185  -0.001164    0.879670         0.000917  \n1       0.001396  -0.000229    0.921870         0.001254  \n2       0.000360   0.000498    0.995797        -0.000074  \n3       0.001286  -0.000267    1.001109        -0.000633  \n4       0.001286  -0.000267    1.001109        -0.000633  \n5       0.001286  -0.000267    1.001109        -0.000633  \n6       0.001185  -0.001164    0.879670         0.000917  \n7       0.001396  -0.000229    0.921870         0.001254  \n8       0.000360   0.000498    0.995797        -0.000074  \n9       0.001286  -0.000267    1.001109        -0.000633  \n10      0.000360   0.000498    0.995797        -0.000074  \n11      0.001396  -0.000229    0.921870         0.001254  \n12      0.001396  -0.000229    0.921870         0.001254  \n13      0.001185  -0.001164    0.879670         0.000917  \n14      0.000360   0.000498    0.995797        -0.000074  \n15      0.001185  -0.001164    0.879670         0.000917  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>attached_mic</th>\n      <th>recording_quality</th>\n      <th>noise_handling</th>\n      <th>Impedance</th>\n      <th>sensitivity(dbv)</th>\n      <th>accuracy</th>\n      <th>weighted_harmonic_distortion</th>\n      <th>soundstage</th>\n      <th>imaging</th>\n      <th>noise_isolation</th>\n      <th>wireless</th>\n      <th>over_ear_style</th>\n      <th>on_ear_style</th>\n      <th>in_ear_style</th>\n      <th>open_back</th>\n      <th>close_back</th>\n      <th>semiclosed_back</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.000307</td>\n      <td>0.001822</td>\n      <td>0.419454</td>\n      <td>0.186553</td>\n      <td>0.856798</td>\n      <td>0.688130</td>\n      <td>0.433724</td>\n      <td>0.544512</td>\n      <td>0.618112</td>\n      <td>0.559364</td>\n      <td>0.002598</td>\n      <td>0.024724</td>\n      <td>0.000173</td>\n      <td>0.001185</td>\n      <td>-0.001164</td>\n      <td>0.879670</td>\n      <td>0.000917</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.001906</td>\n      <td>0.001961</td>\n      <td>0.499849</td>\n      <td>0.082434</td>\n      <td>0.649965</td>\n      <td>0.735481</td>\n      <td>0.512960</td>\n      <td>0.817588</td>\n      <td>0.340001</td>\n      <td>0.749867</td>\n      <td>0.002586</td>\n      <td>1.214768</td>\n      <td>0.000115</td>\n      <td>0.001396</td>\n      <td>-0.000229</td>\n      <td>0.921870</td>\n      <td>0.001254</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.000255</td>\n      <td>0.000924</td>\n      <td>0.467086</td>\n      <td>0.123498</td>\n      <td>0.402629</td>\n      <td>0.554614</td>\n      <td>0.701856</td>\n      <td>0.633798</td>\n      <td>0.515059</td>\n      <td>0.389046</td>\n      <td>0.000613</td>\n      <td>0.439493</td>\n      <td>0.000845</td>\n      <td>0.000360</td>\n      <td>0.000498</td>\n      <td>0.995797</td>\n      <td>-0.000074</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.000193</td>\n      <td>0.001409</td>\n      <td>0.443647</td>\n      <td>0.105776</td>\n      <td>0.677223</td>\n      <td>0.429498</td>\n      <td>0.669919</td>\n      <td>0.655458</td>\n      <td>0.678164</td>\n      <td>0.224511</td>\n      <td>0.001834</td>\n      <td>0.441222</td>\n      <td>0.000734</td>\n      <td>0.001286</td>\n      <td>-0.000267</td>\n      <td>1.001109</td>\n      <td>-0.000633</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.000193</td>\n      <td>0.001409</td>\n      <td>0.443647</td>\n      <td>0.105776</td>\n      <td>0.677223</td>\n      <td>0.429498</td>\n      <td>0.669919</td>\n      <td>0.655458</td>\n      <td>0.678164</td>\n      <td>0.224511</td>\n      <td>0.001834</td>\n      <td>0.441222</td>\n      <td>0.000734</td>\n      <td>0.001286</td>\n      <td>-0.000267</td>\n      <td>1.001109</td>\n      <td>-0.000633</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.000193</td>\n      <td>0.001409</td>\n      <td>0.443647</td>\n      <td>0.105776</td>\n      <td>0.677223</td>\n      <td>0.429498</td>\n      <td>0.669919</td>\n      <td>0.655458</td>\n      <td>0.678164</td>\n      <td>0.224511</td>\n      <td>0.001834</td>\n      <td>0.441222</td>\n      <td>0.000734</td>\n      <td>0.001286</td>\n      <td>-0.000267</td>\n      <td>1.001109</td>\n      <td>-0.000633</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.000307</td>\n      <td>0.001822</td>\n      <td>0.419454</td>\n      <td>0.186553</td>\n      <td>0.856798</td>\n      <td>0.688130</td>\n      <td>0.433724</td>\n      <td>0.544512</td>\n      <td>0.618112</td>\n      <td>0.559364</td>\n      <td>0.002598</td>\n      <td>0.024724</td>\n      <td>0.000173</td>\n      <td>0.001185</td>\n      <td>-0.001164</td>\n      <td>0.879670</td>\n      <td>0.000917</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.001906</td>\n      <td>0.001961</td>\n      <td>0.499849</td>\n      <td>0.082434</td>\n      <td>0.649965</td>\n      <td>0.735481</td>\n      <td>0.512960</td>\n      <td>0.817588</td>\n      <td>0.340001</td>\n      <td>0.749867</td>\n      <td>0.002586</td>\n      <td>1.214768</td>\n      <td>0.000115</td>\n      <td>0.001396</td>\n      <td>-0.000229</td>\n      <td>0.921870</td>\n      <td>0.001254</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.000255</td>\n      <td>0.000924</td>\n      <td>0.467086</td>\n      <td>0.123498</td>\n      <td>0.402629</td>\n      <td>0.554614</td>\n      <td>0.701856</td>\n      <td>0.633798</td>\n      <td>0.515059</td>\n      <td>0.389046</td>\n      <td>0.000613</td>\n      <td>0.439493</td>\n      <td>0.000845</td>\n      <td>0.000360</td>\n      <td>0.000498</td>\n      <td>0.995797</td>\n      <td>-0.000074</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.000193</td>\n      <td>0.001409</td>\n      <td>0.443647</td>\n      <td>0.105776</td>\n      <td>0.677223</td>\n      <td>0.429498</td>\n      <td>0.669919</td>\n      <td>0.655458</td>\n      <td>0.678164</td>\n      <td>0.224511</td>\n      <td>0.001834</td>\n      <td>0.441222</td>\n      <td>0.000734</td>\n      <td>0.001286</td>\n      <td>-0.000267</td>\n      <td>1.001109</td>\n      <td>-0.000633</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.000255</td>\n      <td>0.000924</td>\n      <td>0.467086</td>\n      <td>0.123498</td>\n      <td>0.402629</td>\n      <td>0.554614</td>\n      <td>0.701856</td>\n      <td>0.633798</td>\n      <td>0.515059</td>\n      <td>0.389046</td>\n      <td>0.000613</td>\n      <td>0.439493</td>\n      <td>0.000845</td>\n      <td>0.000360</td>\n      <td>0.000498</td>\n      <td>0.995797</td>\n      <td>-0.000074</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.001906</td>\n      <td>0.001961</td>\n      <td>0.499849</td>\n      <td>0.082434</td>\n      <td>0.649965</td>\n      <td>0.735481</td>\n      <td>0.512960</td>\n      <td>0.817588</td>\n      <td>0.340001</td>\n      <td>0.749867</td>\n      <td>0.002586</td>\n      <td>1.214768</td>\n      <td>0.000115</td>\n      <td>0.001396</td>\n      <td>-0.000229</td>\n      <td>0.921870</td>\n      <td>0.001254</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.001906</td>\n      <td>0.001961</td>\n      <td>0.499849</td>\n      <td>0.082434</td>\n      <td>0.649965</td>\n      <td>0.735481</td>\n      <td>0.512960</td>\n      <td>0.817588</td>\n      <td>0.340001</td>\n      <td>0.749867</td>\n      <td>0.002586</td>\n      <td>1.214768</td>\n      <td>0.000115</td>\n      <td>0.001396</td>\n      <td>-0.000229</td>\n      <td>0.921870</td>\n      <td>0.001254</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.000307</td>\n      <td>0.001822</td>\n      <td>0.419454</td>\n      <td>0.186553</td>\n      <td>0.856798</td>\n      <td>0.688130</td>\n      <td>0.433724</td>\n      <td>0.544512</td>\n      <td>0.618112</td>\n      <td>0.559364</td>\n      <td>0.002598</td>\n      <td>0.024724</td>\n      <td>0.000173</td>\n      <td>0.001185</td>\n      <td>-0.001164</td>\n      <td>0.879670</td>\n      <td>0.000917</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.000255</td>\n      <td>0.000924</td>\n      <td>0.467086</td>\n      <td>0.123498</td>\n      <td>0.402629</td>\n      <td>0.554614</td>\n      <td>0.701856</td>\n      <td>0.633798</td>\n      <td>0.515059</td>\n      <td>0.389046</td>\n      <td>0.000613</td>\n      <td>0.439493</td>\n      <td>0.000845</td>\n      <td>0.000360</td>\n      <td>0.000498</td>\n      <td>0.995797</td>\n      <td>-0.000074</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.000307</td>\n      <td>0.001822</td>\n      <td>0.419454</td>\n      <td>0.186553</td>\n      <td>0.856798</td>\n      <td>0.688130</td>\n      <td>0.433724</td>\n      <td>0.544512</td>\n      <td>0.618112</td>\n      <td>0.559364</td>\n      <td>0.002598</td>\n      <td>0.024724</td>\n      <td>0.000173</td>\n      <td>0.001185</td>\n      <td>-0.001164</td>\n      <td>0.879670</td>\n      <td>0.000917</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "predset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "mse = np.mean((aanpreds - ypred)**2)\n",
        "mse1 =np.mean((randaanpreds - randypred)**2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "(attached_mic                    4.993991e-01\n recording_quality               2.629824e-01\n noise_handling                  2.459394e-01\n Impedance                       1.329961e-01\n sensitivity(dbv)                1.354811e-01\n accuracy                        8.233864e-02\n weighted_harmonic_distortion    2.738057e-01\n soundstage                      1.408889e-01\n imaging                         1.206647e-01\n noise_isolation                 9.458200e-02\n wireless                        1.719521e-01\n over_ear_style                  5.549490e-01\n on_ear_style                    1.484874e-07\n in_ear_style                    1.152364e-01\n open_back                       6.541559e-01\n close_back                      8.374821e-01\n semiclosed_back                 1.921639e-01\n dtype: float64, attached_mic                    0.201155\n recording_quality               0.090777\n noise_handling                  0.081329\n Impedance                       0.044057\n sensitivity(dbv)                0.081817\n accuracy                        0.083029\n weighted_harmonic_distortion    0.081665\n soundstage                      0.080809\n imaging                         0.081491\n noise_isolation                 0.081198\n wireless                        0.151676\n over_ear_style                  0.243101\n on_ear_style                    0.126715\n in_ear_style                    0.243805\n open_back                       0.149723\n close_back                      0.301615\n semiclosed_back                 0.077100\n dtype: float64)"
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "mse,mse1"
      ]
    }
  ]
}