{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF2.0 Recommender System.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "Python 3.8.3 64-bit (conda)",
      "display_name": "Python 3.8.3 64-bit (conda)",
      "metadata": {
        "interpreter": {
          "hash": "7d8b0fcd9a33b0b340771ad2580a0cc166ae414f15b0a3afbf83c0b8b1a5722a"
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "2.3.0\n"
        }
      ],
      "source": [
        "\n",
        "#Check TF version\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Default GPU Device:/device:GPU:0\n"
        }
      ],
      "source": [
        "# Is GPU enabled\n",
        "if tf.test.gpu_device_name():\n",
        "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
        "else:\n",
        "    print(\"Fix it\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmO5csZi7cdr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, Flatten, \\\n",
        "  Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.multioutput import RegressorChain\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import plot_roc_curve\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os \n",
        "import earthpy as et "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Code needed to set a new working directory\n",
        "\n",
        "#my_path = os.path.join(et.io.HOME, 'recommender_system')\n",
        "#os.mkdir(my_path)\n",
        "\n",
        "## Set Working Directory\n",
        "os.chdir(os.path.join(\"/home/ckamerin/Documents/GitHub\", 'recommender_system'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "&#39;/home/ckamerin/Documents/GitHub/recommender_system&#39;"
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Check if it worked\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6h0pEt_7lZC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4a410b48-1608-4ea0-b7d5-5bcf12ea065a"
      },
      "source": [
        "# Data Import\n",
        "df = pd.read_csv(\"/home/ckamerin/Desktop/headphone_df_cleaned.csv\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "df = df.drop(columns='Unnamed: 0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "Index([&#39;headphone_name&#39;, &#39;game_use&#39;, &#39;travel_use&#39;, &#39;exercise_use&#39;,\n       &#39;office_use&#39;, &#39;phone_call_use&#39;, &#39;studio_use&#39;, &#39;wireless&#39;,\n       &#39;noise_cancelling&#39;, &#39;mic_presence&#39;, &#39;frequency_response_consistency&#39;,\n       &#39;bass_accuracy&#39;, &#39;mid_accuracy&#39;, &#39;treble_accuracy&#39;, &#39;peaks_dips&#39;,\n       &#39;imaging&#39;, &#39;passive_soundstage&#39;, &#39;weighted_harmonic_distortion&#39;,\n       &#39;noise_isolation&#39;, &#39;microphone_rating&#39;, &#39;mic_recording_quality&#39;,\n       &#39;bluetooth&#39;, &#39;closed_back&#39;, &#39;open_back&#39;, &#39;in_ear&#39;, &#39;on_ear&#39;, &#39;over_ear&#39;,\n       &#39;head_set&#39;],\n      dtype=&#39;object&#39;)"
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "X=df[['travel_use', 'exercise_use', 'office_use',\n",
        "       'phone_call_use', 'studio_use', 'game_use']]\n",
        "y=df[[ 'wireless', 'noise_cancelling',\n",
        "       'mic_presence', 'frequency_response_consistency', 'bass_accuracy',\n",
        "       'mid_accuracy', 'treble_accuracy', 'peaks_dips', 'imaging',\n",
        "       'passive_soundstage', 'weighted_harmonic_distortion', 'noise_isolation',\n",
        "       'microphone_rating', 'mic_recording_quality', 'bluetooth',\n",
        "       'closed_back', 'open_back', 'in_ear', 'on_ear', 'over_ear', 'head_set']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        " X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "x1_train, x1_test, y1_train, y1_test = y_train, y_test, X_train, X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Put models in a dictionary\n",
        "models = {\"KNN\": KNeighborsRegressor(),\n",
        "          'KNN Multi' : MultiOutputRegressor(KNeighborsRegressor()),\n",
        "          \"Random Forest\": RandomForestRegressor(),\n",
        "          \"Random Forest Multi\": MultiOutputRegressor(RandomForestRegressor()),\n",
        "          \"Linear Regression\": LinearRegression(),\n",
        "          \"Linear Regression Multi\": MultiOutputRegressor(LinearRegression()),\n",
        "          'Decision Tree Regression': DecisionTreeRegressor(),\n",
        "          'Decision Tree Multi': MultiOutputRegressor(DecisionTreeRegressor()),\n",
        "          'Ridge Regressor Chain': RegressorChain(Ridge()),\n",
        "          'Ridge Regresor Multioutput': MultiOutputRegressor(Ridge())\n",
        "          }\n",
        "# Create function to fit and score models\n",
        "def fit_and_score(models, X_train, X_test, y_train, y_test):\n",
        "    \"\"\"\n",
        "    Fits and evaluates given machine learning models.\n",
        "    models : a dict of different Scikit-Learn machine learning models\n",
        "    X_train : training data\n",
        "    X_test : testing data\n",
        "    y_train : labels assosciated with training data\n",
        "    y_test : labels assosciated with test data\n",
        "    \"\"\"\n",
        "    # Random seed for reproducible results\n",
        "    np.random.seed(42)\n",
        "    # Make a list to keep model scores\n",
        "    model_scores = {}\n",
        "    # Loop through models\n",
        "    for name, model in models.items():\n",
        "        # Fit the model to the data\n",
        "        model.fit(X_train, y_train)\n",
        "        # Evaluate the model and append its score to model_scores\n",
        "        model_scores[name] = model.score(X_test, y_test)\n",
        "    return model_scores\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "{&#39;KNN&#39;: 0.599778178639396,\n &#39;KNN Multi&#39;: 0.599778178639396,\n &#39;Random Forest&#39;: 0.5886879251928663,\n &#39;Random Forest Multi&#39;: 0.6285097404574641,\n &#39;Linear Regression&#39;: 0.5444887788478071,\n &#39;Linear Regression Multi&#39;: 0.5444887788478071,\n &#39;Decision Tree Regression&#39;: 0.19152007634124824,\n &#39;Decision Tree Multi&#39;: 0.26194138595007344,\n &#39;Ridge Regressor Chain&#39;: 0.5288152584304666,\n &#39;Ridge Regresor Multioutput&#39;: 0.5288152584304666}"
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "#Test all models on one dataset\n",
        "model_scores = fit_and_score(models=models,\n",
        "                             X_train=X_train,\n",
        "                             X_test=X_test,\n",
        "                             y_train=y_train,\n",
        "                             y_test=y_test)\n",
        "model_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "{&#39;KNN&#39;: 0.8497970055606429,\n &#39;KNN Multi&#39;: 0.8497970055606429,\n &#39;Random Forest&#39;: 0.8516601228507065,\n &#39;Random Forest Multi&#39;: 0.8754651302596562,\n &#39;Linear Regression&#39;: 0.9156168267307402,\n &#39;Linear Regression Multi&#39;: 0.9156168267307402,\n &#39;Decision Tree Regression&#39;: 0.755113198364849,\n &#39;Decision Tree Multi&#39;: 0.739954070698437,\n &#39;Ridge Regressor Chain&#39;: 0.9114208755853902,\n &#39;Ridge Regresor Multioutput&#39;: 0.9114208755853904}"
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "model_scores = fit_and_score(models=models,\n",
        "                             X_train=x1_train,\n",
        "                             X_test=x1_test,\n",
        "                             y_train=y1_train,\n",
        "                             y_test=y1_test)\n",
        "model_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "ANN = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(108, input_dim = 6, activation='relu'),\n",
        "  #tf.keras.layers.Dropout(.1),\n",
        "  tf.keras.layers.Dense(256, activation='relu'),\n",
        "  #tf.keras.layers.Dropout(.1),\n",
        "  tf.keras.layers.Dense(512, activation='relu'),\n",
        "  #tf.keras.layers.Dropout(.1),\n",
        "  tf.keras.layers.Dense(256, activation='relu'),\n",
        "  #tf.keras.layers.Dropout(.1),\n",
        "  tf.keras.layers.Dense(21, activation= 'linear')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "opt = tf.keras.optimizers.Adam(.00001)\n",
        "mae = tf.keras.losses.MeanAbsoluteError()\n",
        "ANN.compile(optimizer=opt,metrics=['accuracy'],loss='mse')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "tags": [
          "outputPrepend"
        ]
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[==============================] - 0s 2ms/step - loss: 0.0403 - accuracy: 0.3043 - val_loss: 0.0434 - val_accuracy: 0.3966\nEpoch 212/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0402 - accuracy: 0.3087 - val_loss: 0.0437 - val_accuracy: 0.4138\nEpoch 213/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0401 - accuracy: 0.3217 - val_loss: 0.0434 - val_accuracy: 0.4138\nEpoch 214/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0400 - accuracy: 0.3174 - val_loss: 0.0433 - val_accuracy: 0.4138\nEpoch 215/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0399 - accuracy: 0.3217 - val_loss: 0.0433 - val_accuracy: 0.4138\nEpoch 216/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0399 - accuracy: 0.3217 - val_loss: 0.0433 - val_accuracy: 0.4138\nEpoch 217/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0398 - accuracy: 0.3130 - val_loss: 0.0432 - val_accuracy: 0.4138\nEpoch 218/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 0.3174 - val_loss: 0.0431 - val_accuracy: 0.4138\nEpoch 219/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 0.3217 - val_loss: 0.0430 - val_accuracy: 0.4138\nEpoch 220/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0396 - accuracy: 0.3130 - val_loss: 0.0429 - val_accuracy: 0.4138\nEpoch 221/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0396 - accuracy: 0.3130 - val_loss: 0.0431 - val_accuracy: 0.4138\nEpoch 222/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0395 - accuracy: 0.3087 - val_loss: 0.0429 - val_accuracy: 0.4138\nEpoch 223/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0394 - accuracy: 0.3087 - val_loss: 0.0427 - val_accuracy: 0.4138\nEpoch 224/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0394 - accuracy: 0.3130 - val_loss: 0.0429 - val_accuracy: 0.4138\nEpoch 225/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0392 - accuracy: 0.3217 - val_loss: 0.0426 - val_accuracy: 0.4138\nEpoch 226/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0392 - accuracy: 0.3261 - val_loss: 0.0427 - val_accuracy: 0.4138\nEpoch 227/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0391 - accuracy: 0.3261 - val_loss: 0.0429 - val_accuracy: 0.4138\nEpoch 228/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0390 - accuracy: 0.3261 - val_loss: 0.0426 - val_accuracy: 0.4138\nEpoch 229/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0390 - accuracy: 0.3174 - val_loss: 0.0425 - val_accuracy: 0.4138\nEpoch 230/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0389 - accuracy: 0.3217 - val_loss: 0.0425 - val_accuracy: 0.4138\nEpoch 231/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0388 - accuracy: 0.3130 - val_loss: 0.0424 - val_accuracy: 0.4138\nEpoch 232/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0388 - accuracy: 0.3130 - val_loss: 0.0423 - val_accuracy: 0.4138\nEpoch 233/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0387 - accuracy: 0.3130 - val_loss: 0.0424 - val_accuracy: 0.4138\nEpoch 234/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0387 - accuracy: 0.3217 - val_loss: 0.0424 - val_accuracy: 0.4138\nEpoch 235/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0386 - accuracy: 0.3217 - val_loss: 0.0422 - val_accuracy: 0.4138\nEpoch 236/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0386 - accuracy: 0.3217 - val_loss: 0.0423 - val_accuracy: 0.4138\nEpoch 237/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0385 - accuracy: 0.3174 - val_loss: 0.0421 - val_accuracy: 0.4138\nEpoch 238/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0384 - accuracy: 0.3217 - val_loss: 0.0423 - val_accuracy: 0.4138\nEpoch 239/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0384 - accuracy: 0.3174 - val_loss: 0.0423 - val_accuracy: 0.4138\nEpoch 240/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0383 - accuracy: 0.3304 - val_loss: 0.0422 - val_accuracy: 0.4138\nEpoch 241/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0382 - accuracy: 0.3304 - val_loss: 0.0421 - val_accuracy: 0.4138\nEpoch 242/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0382 - accuracy: 0.3217 - val_loss: 0.0420 - val_accuracy: 0.4138\nEpoch 243/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0381 - accuracy: 0.3261 - val_loss: 0.0420 - val_accuracy: 0.4138\nEpoch 244/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0381 - accuracy: 0.3261 - val_loss: 0.0421 - val_accuracy: 0.4138\nEpoch 245/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0380 - accuracy: 0.3217 - val_loss: 0.0418 - val_accuracy: 0.4138\nEpoch 246/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0380 - accuracy: 0.3174 - val_loss: 0.0418 - val_accuracy: 0.4138\nEpoch 247/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0379 - accuracy: 0.3174 - val_loss: 0.0417 - val_accuracy: 0.4138\nEpoch 248/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0378 - accuracy: 0.3217 - val_loss: 0.0419 - val_accuracy: 0.4138\nEpoch 249/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0378 - accuracy: 0.3217 - val_loss: 0.0417 - val_accuracy: 0.4138\nEpoch 250/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0377 - accuracy: 0.3217 - val_loss: 0.0417 - val_accuracy: 0.4138\nEpoch 251/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0377 - accuracy: 0.3304 - val_loss: 0.0418 - val_accuracy: 0.4138\nEpoch 252/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0376 - accuracy: 0.3304 - val_loss: 0.0415 - val_accuracy: 0.4138\nEpoch 253/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0375 - accuracy: 0.3304 - val_loss: 0.0416 - val_accuracy: 0.4138\nEpoch 254/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0375 - accuracy: 0.3261 - val_loss: 0.0417 - val_accuracy: 0.4138\nEpoch 255/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0374 - accuracy: 0.3217 - val_loss: 0.0416 - val_accuracy: 0.4138\nEpoch 256/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0374 - accuracy: 0.3304 - val_loss: 0.0416 - val_accuracy: 0.4138\nEpoch 257/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0374 - accuracy: 0.3087 - val_loss: 0.0413 - val_accuracy: 0.4138\nEpoch 258/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0372 - accuracy: 0.3087 - val_loss: 0.0416 - val_accuracy: 0.3966\nEpoch 259/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0372 - accuracy: 0.3174 - val_loss: 0.0415 - val_accuracy: 0.3966\nEpoch 260/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0373 - accuracy: 0.3261 - val_loss: 0.0414 - val_accuracy: 0.4138\nEpoch 261/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0371 - accuracy: 0.3174 - val_loss: 0.0416 - val_accuracy: 0.4138\nEpoch 262/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0370 - accuracy: 0.3217 - val_loss: 0.0413 - val_accuracy: 0.4138\nEpoch 263/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0370 - accuracy: 0.3174 - val_loss: 0.0412 - val_accuracy: 0.3966\nEpoch 264/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0369 - accuracy: 0.3174 - val_loss: 0.0413 - val_accuracy: 0.3966\nEpoch 265/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0368 - accuracy: 0.3174 - val_loss: 0.0412 - val_accuracy: 0.4138\nEpoch 266/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0368 - accuracy: 0.3261 - val_loss: 0.0414 - val_accuracy: 0.4138\nEpoch 267/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0368 - accuracy: 0.3217 - val_loss: 0.0412 - val_accuracy: 0.4138\nEpoch 268/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0367 - accuracy: 0.3304 - val_loss: 0.0413 - val_accuracy: 0.3966\nEpoch 269/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0367 - accuracy: 0.3217 - val_loss: 0.0410 - val_accuracy: 0.4138\nEpoch 270/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0366 - accuracy: 0.3174 - val_loss: 0.0411 - val_accuracy: 0.4138\nEpoch 271/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.3304 - val_loss: 0.0411 - val_accuracy: 0.4138\nEpoch 272/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.3304 - val_loss: 0.0411 - val_accuracy: 0.4138\nEpoch 273/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.3261 - val_loss: 0.0411 - val_accuracy: 0.4138\nEpoch 274/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.3217 - val_loss: 0.0409 - val_accuracy: 0.4138\nEpoch 275/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.3261 - val_loss: 0.0409 - val_accuracy: 0.4138\nEpoch 276/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0363 - accuracy: 0.3261 - val_loss: 0.0411 - val_accuracy: 0.4138\nEpoch 277/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0363 - accuracy: 0.3174 - val_loss: 0.0408 - val_accuracy: 0.4138\nEpoch 278/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0362 - accuracy: 0.3217 - val_loss: 0.0408 - val_accuracy: 0.4138\nEpoch 279/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0361 - accuracy: 0.3174 - val_loss: 0.0408 - val_accuracy: 0.3966\nEpoch 280/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0361 - accuracy: 0.3217 - val_loss: 0.0407 - val_accuracy: 0.4138\nEpoch 281/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0361 - accuracy: 0.3261 - val_loss: 0.0407 - val_accuracy: 0.4138\nEpoch 282/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0360 - accuracy: 0.3217 - val_loss: 0.0406 - val_accuracy: 0.3966\nEpoch 283/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0360 - accuracy: 0.3217 - val_loss: 0.0409 - val_accuracy: 0.3966\nEpoch 284/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0360 - accuracy: 0.3348 - val_loss: 0.0407 - val_accuracy: 0.4138\nEpoch 285/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0359 - accuracy: 0.3304 - val_loss: 0.0407 - val_accuracy: 0.4138\nEpoch 286/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0359 - accuracy: 0.3304 - val_loss: 0.0406 - val_accuracy: 0.4138\nEpoch 287/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 0.3261 - val_loss: 0.0406 - val_accuracy: 0.4138\nEpoch 288/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 0.3261 - val_loss: 0.0406 - val_accuracy: 0.4138\nEpoch 289/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0357 - accuracy: 0.3435 - val_loss: 0.0406 - val_accuracy: 0.4138\nEpoch 290/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0357 - accuracy: 0.3304 - val_loss: 0.0406 - val_accuracy: 0.4138\nEpoch 291/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0357 - accuracy: 0.3130 - val_loss: 0.0405 - val_accuracy: 0.3966\nEpoch 292/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0356 - accuracy: 0.3217 - val_loss: 0.0405 - val_accuracy: 0.4138\nEpoch 293/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 0.3261 - val_loss: 0.0405 - val_accuracy: 0.4138\nEpoch 294/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 0.3217 - val_loss: 0.0404 - val_accuracy: 0.3966\nEpoch 295/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 0.3217 - val_loss: 0.0403 - val_accuracy: 0.4138\nEpoch 296/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0354 - accuracy: 0.3304 - val_loss: 0.0405 - val_accuracy: 0.4138\nEpoch 297/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0354 - accuracy: 0.3217 - val_loss: 0.0403 - val_accuracy: 0.3966\nEpoch 298/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0354 - accuracy: 0.3130 - val_loss: 0.0404 - val_accuracy: 0.3966\nEpoch 299/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0353 - accuracy: 0.3217 - val_loss: 0.0403 - val_accuracy: 0.4138\nEpoch 300/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0353 - accuracy: 0.3304 - val_loss: 0.0403 - val_accuracy: 0.3966\nEpoch 301/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0352 - accuracy: 0.3174 - val_loss: 0.0403 - val_accuracy: 0.4138\nEpoch 302/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0352 - accuracy: 0.3261 - val_loss: 0.0403 - val_accuracy: 0.4138\nEpoch 303/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0352 - accuracy: 0.3261 - val_loss: 0.0403 - val_accuracy: 0.3966\nEpoch 304/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0352 - accuracy: 0.3261 - val_loss: 0.0403 - val_accuracy: 0.4138\nEpoch 305/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0351 - accuracy: 0.3217 - val_loss: 0.0402 - val_accuracy: 0.3966\nEpoch 306/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0350 - accuracy: 0.3217 - val_loss: 0.0403 - val_accuracy: 0.4138\nEpoch 307/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0350 - accuracy: 0.3174 - val_loss: 0.0400 - val_accuracy: 0.4138\nEpoch 308/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0350 - accuracy: 0.3043 - val_loss: 0.0400 - val_accuracy: 0.4138\nEpoch 309/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0350 - accuracy: 0.3304 - val_loss: 0.0401 - val_accuracy: 0.4138\nEpoch 310/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0349 - accuracy: 0.3304 - val_loss: 0.0402 - val_accuracy: 0.4138\nEpoch 311/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0349 - accuracy: 0.3217 - val_loss: 0.0401 - val_accuracy: 0.4138\nEpoch 312/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0348 - accuracy: 0.3391 - val_loss: 0.0401 - val_accuracy: 0.4138\nEpoch 313/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0347 - accuracy: 0.3217 - val_loss: 0.0399 - val_accuracy: 0.4138\nEpoch 314/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0348 - accuracy: 0.3261 - val_loss: 0.0400 - val_accuracy: 0.4138\nEpoch 315/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0347 - accuracy: 0.3304 - val_loss: 0.0400 - val_accuracy: 0.3966\nEpoch 316/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0347 - accuracy: 0.3130 - val_loss: 0.0398 - val_accuracy: 0.4138\nEpoch 317/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0347 - accuracy: 0.3435 - val_loss: 0.0400 - val_accuracy: 0.4138\nEpoch 318/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0346 - accuracy: 0.3348 - val_loss: 0.0399 - val_accuracy: 0.3966\nEpoch 319/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0345 - accuracy: 0.3261 - val_loss: 0.0399 - val_accuracy: 0.4138\nEpoch 320/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0346 - accuracy: 0.3304 - val_loss: 0.0400 - val_accuracy: 0.4138\nEpoch 321/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0345 - accuracy: 0.3261 - val_loss: 0.0397 - val_accuracy: 0.4138\nEpoch 322/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0344 - accuracy: 0.3043 - val_loss: 0.0397 - val_accuracy: 0.3966\nEpoch 323/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0344 - accuracy: 0.3348 - val_loss: 0.0399 - val_accuracy: 0.4138\nEpoch 324/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0344 - accuracy: 0.3348 - val_loss: 0.0396 - val_accuracy: 0.4138\nEpoch 325/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0344 - accuracy: 0.3174 - val_loss: 0.0397 - val_accuracy: 0.3966\nEpoch 326/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0343 - accuracy: 0.3087 - val_loss: 0.0397 - val_accuracy: 0.4138\nEpoch 327/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0343 - accuracy: 0.3348 - val_loss: 0.0399 - val_accuracy: 0.4138\nEpoch 328/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0344 - accuracy: 0.3043 - val_loss: 0.0395 - val_accuracy: 0.4138\nEpoch 329/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy: 0.3304 - val_loss: 0.0398 - val_accuracy: 0.3793\nEpoch 330/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy: 0.3435 - val_loss: 0.0398 - val_accuracy: 0.4138\nEpoch 331/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy: 0.3217 - val_loss: 0.0395 - val_accuracy: 0.3793\nEpoch 332/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0341 - accuracy: 0.3261 - val_loss: 0.0397 - val_accuracy: 0.3966\nEpoch 333/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0341 - accuracy: 0.3304 - val_loss: 0.0397 - val_accuracy: 0.4138\nEpoch 334/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0341 - accuracy: 0.3217 - val_loss: 0.0397 - val_accuracy: 0.4138\nEpoch 335/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 0.3217 - val_loss: 0.0395 - val_accuracy: 0.3793\nEpoch 336/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 0.3261 - val_loss: 0.0395 - val_accuracy: 0.4138\nEpoch 337/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 0.3087 - val_loss: 0.0395 - val_accuracy: 0.3966\nEpoch 338/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0339 - accuracy: 0.3304 - val_loss: 0.0396 - val_accuracy: 0.3966\nEpoch 339/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0339 - accuracy: 0.3304 - val_loss: 0.0394 - val_accuracy: 0.4138\nEpoch 340/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0339 - accuracy: 0.3087 - val_loss: 0.0394 - val_accuracy: 0.3621\nEpoch 341/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0338 - accuracy: 0.3348 - val_loss: 0.0395 - val_accuracy: 0.4138\nEpoch 342/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0338 - accuracy: 0.3217 - val_loss: 0.0395 - val_accuracy: 0.4138\nEpoch 343/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0338 - accuracy: 0.3261 - val_loss: 0.0394 - val_accuracy: 0.3793\nEpoch 344/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0337 - accuracy: 0.3304 - val_loss: 0.0395 - val_accuracy: 0.3793\nEpoch 345/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0337 - accuracy: 0.3261 - val_loss: 0.0394 - val_accuracy: 0.3966\nEpoch 346/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0337 - accuracy: 0.3261 - val_loss: 0.0396 - val_accuracy: 0.4138\nEpoch 347/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0337 - accuracy: 0.3391 - val_loss: 0.0393 - val_accuracy: 0.4138\nEpoch 348/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0336 - accuracy: 0.3261 - val_loss: 0.0393 - val_accuracy: 0.3793\nEpoch 349/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0336 - accuracy: 0.3130 - val_loss: 0.0393 - val_accuracy: 0.3621\nEpoch 350/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0336 - accuracy: 0.3130 - val_loss: 0.0393 - val_accuracy: 0.3793\n"
        }
      ],
      "source": [
        "hp_model=ANN.fit(x=X_train,y=y_train, validation_data = (X_test, y_test), epochs=350 ,batch_size = 16)\n",
        "#hp_model=ANN.fit(x=x1_train,y=y1_train, validation_data = (x1_test, y1_test), epochs=100 ,batch_size = 16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "&lt;matplotlib.legend.Legend at 0x7fbfac4cb0a0&gt;"
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "&lt;Figure size 432x288 with 1 Axes&gt;",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 372.103125 248.518125\" width=\"372.103125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 372.103125 248.518125 \nL 372.103125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 224.64 \nL 364.903125 224.64 \nL 364.903125 7.2 \nL 30.103125 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"macad710d71\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.321307\" xlink:href=\"#macad710d71\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(42.140057 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"88.926412\" xlink:href=\"#macad710d71\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 50 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(82.563912 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"132.531518\" xlink:href=\"#macad710d71\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 100 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(122.987768 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"176.136623\" xlink:href=\"#macad710d71\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 150 -->\n      <g transform=\"translate(166.592873 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"219.741729\" xlink:href=\"#macad710d71\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 200 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(210.197979 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"263.346834\" xlink:href=\"#macad710d71\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 250 -->\n      <g transform=\"translate(253.803084 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"306.95194\" xlink:href=\"#macad710d71\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 300 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(297.40819 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"350.557045\" xlink:href=\"#macad710d71\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 350 -->\n      <g transform=\"translate(341.013295 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_9\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m4401e68381\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m4401e68381\" y=\"189.363137\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.1 -->\n      <defs>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n      </defs>\n      <g transform=\"translate(7.2 193.162356)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m4401e68381\" y=\"151.145897\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.2 -->\n      <g transform=\"translate(7.2 154.945116)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m4401e68381\" y=\"112.928657\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.3 -->\n      <g transform=\"translate(7.2 116.727876)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m4401e68381\" y=\"74.711417\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.4 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(7.2 78.510636)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m4401e68381\" y=\"36.494177\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.5 -->\n      <g transform=\"translate(7.2 40.293396)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_14\">\n    <path clip-path=\"url(#pe4d1aaef12)\" d=\"M 45.321307 17.083636 \nL 47.065511 50.229974 \nL 48.809715 77.037484 \nL 50.553919 100.173206 \nL 52.298124 119.963375 \nL 54.042328 136.735771 \nL 55.786532 150.210773 \nL 57.530736 161.798948 \nL 59.274941 170.891257 \nL 60.147043 174.58518 \nL 61.019145 177.789218 \nL 61.891247 180.567325 \nL 63.635451 185.182691 \nL 64.507553 187.020868 \nL 65.379655 188.533866 \nL 66.251757 189.733592 \nL 67.995962 191.551878 \nL 68.868064 192.236377 \nL 70.612268 193.224988 \nL 73.228574 194.246629 \nL 78.461187 195.732346 \nL 87.182208 197.707571 \nL 95.031127 199.434908 \nL 109.856863 202.817962 \nL 115.961578 204.038406 \nL 119.449986 204.689641 \nL 130.787314 206.605212 \nL 134.275722 207.071206 \nL 144.740947 208.144389 \nL 167.415602 209.697526 \nL 176.136623 210.152848 \nL 190.962359 210.82918 \nL 202.299687 211.285548 \nL 249.393201 212.838151 \nL 253.753711 212.948853 \nL 317.417165 214.300259 \nL 323.52188 214.351423 \nL 327.010288 214.451411 \nL 333.115003 214.525325 \nL 345.324433 214.701548 \nL 349.684943 214.751144 \nL 349.684943 214.751144 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_15\">\n    <path clip-path=\"url(#pe4d1aaef12)\" d=\"M 45.321307 23.821852 \nL 47.065511 55.000985 \nL 48.809715 80.787894 \nL 50.553919 103.122698 \nL 52.298124 122.524753 \nL 54.042328 138.500303 \nL 55.786532 151.990078 \nL 57.530736 163.307048 \nL 58.402838 168.070753 \nL 60.147043 175.79936 \nL 61.019145 178.906985 \nL 62.763349 183.993589 \nL 63.635451 186.104841 \nL 64.507553 187.822422 \nL 65.379655 189.247979 \nL 66.251757 190.415022 \nL 67.995962 192.077127 \nL 69.740166 193.231927 \nL 71.48437 194.0153 \nL 74.972779 195.052376 \nL 84.565902 197.276218 \nL 86.310106 197.648197 \nL 94.159025 199.259761 \nL 95.031127 199.404153 \nL 95.903229 199.673369 \nL 96.775331 199.812448 \nL 98.519536 200.351362 \nL 99.391638 200.437642 \nL 108.984761 202.567393 \nL 122.066292 205.069695 \nL 122.938395 205.110153 \nL 126.426803 205.702563 \nL 133.40362 206.689541 \nL 136.019926 206.915208 \nL 136.892028 207.111559 \nL 142.124641 207.547804 \nL 144.740947 207.809663 \nL 146.485152 207.868028 \nL 148.229356 208.054829 \nL 149.101458 208.03696 \nL 150.845662 208.261308 \nL 152.589866 208.300701 \nL 155.206173 208.486357 \nL 156.950377 208.586627 \nL 157.822479 208.699146 \nL 159.566683 208.678248 \nL 161.310887 208.855427 \nL 163.055092 208.873668 \nL 166.5435 209.088445 \nL 168.287704 209.168232 \nL 211.89281 210.569243 \nL 215.381218 210.608014 \nL 217.125422 210.690675 \nL 222.358035 210.779784 \nL 223.230137 210.913396 \nL 224.102239 210.914398 \nL 224.974341 210.79114 \nL 226.718546 210.978406 \nL 230.206954 211.003038 \nL 236.311669 211.20014 \nL 237.183771 211.100627 \nL 238.927975 211.265733 \nL 239.800077 211.199875 \nL 240.672179 211.296204 \nL 242.416384 211.166513 \nL 243.288486 211.309669 \nL 247.648996 211.361143 \nL 254.625813 211.492225 \nL 262.474732 211.658976 \nL 263.346834 211.59139 \nL 264.218936 211.71133 \nL 265.963141 211.630534 \nL 268.579447 211.799839 \nL 269.451549 211.699801 \nL 271.195753 211.760963 \nL 272.067855 211.681203 \nL 273.81206 211.820242 \nL 278.17257 211.782333 \nL 279.044672 211.908902 \nL 281.660979 211.870831 \nL 285.149387 211.891974 \nL 286.021489 212.002468 \nL 287.765693 211.976034 \nL 290.382 212.047946 \nL 291.254102 211.964076 \nL 292.998306 212.029714 \nL 299.103021 212.11132 \nL 300.847225 212.126773 \nL 301.719327 212.182022 \nL 302.591429 212.10634 \nL 303.463531 212.18807 \nL 305.207736 212.194857 \nL 311.31245 212.169579 \nL 312.184552 212.305034 \nL 317.417165 212.313151 \nL 323.52188 212.282578 \nL 325.266084 212.419648 \nL 326.138186 212.340211 \nL 327.88239 212.403706 \nL 339.219718 212.463762 \nL 340.963922 212.506046 \nL 346.196535 212.449446 \nL 347.068637 212.560296 \nL 349.684943 212.567934 \nL 349.684943 212.567934 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 224.64 \nL 30.103125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 364.903125 224.64 \nL 364.903125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 224.64 \nL 364.903125 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 7.2 \nL 364.903125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 302.628125 44.55625 \nL 357.903125 44.55625 \nQ 359.903125 44.55625 359.903125 42.55625 \nL 359.903125 14.2 \nQ 359.903125 12.2 357.903125 12.2 \nL 302.628125 12.2 \nQ 300.628125 12.2 300.628125 14.2 \nL 300.628125 42.55625 \nQ 300.628125 44.55625 302.628125 44.55625 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_16\">\n     <path d=\"M 304.628125 20.298437 \nL 324.628125 20.298437 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_17\"/>\n    <g id=\"text_14\">\n     <!-- train -->\n     <defs>\n      <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n      <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n      <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n      <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n     </defs>\n     <g transform=\"translate(332.628125 23.798437)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-110\"/>\n     </g>\n    </g>\n    <g id=\"line2d_18\">\n     <path d=\"M 304.628125 34.976562 \nL 324.628125 34.976562 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_19\"/>\n    <g id=\"text_15\">\n     <!-- val -->\n     <defs>\n      <path d=\"M 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 8.796875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nL 35.6875 0 \nL 23.484375 0 \nz\n\" id=\"DejaVuSans-118\"/>\n      <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n     </defs>\n     <g transform=\"translate(332.628125 38.476562)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-118\"/>\n      <use x=\"59.179688\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"120.458984\" xlink:href=\"#DejaVuSans-108\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pe4d1aaef12\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"30.103125\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(hp_model.history['loss'],label='loss')\n",
        "plt.plot(hp_model.history['val_loss'],label='val_loss')\n",
        "plt.legend(['train','val'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "&lt;matplotlib.legend.Legend at 0x7fbfaffe3ac0&gt;"
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "&lt;Figure size 432x288 with 1 Axes&gt;",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 372.103125 248.518125\" width=\"372.103125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 372.103125 248.518125 \nL 372.103125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 224.64 \nL 364.903125 224.64 \nL 364.903125 7.2 \nL 30.103125 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m608f08fb43\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.321307\" xlink:href=\"#m608f08fb43\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(42.140057 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"88.926412\" xlink:href=\"#m608f08fb43\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 50 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(82.563912 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"132.531518\" xlink:href=\"#m608f08fb43\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 100 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(122.987768 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"176.136623\" xlink:href=\"#m608f08fb43\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 150 -->\n      <g transform=\"translate(166.592873 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"219.741729\" xlink:href=\"#m608f08fb43\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 200 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(210.197979 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"263.346834\" xlink:href=\"#m608f08fb43\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 250 -->\n      <g transform=\"translate(253.803084 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"306.95194\" xlink:href=\"#m608f08fb43\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 300 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(297.40819 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"350.557045\" xlink:href=\"#m608f08fb43\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 350 -->\n      <g transform=\"translate(341.013295 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_9\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"mdb3841aaa2\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mdb3841aaa2\" y=\"214.756364\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.0 -->\n      <defs>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n      </defs>\n      <g transform=\"translate(7.2 218.555582)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mdb3841aaa2\" y=\"166.985456\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.1 -->\n      <g transform=\"translate(7.2 170.784675)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mdb3841aaa2\" y=\"119.214549\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.2 -->\n      <g transform=\"translate(7.2 123.013767)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mdb3841aaa2\" y=\"71.443641\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.3 -->\n      <g transform=\"translate(7.2 75.24286)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mdb3841aaa2\" y=\"23.672733\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.4 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(7.2 27.471952)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_14\">\n    <path clip-path=\"url(#p67546bc679)\" d=\"M 45.321307 214.756364 \nL 62.763349 214.756364 \nL 63.635451 210.602372 \nL 64.507553 202.294388 \nL 65.379655 198.140397 \nL 67.995962 198.140397 \nL 68.868064 196.0634 \nL 70.612268 196.0634 \nL 72.356472 200.217392 \nL 73.228574 204.371384 \nL 74.100676 206.44838 \nL 74.972779 212.679368 \nL 75.844881 214.756364 \nL 107.240557 214.756364 \nL 108.112659 212.679368 \nL 108.984761 212.679368 \nL 109.856863 210.602372 \nL 110.728965 206.44838 \nL 144.740947 206.44838 \nL 145.613049 204.371384 \nL 146.485152 206.44838 \nL 148.229356 206.44838 \nL 149.101458 204.371384 \nL 149.97356 206.44838 \nL 151.717764 206.44838 \nL 152.589866 204.371384 \nL 153.461968 204.371384 \nL 154.334071 206.44838 \nL 155.206173 206.44838 \nL 156.078275 204.371384 \nL 158.694581 204.371384 \nL 159.566683 181.524429 \nL 160.438785 187.755416 \nL 161.310887 202.294388 \nL 162.18299 166.985455 \nL 163.055092 148.292495 \nL 163.927194 154.523483 \nL 164.799296 152.446485 \nL 165.671398 158.677473 \nL 166.5435 158.677473 \nL 167.415602 125.445535 \nL 168.287704 125.445535 \nL 169.159806 131.676523 \nL 170.904011 131.676523 \nL 171.776113 115.060558 \nL 172.648215 110.906568 \nL 173.520317 115.060558 \nL 174.392419 123.368544 \nL 175.264521 110.906568 \nL 176.136623 90.136606 \nL 177.008725 79.751629 \nL 177.880828 77.67463 \nL 179.625032 81.828627 \nL 180.497134 77.67463 \nL 182.241338 77.67463 \nL 183.11344 81.828627 \nL 183.985542 79.751629 \nL 184.857644 75.597632 \nL 185.729747 73.520634 \nL 186.601849 75.597632 \nL 187.473951 83.905611 \nL 188.346053 77.67463 \nL 190.090257 73.520634 \nL 190.962359 69.366651 \nL 191.834461 75.597632 \nL 192.706563 73.520634 \nL 193.578666 75.597632 \nL 195.32287 67.289653 \nL 196.194972 75.597632 \nL 197.939176 71.443635 \nL 199.68338 71.443635 \nL 201.427584 67.289653 \nL 202.299687 69.366651 \nL 203.171789 69.366651 \nL 204.043891 67.289653 \nL 204.915993 71.443635 \nL 205.788095 73.520634 \nL 206.660197 69.366651 \nL 207.532299 69.366651 \nL 208.404401 71.443635 \nL 209.276503 69.366651 \nL 210.148606 69.366651 \nL 211.020708 71.443635 \nL 211.89281 67.289653 \nL 212.764912 67.289653 \nL 213.637014 69.366651 \nL 214.509116 69.366651 \nL 215.381218 67.289653 \nL 216.25332 69.366651 \nL 217.125422 67.289653 \nL 217.997525 69.366651 \nL 218.869627 63.135656 \nL 219.741729 67.289653 \nL 220.613831 69.366651 \nL 221.485933 69.366651 \nL 222.358035 65.212655 \nL 223.230137 67.289653 \nL 224.102239 67.289653 \nL 225.846444 63.135656 \nL 226.718546 65.212655 \nL 227.590648 63.135656 \nL 228.46275 69.366651 \nL 229.334852 67.289653 \nL 230.206954 61.058658 \nL 231.079056 63.135656 \nL 231.951158 61.058658 \nL 232.82326 61.058658 \nL 233.695363 65.212655 \nL 235.439567 61.058658 \nL 236.311669 65.212655 \nL 237.183771 65.212655 \nL 238.055873 67.289653 \nL 238.927975 67.289653 \nL 239.800077 65.212655 \nL 240.672179 61.058658 \nL 241.544282 58.98166 \nL 243.288486 58.98166 \nL 244.160588 63.135656 \nL 245.03269 61.058658 \nL 245.904792 65.212655 \nL 247.648996 65.212655 \nL 248.521098 61.058658 \nL 250.265303 61.058658 \nL 251.137405 63.135656 \nL 252.009507 61.058658 \nL 252.881609 63.135656 \nL 253.753711 56.904675 \nL 254.625813 56.904675 \nL 255.497915 61.058658 \nL 256.370017 58.98166 \nL 257.24212 58.98166 \nL 258.986324 63.135656 \nL 259.858426 63.135656 \nL 260.730528 61.058658 \nL 262.474732 61.058658 \nL 263.346834 56.904675 \nL 265.091039 56.904675 \nL 266.835243 61.058658 \nL 267.707345 56.904675 \nL 268.579447 67.289653 \nL 269.451549 67.289653 \nL 271.195753 58.98166 \nL 272.067855 63.135656 \nL 272.939958 61.058658 \nL 273.81206 63.135656 \nL 275.556264 63.135656 \nL 276.428366 58.98166 \nL 277.300468 61.058658 \nL 278.17257 56.904675 \nL 279.044672 61.058658 \nL 279.916774 63.135656 \nL 280.788876 56.904675 \nL 281.660979 56.904675 \nL 283.405183 61.058658 \nL 284.277285 58.98166 \nL 285.149387 58.98166 \nL 286.021489 63.135656 \nL 286.893591 61.058658 \nL 287.765693 63.135656 \nL 289.509898 58.98166 \nL 290.382 61.058658 \nL 291.254102 61.058658 \nL 292.126204 54.827677 \nL 292.998306 56.904675 \nL 293.870408 56.904675 \nL 294.74251 58.98166 \nL 295.614612 58.98166 \nL 296.486714 50.67368 \nL 297.358817 56.904675 \nL 298.230919 65.212655 \nL 299.103021 61.058658 \nL 299.975123 58.98166 \nL 300.847225 61.058658 \nL 301.719327 61.058658 \nL 302.591429 56.904675 \nL 304.335633 65.212655 \nL 306.079838 56.904675 \nL 306.95194 63.135656 \nL 307.824042 58.98166 \nL 309.568246 58.98166 \nL 310.440348 61.058658 \nL 311.31245 61.058658 \nL 312.184552 63.135656 \nL 313.056655 69.366651 \nL 313.928757 56.904675 \nL 314.800859 56.904675 \nL 315.672961 61.058658 \nL 316.545063 52.750679 \nL 317.417165 61.058658 \nL 319.161369 56.904675 \nL 320.033471 65.212655 \nL 320.905574 50.67368 \nL 322.649778 58.98166 \nL 323.52188 56.904675 \nL 324.393982 58.98166 \nL 325.266084 69.366651 \nL 326.138186 54.827677 \nL 327.010288 54.827677 \nL 327.88239 63.135656 \nL 328.754493 67.289653 \nL 329.626595 54.827677 \nL 330.498697 69.366651 \nL 331.370799 56.904675 \nL 332.242901 50.67368 \nL 333.115003 61.058658 \nL 334.859207 56.904675 \nL 335.731309 61.058658 \nL 336.603412 61.058658 \nL 337.475514 58.98166 \nL 338.347616 67.289653 \nL 339.219718 56.904675 \nL 340.09182 56.904675 \nL 340.963922 67.289653 \nL 341.836024 54.827677 \nL 342.708126 61.058658 \nL 344.452331 56.904675 \nL 345.324433 58.98166 \nL 346.196535 58.98166 \nL 347.068637 52.750679 \nL 348.812841 65.212655 \nL 349.684943 65.212655 \nL 349.684943 65.212655 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_15\">\n    <path clip-path=\"url(#p67546bc679)\" d=\"M 45.321307 214.756364 \nL 63.635451 214.756364 \nL 64.507553 206.52 \nL 67.995962 206.52 \nL 68.868064 198.283637 \nL 69.740166 198.283637 \nL 70.612268 206.52 \nL 73.228574 206.52 \nL 74.100676 214.756364 \nL 91.542719 214.756364 \nL 92.414821 206.52 \nL 93.286923 214.756364 \nL 94.159025 214.756364 \nL 95.031127 206.52 \nL 95.903229 214.756364 \nL 96.775331 206.52 \nL 97.647433 206.52 \nL 98.519536 214.756364 \nL 99.391638 206.52 \nL 100.26374 206.52 \nL 101.135842 214.756364 \nL 102.007944 206.52 \nL 102.880046 206.52 \nL 103.752148 214.756364 \nL 104.62425 206.52 \nL 106.368455 206.52 \nL 107.240557 214.756364 \nL 108.984761 214.756364 \nL 109.856863 206.52 \nL 111.601067 206.52 \nL 112.473169 214.756364 \nL 113.345271 214.756364 \nL 114.217374 206.52 \nL 158.694581 206.52 \nL 159.566683 173.574546 \nL 160.438785 206.52 \nL 161.310887 198.283637 \nL 162.18299 157.101821 \nL 163.055092 148.865457 \nL 163.927194 173.574546 \nL 164.799296 165.338182 \nL 165.671398 173.574546 \nL 166.5435 148.865457 \nL 167.415602 115.92 \nL 168.287704 148.865457 \nL 169.159806 165.338182 \nL 170.904011 148.865457 \nL 171.776113 107.683639 \nL 172.648215 115.92 \nL 173.520317 107.683639 \nL 174.392419 124.156368 \nL 175.264521 107.683639 \nL 176.136623 74.738182 \nL 177.008725 66.501829 \nL 177.880828 33.556372 \nL 178.75293 74.738182 \nL 179.625032 74.738182 \nL 180.497134 58.265461 \nL 181.369236 66.501829 \nL 182.241338 33.556372 \nL 183.11344 74.738182 \nL 183.985542 41.79274 \nL 184.857644 33.556372 \nL 185.729747 33.556372 \nL 186.601849 41.79274 \nL 187.473951 74.738182 \nL 188.346053 33.556372 \nL 197.939176 33.556372 \nL 198.811278 25.320004 \nL 199.68338 33.556372 \nL 200.555482 33.556372 \nL 201.427584 25.320004 \nL 202.299687 33.556372 \nL 203.171789 25.320004 \nL 204.043891 25.320004 \nL 204.915993 33.556372 \nL 205.788095 17.083636 \nL 206.660197 25.320004 \nL 208.404401 25.320004 \nL 209.276503 17.083636 \nL 210.148606 17.083636 \nL 211.020708 25.320004 \nL 211.89281 17.083636 \nL 212.764912 25.320004 \nL 213.637014 25.320004 \nL 214.509116 17.083636 \nL 215.381218 25.320004 \nL 216.25332 17.083636 \nL 217.125422 17.083636 \nL 217.997525 25.320004 \nL 218.869627 17.083636 \nL 221.485933 17.083636 \nL 222.358035 25.320004 \nL 223.230137 25.320004 \nL 224.102239 17.083636 \nL 227.590648 17.083636 \nL 228.46275 25.320004 \nL 229.334852 17.083636 \nL 268.579447 17.083636 \nL 269.451549 25.320004 \nL 270.323651 25.320004 \nL 271.195753 17.083636 \nL 272.939958 17.083636 \nL 273.81206 25.320004 \nL 274.684162 25.320004 \nL 275.556264 17.083636 \nL 277.300468 17.083636 \nL 278.17257 25.320004 \nL 279.044672 17.083636 \nL 286.893591 17.083636 \nL 287.765693 25.320004 \nL 288.637795 17.083636 \nL 289.509898 17.083636 \nL 290.382 25.320004 \nL 291.254102 25.320004 \nL 292.126204 17.083636 \nL 297.358817 17.083636 \nL 298.230919 25.320004 \nL 299.103021 17.083636 \nL 299.975123 17.083636 \nL 300.847225 25.320004 \nL 301.719327 17.083636 \nL 302.591429 17.083636 \nL 303.463531 25.320004 \nL 304.335633 25.320004 \nL 305.207736 17.083636 \nL 306.079838 25.320004 \nL 306.95194 17.083636 \nL 307.824042 17.083636 \nL 308.696144 25.320004 \nL 309.568246 17.083636 \nL 310.440348 25.320004 \nL 311.31245 17.083636 \nL 318.289267 17.083636 \nL 319.161369 25.320004 \nL 320.033471 17.083636 \nL 320.905574 17.083636 \nL 321.777676 25.320004 \nL 322.649778 17.083636 \nL 324.393982 17.083636 \nL 325.266084 25.320004 \nL 326.138186 17.083636 \nL 327.010288 17.083636 \nL 327.88239 25.320004 \nL 328.754493 17.083636 \nL 330.498697 17.083636 \nL 331.370799 33.556372 \nL 332.242901 17.083636 \nL 333.115003 33.556372 \nL 334.859207 17.083636 \nL 335.731309 17.083636 \nL 336.603412 33.556372 \nL 337.475514 17.083636 \nL 338.347616 25.320004 \nL 339.219718 25.320004 \nL 340.09182 17.083636 \nL 340.963922 41.79274 \nL 341.836024 17.083636 \nL 342.708126 17.083636 \nL 343.580228 33.556372 \nL 344.452331 33.556372 \nL 346.196535 17.083636 \nL 347.068637 17.083636 \nL 347.940739 33.556372 \nL 348.812841 41.79274 \nL 349.684943 33.556372 \nL 349.684943 33.556372 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 224.64 \nL 30.103125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 364.903125 224.64 \nL 364.903125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 224.64 \nL 364.903125 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 7.2 \nL 364.903125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 37.103125 44.55625 \nL 92.378125 44.55625 \nQ 94.378125 44.55625 94.378125 42.55625 \nL 94.378125 14.2 \nQ 94.378125 12.2 92.378125 12.2 \nL 37.103125 12.2 \nQ 35.103125 12.2 35.103125 14.2 \nL 35.103125 42.55625 \nQ 35.103125 44.55625 37.103125 44.55625 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_16\">\n     <path d=\"M 39.103125 20.298437 \nL 59.103125 20.298437 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_17\"/>\n    <g id=\"text_14\">\n     <!-- train -->\n     <defs>\n      <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n      <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n      <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n      <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n     </defs>\n     <g transform=\"translate(67.103125 23.798437)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-110\"/>\n     </g>\n    </g>\n    <g id=\"line2d_18\">\n     <path d=\"M 39.103125 34.976562 \nL 59.103125 34.976562 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_19\"/>\n    <g id=\"text_15\">\n     <!-- val -->\n     <defs>\n      <path d=\"M 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 8.796875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nL 35.6875 0 \nL 23.484375 0 \nz\n\" id=\"DejaVuSans-118\"/>\n      <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n     </defs>\n     <g transform=\"translate(67.103125 38.476562)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-118\"/>\n      <use x=\"59.179688\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"120.458984\" xlink:href=\"#DejaVuSans-108\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p67546bc679\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"30.103125\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(hp_model.history['accuracy'],label='accuracy')\n",
        "plt.plot(hp_model.history['val_accuracy'],label='val_accuracy')\n",
        "plt.legend(['train','val'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "userlist = np.array([[0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "userinputs = pd.DataFrame(data=userlist,columns = df.columns )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "   headphone_name  game_use  travel_use  exercise_use  office_use  \\\n0               0         0           0             0           0   \n1               0         1           0             0           0   \n2               0         0           1             0           0   \n3               0         0           0             1           0   \n4               0         0           0             0           1   \n5               0         0           0             0           0   \n\n   phone_call_use  studio_use  wireless  noise_cancelling  mic_presence  ...  \\\n0               1           0         0                 0             0  ...   \n1               0           0         0                 0             0  ...   \n2               0           0         0                 0             0  ...   \n3               0           0         0                 0             0  ...   \n4               0           0         0                 0             0  ...   \n5               0           1         0                 0             0  ...   \n\n   noise_isolation  microphone_rating  mic_recording_quality  bluetooth  \\\n0                0                  0                      0          0   \n1                0                  0                      0          0   \n2                0                  0                      0          0   \n3                0                  0                      0          0   \n4                0                  0                      0          0   \n5                0                  0                      0          0   \n\n   closed_back  open_back  in_ear  on_ear  over_ear  head_set  \n0            0          0       0       0         0         0  \n1            0          0       0       0         0         0  \n2            0          0       0       0         0         0  \n3            0          0       0       0         0         0  \n4            0          0       0       0         0         0  \n5            0          0       0       0         0         0  \n\n[6 rows x 28 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>headphone_name</th>\n      <th>game_use</th>\n      <th>travel_use</th>\n      <th>exercise_use</th>\n      <th>office_use</th>\n      <th>phone_call_use</th>\n      <th>studio_use</th>\n      <th>wireless</th>\n      <th>noise_cancelling</th>\n      <th>mic_presence</th>\n      <th>...</th>\n      <th>noise_isolation</th>\n      <th>microphone_rating</th>\n      <th>mic_recording_quality</th>\n      <th>bluetooth</th>\n      <th>closed_back</th>\n      <th>open_back</th>\n      <th>in_ear</th>\n      <th>on_ear</th>\n      <th>over_ear</th>\n      <th>head_set</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>6 rows × 28 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "userinputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_pred=userinputs[['travel_use', 'exercise_use', 'office_use',\n",
        "       'phone_call_use', 'studio_use',  'game_use']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "y_pred=ANN.predict(X_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "annpreddf = pd.DataFrame(data=y_pred, columns =y.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "   wireless  noise_cancelling  mic_presence  frequency_response_consistency  \\\n0  0.096270         -0.078872      0.176291                        0.168226   \n1  0.030106         -0.042024      0.039074                        0.135130   \n2  0.200429         -0.071318      0.136129                        0.368717   \n3  0.121782         -0.226634      0.129154                        0.339713   \n4  0.064136          0.018379      0.105476                        0.165565   \n5  0.021707         -0.171379     -0.005968                        0.332237   \n\n   bass_accuracy  mid_accuracy  treble_accuracy  peaks_dips   imaging  \\\n0       0.098831      0.124639         0.156752    0.106362  0.151175   \n1       0.112860      0.147658         0.150999    0.130245  0.191010   \n2       0.162191      0.205057         0.157895    0.213790  0.262588   \n3       0.101716      0.162978         0.168453    0.189239  0.250814   \n4       0.084929      0.128608         0.087785    0.066319  0.109932   \n5       0.085741      0.205185         0.232295    0.199096  0.260928   \n\n   passive_soundstage  ...  noise_isolation  microphone_rating  \\\n0            0.005064  ...         0.094648           0.159382   \n1            0.072013  ...         0.049336           0.015607   \n2           -0.043498  ...         0.177078           0.031364   \n3           -0.013980  ...         0.074625           0.032415   \n4            0.021853  ...         0.120078          -0.031366   \n5           -0.054635  ...         0.066445          -0.053981   \n\n   mic_recording_quality  bluetooth  closed_back  open_back    in_ear  \\\n0               0.127994   0.071718     0.203379   0.000266  0.242804   \n1               0.019078   0.057627     0.122655   0.074602  0.125649   \n2              -0.006719   0.116920     0.216913   0.085184  0.481830   \n3              -0.020423   0.086544     0.140498   0.170947  0.500878   \n4               0.014469   0.070910     0.150686   0.033411  0.189389   \n5              -0.065736   0.071597     0.124259   0.170229  0.422704   \n\n     on_ear  over_ear  head_set  \n0  0.002267 -0.097962  0.005064  \n1 -0.003358  0.055094  0.009502  \n2  0.018573 -0.195522 -0.012810  \n3  0.007302 -0.231616 -0.014367  \n4 -0.017655 -0.085696  0.020397  \n5 -0.023979 -0.098289  0.010685  \n\n[6 rows x 21 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>wireless</th>\n      <th>noise_cancelling</th>\n      <th>mic_presence</th>\n      <th>frequency_response_consistency</th>\n      <th>bass_accuracy</th>\n      <th>mid_accuracy</th>\n      <th>treble_accuracy</th>\n      <th>peaks_dips</th>\n      <th>imaging</th>\n      <th>passive_soundstage</th>\n      <th>...</th>\n      <th>noise_isolation</th>\n      <th>microphone_rating</th>\n      <th>mic_recording_quality</th>\n      <th>bluetooth</th>\n      <th>closed_back</th>\n      <th>open_back</th>\n      <th>in_ear</th>\n      <th>on_ear</th>\n      <th>over_ear</th>\n      <th>head_set</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.096270</td>\n      <td>-0.078872</td>\n      <td>0.176291</td>\n      <td>0.168226</td>\n      <td>0.098831</td>\n      <td>0.124639</td>\n      <td>0.156752</td>\n      <td>0.106362</td>\n      <td>0.151175</td>\n      <td>0.005064</td>\n      <td>...</td>\n      <td>0.094648</td>\n      <td>0.159382</td>\n      <td>0.127994</td>\n      <td>0.071718</td>\n      <td>0.203379</td>\n      <td>0.000266</td>\n      <td>0.242804</td>\n      <td>0.002267</td>\n      <td>-0.097962</td>\n      <td>0.005064</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.030106</td>\n      <td>-0.042024</td>\n      <td>0.039074</td>\n      <td>0.135130</td>\n      <td>0.112860</td>\n      <td>0.147658</td>\n      <td>0.150999</td>\n      <td>0.130245</td>\n      <td>0.191010</td>\n      <td>0.072013</td>\n      <td>...</td>\n      <td>0.049336</td>\n      <td>0.015607</td>\n      <td>0.019078</td>\n      <td>0.057627</td>\n      <td>0.122655</td>\n      <td>0.074602</td>\n      <td>0.125649</td>\n      <td>-0.003358</td>\n      <td>0.055094</td>\n      <td>0.009502</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.200429</td>\n      <td>-0.071318</td>\n      <td>0.136129</td>\n      <td>0.368717</td>\n      <td>0.162191</td>\n      <td>0.205057</td>\n      <td>0.157895</td>\n      <td>0.213790</td>\n      <td>0.262588</td>\n      <td>-0.043498</td>\n      <td>...</td>\n      <td>0.177078</td>\n      <td>0.031364</td>\n      <td>-0.006719</td>\n      <td>0.116920</td>\n      <td>0.216913</td>\n      <td>0.085184</td>\n      <td>0.481830</td>\n      <td>0.018573</td>\n      <td>-0.195522</td>\n      <td>-0.012810</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.121782</td>\n      <td>-0.226634</td>\n      <td>0.129154</td>\n      <td>0.339713</td>\n      <td>0.101716</td>\n      <td>0.162978</td>\n      <td>0.168453</td>\n      <td>0.189239</td>\n      <td>0.250814</td>\n      <td>-0.013980</td>\n      <td>...</td>\n      <td>0.074625</td>\n      <td>0.032415</td>\n      <td>-0.020423</td>\n      <td>0.086544</td>\n      <td>0.140498</td>\n      <td>0.170947</td>\n      <td>0.500878</td>\n      <td>0.007302</td>\n      <td>-0.231616</td>\n      <td>-0.014367</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.064136</td>\n      <td>0.018379</td>\n      <td>0.105476</td>\n      <td>0.165565</td>\n      <td>0.084929</td>\n      <td>0.128608</td>\n      <td>0.087785</td>\n      <td>0.066319</td>\n      <td>0.109932</td>\n      <td>0.021853</td>\n      <td>...</td>\n      <td>0.120078</td>\n      <td>-0.031366</td>\n      <td>0.014469</td>\n      <td>0.070910</td>\n      <td>0.150686</td>\n      <td>0.033411</td>\n      <td>0.189389</td>\n      <td>-0.017655</td>\n      <td>-0.085696</td>\n      <td>0.020397</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.021707</td>\n      <td>-0.171379</td>\n      <td>-0.005968</td>\n      <td>0.332237</td>\n      <td>0.085741</td>\n      <td>0.205185</td>\n      <td>0.232295</td>\n      <td>0.199096</td>\n      <td>0.260928</td>\n      <td>-0.054635</td>\n      <td>...</td>\n      <td>0.066445</td>\n      <td>-0.053981</td>\n      <td>-0.065736</td>\n      <td>0.071597</td>\n      <td>0.124259</td>\n      <td>0.170229</td>\n      <td>0.422704</td>\n      <td>-0.023979</td>\n      <td>-0.098289</td>\n      <td>0.010685</td>\n    </tr>\n  </tbody>\n</table>\n<p>6 rows × 21 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "annpreddf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "KNN = KNeighborsRegressor(n_neighbors=6,weights='distance',algorithm='brute')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "KNeighborsRegressor(algorithm=&#39;brute&#39;, n_neighbors=6, weights=&#39;distance&#39;)"
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "KNN.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "0.6166551223074017"
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "KNN.score(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "knny_pred = KNN.predict(X_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "knnpreddf = pd.DataFrame(data=knny_pred, columns =y.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "   wireless  noise_cancelling  mic_presence  frequency_response_consistency  \\\n0       1.0               0.0           1.0                        0.427420   \n1       1.0               0.0           1.0                        0.423909   \n2       1.0               0.0           1.0                        0.428327   \n3       1.0               0.0           1.0                        0.426560   \n4       1.0               0.0           1.0                        0.427755   \n5       1.0               0.0           1.0                        0.521641   \n\n   bass_accuracy  mid_accuracy  treble_accuracy  peaks_dips   imaging  \\\n0       0.139898      0.475511         0.527918    0.298694  0.488387   \n1       0.139596      0.475735         0.525522    0.297897  0.484787   \n2       0.140584      0.477280         0.527551    0.300490  0.490503   \n3       0.139751      0.476072         0.527801    0.298775  0.488947   \n4       0.140539      0.476969         0.527331    0.300184  0.489745   \n5       0.152819      0.554869         0.549754    0.402375  0.587310   \n\n   passive_soundstage  ...  noise_isolation  microphone_rating  \\\n0            0.306869  ...         0.313004           0.605833   \n1            0.308819  ...         0.309702           0.604500   \n2            0.306230  ...         0.315054           0.605038   \n3            0.306856  ...         0.312431           0.605178   \n4            0.306770  ...         0.314601           0.605071   \n5            0.259278  ...         0.327028           0.608699   \n\n   mic_recording_quality  bluetooth  closed_back  open_back    in_ear  on_ear  \\\n0               0.644754   0.826144     0.840576   0.159424  0.493958     0.0   \n1               0.644192   0.826205     0.842678   0.157322  0.490954     0.0   \n2               0.643782   0.825338     0.841950   0.158050  0.496908     0.0   \n3               0.644160   0.825976     0.841433   0.158567  0.495062     0.0   \n4               0.643849   0.825477     0.841284   0.158716  0.495761     0.0   \n5               0.651203   0.794842     1.000000   0.000000  0.655223     0.0   \n\n   over_ear  head_set  \n0       0.0  0.346618  \n1       0.0  0.351725  \n2       0.0  0.345042  \n3       0.0  0.346372  \n4       0.0  0.345523  \n5       0.0  0.344777  \n\n[6 rows x 21 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>wireless</th>\n      <th>noise_cancelling</th>\n      <th>mic_presence</th>\n      <th>frequency_response_consistency</th>\n      <th>bass_accuracy</th>\n      <th>mid_accuracy</th>\n      <th>treble_accuracy</th>\n      <th>peaks_dips</th>\n      <th>imaging</th>\n      <th>passive_soundstage</th>\n      <th>...</th>\n      <th>noise_isolation</th>\n      <th>microphone_rating</th>\n      <th>mic_recording_quality</th>\n      <th>bluetooth</th>\n      <th>closed_back</th>\n      <th>open_back</th>\n      <th>in_ear</th>\n      <th>on_ear</th>\n      <th>over_ear</th>\n      <th>head_set</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.427420</td>\n      <td>0.139898</td>\n      <td>0.475511</td>\n      <td>0.527918</td>\n      <td>0.298694</td>\n      <td>0.488387</td>\n      <td>0.306869</td>\n      <td>...</td>\n      <td>0.313004</td>\n      <td>0.605833</td>\n      <td>0.644754</td>\n      <td>0.826144</td>\n      <td>0.840576</td>\n      <td>0.159424</td>\n      <td>0.493958</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.346618</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.423909</td>\n      <td>0.139596</td>\n      <td>0.475735</td>\n      <td>0.525522</td>\n      <td>0.297897</td>\n      <td>0.484787</td>\n      <td>0.308819</td>\n      <td>...</td>\n      <td>0.309702</td>\n      <td>0.604500</td>\n      <td>0.644192</td>\n      <td>0.826205</td>\n      <td>0.842678</td>\n      <td>0.157322</td>\n      <td>0.490954</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.351725</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.428327</td>\n      <td>0.140584</td>\n      <td>0.477280</td>\n      <td>0.527551</td>\n      <td>0.300490</td>\n      <td>0.490503</td>\n      <td>0.306230</td>\n      <td>...</td>\n      <td>0.315054</td>\n      <td>0.605038</td>\n      <td>0.643782</td>\n      <td>0.825338</td>\n      <td>0.841950</td>\n      <td>0.158050</td>\n      <td>0.496908</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.345042</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.426560</td>\n      <td>0.139751</td>\n      <td>0.476072</td>\n      <td>0.527801</td>\n      <td>0.298775</td>\n      <td>0.488947</td>\n      <td>0.306856</td>\n      <td>...</td>\n      <td>0.312431</td>\n      <td>0.605178</td>\n      <td>0.644160</td>\n      <td>0.825976</td>\n      <td>0.841433</td>\n      <td>0.158567</td>\n      <td>0.495062</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.346372</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.427755</td>\n      <td>0.140539</td>\n      <td>0.476969</td>\n      <td>0.527331</td>\n      <td>0.300184</td>\n      <td>0.489745</td>\n      <td>0.306770</td>\n      <td>...</td>\n      <td>0.314601</td>\n      <td>0.605071</td>\n      <td>0.643849</td>\n      <td>0.825477</td>\n      <td>0.841284</td>\n      <td>0.158716</td>\n      <td>0.495761</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.345523</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.521641</td>\n      <td>0.152819</td>\n      <td>0.554869</td>\n      <td>0.549754</td>\n      <td>0.402375</td>\n      <td>0.587310</td>\n      <td>0.259278</td>\n      <td>...</td>\n      <td>0.327028</td>\n      <td>0.608699</td>\n      <td>0.651203</td>\n      <td>0.794842</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.655223</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.344777</td>\n    </tr>\n  </tbody>\n</table>\n<p>6 rows × 21 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "knnpreddf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "RF = RandomForestRegressor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "RandomForestRegressor()"
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "RF.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "0.5886879251928663"
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "RF.score(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "rf_pred = RF.predict(X_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "rfpreddf = pd.DataFrame(data=rf_pred, columns =y.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "   wireless  noise_cancelling  mic_presence  frequency_response_consistency  \\\n0      0.12              0.07          0.88                        0.220000   \n1      0.04              0.00          0.04                        0.478511   \n2      0.04              0.00          0.04                        0.491277   \n3      0.76              0.00          0.76                        0.507660   \n4      0.04              0.00          0.04                        0.485106   \n5      0.03              0.00          0.03                        0.492128   \n\n   bass_accuracy  mid_accuracy  treble_accuracy  peaks_dips   imaging  \\\n0       0.581839      0.600408         0.491235    0.395111  0.748421   \n1       0.645977      0.852653         0.567901    0.613333  0.874526   \n2       0.671494      0.836735         0.521975    0.584667  0.875263   \n3       0.211724      0.611020         0.540123    0.300444  0.365474   \n4       0.658506      0.845306         0.549877    0.597778  0.892000   \n5       0.686552      0.867755         0.667654    0.640000  0.881263   \n\n   passive_soundstage  ...  noise_isolation  microphone_rating  \\\n0            0.568667  ...         0.391383           0.803146   \n1            0.651778  ...         0.280638           0.018427   \n2            0.477000  ...         0.429043           0.019101   \n3            0.338444  ...         0.128830           0.481573   \n4            0.523000  ...         0.393830           0.021798   \n5            0.719667  ...         0.236170           0.014944   \n\n   mic_recording_quality  bluetooth  closed_back  open_back  in_ear  on_ear  \\\n0               0.788222   0.110000         0.77       0.23    0.11     0.0   \n1               0.023111   0.030909         0.31       0.24    0.22     0.0   \n2               0.021222   0.030682         0.62       0.07    0.40     0.0   \n3               0.495000   0.679432         0.86       0.08    0.29     0.0   \n4               0.019222   0.030114         0.52       0.10    0.35     0.0   \n5               0.016667   0.024432         0.20       0.30    0.13     0.0   \n\n   over_ear  head_set  \n0      0.77      0.07  \n1      0.74      0.04  \n2      0.57      0.03  \n3      0.12      0.58  \n4      0.64      0.01  \n5      0.84      0.03  \n\n[6 rows x 21 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>wireless</th>\n      <th>noise_cancelling</th>\n      <th>mic_presence</th>\n      <th>frequency_response_consistency</th>\n      <th>bass_accuracy</th>\n      <th>mid_accuracy</th>\n      <th>treble_accuracy</th>\n      <th>peaks_dips</th>\n      <th>imaging</th>\n      <th>passive_soundstage</th>\n      <th>...</th>\n      <th>noise_isolation</th>\n      <th>microphone_rating</th>\n      <th>mic_recording_quality</th>\n      <th>bluetooth</th>\n      <th>closed_back</th>\n      <th>open_back</th>\n      <th>in_ear</th>\n      <th>on_ear</th>\n      <th>over_ear</th>\n      <th>head_set</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.12</td>\n      <td>0.07</td>\n      <td>0.88</td>\n      <td>0.220000</td>\n      <td>0.581839</td>\n      <td>0.600408</td>\n      <td>0.491235</td>\n      <td>0.395111</td>\n      <td>0.748421</td>\n      <td>0.568667</td>\n      <td>...</td>\n      <td>0.391383</td>\n      <td>0.803146</td>\n      <td>0.788222</td>\n      <td>0.110000</td>\n      <td>0.77</td>\n      <td>0.23</td>\n      <td>0.11</td>\n      <td>0.0</td>\n      <td>0.77</td>\n      <td>0.07</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.04</td>\n      <td>0.00</td>\n      <td>0.04</td>\n      <td>0.478511</td>\n      <td>0.645977</td>\n      <td>0.852653</td>\n      <td>0.567901</td>\n      <td>0.613333</td>\n      <td>0.874526</td>\n      <td>0.651778</td>\n      <td>...</td>\n      <td>0.280638</td>\n      <td>0.018427</td>\n      <td>0.023111</td>\n      <td>0.030909</td>\n      <td>0.31</td>\n      <td>0.24</td>\n      <td>0.22</td>\n      <td>0.0</td>\n      <td>0.74</td>\n      <td>0.04</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.04</td>\n      <td>0.00</td>\n      <td>0.04</td>\n      <td>0.491277</td>\n      <td>0.671494</td>\n      <td>0.836735</td>\n      <td>0.521975</td>\n      <td>0.584667</td>\n      <td>0.875263</td>\n      <td>0.477000</td>\n      <td>...</td>\n      <td>0.429043</td>\n      <td>0.019101</td>\n      <td>0.021222</td>\n      <td>0.030682</td>\n      <td>0.62</td>\n      <td>0.07</td>\n      <td>0.40</td>\n      <td>0.0</td>\n      <td>0.57</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.76</td>\n      <td>0.00</td>\n      <td>0.76</td>\n      <td>0.507660</td>\n      <td>0.211724</td>\n      <td>0.611020</td>\n      <td>0.540123</td>\n      <td>0.300444</td>\n      <td>0.365474</td>\n      <td>0.338444</td>\n      <td>...</td>\n      <td>0.128830</td>\n      <td>0.481573</td>\n      <td>0.495000</td>\n      <td>0.679432</td>\n      <td>0.86</td>\n      <td>0.08</td>\n      <td>0.29</td>\n      <td>0.0</td>\n      <td>0.12</td>\n      <td>0.58</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.04</td>\n      <td>0.00</td>\n      <td>0.04</td>\n      <td>0.485106</td>\n      <td>0.658506</td>\n      <td>0.845306</td>\n      <td>0.549877</td>\n      <td>0.597778</td>\n      <td>0.892000</td>\n      <td>0.523000</td>\n      <td>...</td>\n      <td>0.393830</td>\n      <td>0.021798</td>\n      <td>0.019222</td>\n      <td>0.030114</td>\n      <td>0.52</td>\n      <td>0.10</td>\n      <td>0.35</td>\n      <td>0.0</td>\n      <td>0.64</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.03</td>\n      <td>0.00</td>\n      <td>0.03</td>\n      <td>0.492128</td>\n      <td>0.686552</td>\n      <td>0.867755</td>\n      <td>0.667654</td>\n      <td>0.640000</td>\n      <td>0.881263</td>\n      <td>0.719667</td>\n      <td>...</td>\n      <td>0.236170</td>\n      <td>0.014944</td>\n      <td>0.016667</td>\n      <td>0.024432</td>\n      <td>0.20</td>\n      <td>0.30</td>\n      <td>0.13</td>\n      <td>0.0</td>\n      <td>0.84</td>\n      <td>0.03</td>\n    </tr>\n  </tbody>\n</table>\n<p>6 rows × 21 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "rfpreddf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "rfdf = pd.DataFrame(columns = ['game_use', 'travel_use', 'exercise_use',\n",
        "       'office_use', 'phone_call_use', 'studio_use', 'wireless',\n",
        "       'noise_cancelling', 'mic_presence', 'frequency_response_consistency',\n",
        "       'bass_accuracy', 'mid_accuracy', 'treble_accuracy', 'peaks_dips',\n",
        "       'imaging', 'passive_soundstage', 'weighted_harmonic_distortion',\n",
        "       'noise_isolation', 'microphone_rating', 'mic_recording_quality',\n",
        "       'bluetooth', 'closed_back', 'open_back', 'in_ear', 'on_ear', 'over_ear',\n",
        "       'head_set'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "rfdf[['game_use', 'travel_use', 'exercise_use',\n",
        "       'office_use', 'phone_call_use', 'studio_use']] = X_pred[['game_use', 'travel_use', 'exercise_use',\n",
        "       'office_use', 'phone_call_use', 'studio_use']]\n",
        "rfdf[['wireless',\n",
        "       'noise_cancelling', 'mic_presence', 'frequency_response_consistency',\n",
        "       'bass_accuracy', 'mid_accuracy', 'treble_accuracy', 'peaks_dips',\n",
        "       'imaging', 'passive_soundstage', 'weighted_harmonic_distortion',\n",
        "       'noise_isolation', 'microphone_rating', 'mic_recording_quality',\n",
        "       'bluetooth', 'closed_back', 'open_back', 'in_ear', 'on_ear', 'over_ear',\n",
        "       'head_set']] = rfpreddf[['wireless',\n",
        "       'noise_cancelling', 'mic_presence', 'frequency_response_consistency',\n",
        "       'bass_accuracy', 'mid_accuracy', 'treble_accuracy', 'peaks_dips',\n",
        "       'imaging', 'passive_soundstage', 'weighted_harmonic_distortion',\n",
        "       'noise_isolation', 'microphone_rating', 'mic_recording_quality',\n",
        "       'bluetooth', 'closed_back', 'open_back', 'in_ear', 'on_ear', 'over_ear',\n",
        "       'head_set']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "   game_use  travel_use  exercise_use  office_use  phone_call_use  studio_use  \\\n0         0           0             0           0               1           0   \n1         1           0             0           0               0           0   \n2         0           1             0           0               0           0   \n3         0           0             1           0               0           0   \n4         0           0             0           1               0           0   \n5         0           0             0           0               0           1   \n\n   wireless  noise_cancelling  mic_presence  frequency_response_consistency  \\\n0      0.12              0.07          0.88                        0.220000   \n1      0.04              0.00          0.04                        0.478511   \n2      0.04              0.00          0.04                        0.491277   \n3      0.76              0.00          0.76                        0.507660   \n4      0.04              0.00          0.04                        0.485106   \n5      0.03              0.00          0.03                        0.492128   \n\n   ...  noise_isolation  microphone_rating  mic_recording_quality  bluetooth  \\\n0  ...         0.391383           0.803146               0.788222   0.110000   \n1  ...         0.280638           0.018427               0.023111   0.030909   \n2  ...         0.429043           0.019101               0.021222   0.030682   \n3  ...         0.128830           0.481573               0.495000   0.679432   \n4  ...         0.393830           0.021798               0.019222   0.030114   \n5  ...         0.236170           0.014944               0.016667   0.024432   \n\n   closed_back  open_back  in_ear  on_ear  over_ear  head_set  \n0         0.77       0.23    0.11     0.0      0.77      0.07  \n1         0.31       0.24    0.22     0.0      0.74      0.04  \n2         0.62       0.07    0.40     0.0      0.57      0.03  \n3         0.86       0.08    0.29     0.0      0.12      0.58  \n4         0.52       0.10    0.35     0.0      0.64      0.01  \n5         0.20       0.30    0.13     0.0      0.84      0.03  \n\n[6 rows x 27 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>game_use</th>\n      <th>travel_use</th>\n      <th>exercise_use</th>\n      <th>office_use</th>\n      <th>phone_call_use</th>\n      <th>studio_use</th>\n      <th>wireless</th>\n      <th>noise_cancelling</th>\n      <th>mic_presence</th>\n      <th>frequency_response_consistency</th>\n      <th>...</th>\n      <th>noise_isolation</th>\n      <th>microphone_rating</th>\n      <th>mic_recording_quality</th>\n      <th>bluetooth</th>\n      <th>closed_back</th>\n      <th>open_back</th>\n      <th>in_ear</th>\n      <th>on_ear</th>\n      <th>over_ear</th>\n      <th>head_set</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.12</td>\n      <td>0.07</td>\n      <td>0.88</td>\n      <td>0.220000</td>\n      <td>...</td>\n      <td>0.391383</td>\n      <td>0.803146</td>\n      <td>0.788222</td>\n      <td>0.110000</td>\n      <td>0.77</td>\n      <td>0.23</td>\n      <td>0.11</td>\n      <td>0.0</td>\n      <td>0.77</td>\n      <td>0.07</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.04</td>\n      <td>0.00</td>\n      <td>0.04</td>\n      <td>0.478511</td>\n      <td>...</td>\n      <td>0.280638</td>\n      <td>0.018427</td>\n      <td>0.023111</td>\n      <td>0.030909</td>\n      <td>0.31</td>\n      <td>0.24</td>\n      <td>0.22</td>\n      <td>0.0</td>\n      <td>0.74</td>\n      <td>0.04</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.04</td>\n      <td>0.00</td>\n      <td>0.04</td>\n      <td>0.491277</td>\n      <td>...</td>\n      <td>0.429043</td>\n      <td>0.019101</td>\n      <td>0.021222</td>\n      <td>0.030682</td>\n      <td>0.62</td>\n      <td>0.07</td>\n      <td>0.40</td>\n      <td>0.0</td>\n      <td>0.57</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.76</td>\n      <td>0.00</td>\n      <td>0.76</td>\n      <td>0.507660</td>\n      <td>...</td>\n      <td>0.128830</td>\n      <td>0.481573</td>\n      <td>0.495000</td>\n      <td>0.679432</td>\n      <td>0.86</td>\n      <td>0.08</td>\n      <td>0.29</td>\n      <td>0.0</td>\n      <td>0.12</td>\n      <td>0.58</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.04</td>\n      <td>0.00</td>\n      <td>0.04</td>\n      <td>0.485106</td>\n      <td>...</td>\n      <td>0.393830</td>\n      <td>0.021798</td>\n      <td>0.019222</td>\n      <td>0.030114</td>\n      <td>0.52</td>\n      <td>0.10</td>\n      <td>0.35</td>\n      <td>0.0</td>\n      <td>0.64</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.03</td>\n      <td>0.00</td>\n      <td>0.03</td>\n      <td>0.492128</td>\n      <td>...</td>\n      <td>0.236170</td>\n      <td>0.014944</td>\n      <td>0.016667</td>\n      <td>0.024432</td>\n      <td>0.20</td>\n      <td>0.30</td>\n      <td>0.13</td>\n      <td>0.0</td>\n      <td>0.84</td>\n      <td>0.03</td>\n    </tr>\n  </tbody>\n</table>\n<p>6 rows × 27 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "rfdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "randomdf = rfdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "LR = LinearRegression()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "LinearRegression()"
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "LR.fit(x1_train,y1_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "0.9156168267307402"
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "LR.score(x1_test,y1_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "randomdf[['game_use', 'travel_use', 'exercise_use',\n",
        "       'office_use', 'phone_call_use', 'studio_use']]=LR.predict(rfpreddf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "knnhpx=df[['travel_use', 'exercise_use', 'office_use',\n",
        "       'phone_call_use', 'studio_use', 'game_use', 'wireless', 'noise_cancelling',\n",
        "       'mic_presence', 'frequency_response_consistency', 'bass_accuracy',\n",
        "       'mid_accuracy', 'treble_accuracy', 'peaks_dips', 'imaging',\n",
        "       'passive_soundstage', 'weighted_harmonic_distortion', 'noise_isolation',\n",
        "       'microphone_rating', 'mic_recording_quality', 'bluetooth',\n",
        "       'closed_back', 'open_back', 'in_ear', 'on_ear', 'over_ear', 'head_set']]\n",
        "knnhpy=df['headphone_name']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "288"
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "len(knnhpy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "knnhp = KNeighborsRegressor(n_neighbors=288,weights='distance')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "KNeighborsRegressor(n_neighbors=288, weights=&#39;distance&#39;)"
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "knnhp.fit(knnhpx,knnhpy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "targets = knnhp.predict(randomdf).round()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([143., 139., 141., 146., 140., 138.])"
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "    headphone_name  game_use  travel_use  exercise_use  office_use  \\\n96             143       5.7    0.888889      0.945946         0.8   \n\n    phone_call_use  studio_use  wireless  noise_cancelling  mic_presence  ...  \\\n96        0.815385       0.575         1                 0             1  ...   \n\n    noise_isolation  microphone_rating  mic_recording_quality  bluetooth  \\\n96         0.734043           0.741573               0.777778   0.897727   \n\n    closed_back  open_back  in_ear  on_ear  over_ear  head_set  \n96            1          0       1       0         0         0  \n\n[1 rows x 28 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>headphone_name</th>\n      <th>game_use</th>\n      <th>travel_use</th>\n      <th>exercise_use</th>\n      <th>office_use</th>\n      <th>phone_call_use</th>\n      <th>studio_use</th>\n      <th>wireless</th>\n      <th>noise_cancelling</th>\n      <th>mic_presence</th>\n      <th>...</th>\n      <th>noise_isolation</th>\n      <th>microphone_rating</th>\n      <th>mic_recording_quality</th>\n      <th>bluetooth</th>\n      <th>closed_back</th>\n      <th>open_back</th>\n      <th>in_ear</th>\n      <th>on_ear</th>\n      <th>over_ear</th>\n      <th>head_set</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>96</th>\n      <td>143</td>\n      <td>5.7</td>\n      <td>0.888889</td>\n      <td>0.945946</td>\n      <td>0.8</td>\n      <td>0.815385</td>\n      <td>0.575</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.734043</td>\n      <td>0.741573</td>\n      <td>0.777778</td>\n      <td>0.897727</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 28 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "#Attempting to pull target info from target identified \n",
        "df.loc[df['headphone_name'] == targets[0]]"
      ]
    }
  ]
}