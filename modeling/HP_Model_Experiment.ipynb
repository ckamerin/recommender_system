{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF2.0 Recommender System.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python_defaultSpec_1601346456078",
      "display_name": "Python 3.8.5 64-bit ('rec_sys': conda)"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "2.3.0\n"
        }
      ],
      "source": [
        "\n",
        "#Check TF version\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Default GPU Device:/device:GPU:0\n"
        }
      ],
      "source": [
        "# Is GPU enabled\n",
        "if tf.test.gpu_device_name():\n",
        "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
        "else:\n",
        "    print(\"Fix it\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmO5csZi7cdr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, Flatten, \\\n",
        "  Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.multioutput import RegressorChain\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import plot_roc_curve\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os \n",
        "import earthpy as et "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Code needed to set a new working directory\n",
        "\n",
        "#my_path = os.path.join(et.io.HOME, 'recommender_system')\n",
        "#os.mkdir(my_path)\n",
        "\n",
        "## Set Working Directory\n",
        "os.chdir(os.path.join(\"/home/ckamerin/Documents/GitHub\", 'recommender_system'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "'/home/ckamerin/Documents/GitHub/recommender_system'"
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Check if it worked\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6h0pEt_7lZC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4a410b48-1608-4ea0-b7d5-5bcf12ea065a"
      },
      "source": [
        "# Data Import\n",
        "df = pd.read_csv(\"/home/ckamerin/Desktop/headphone_df_cleaned.csv\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "df = df.drop(columns='Unnamed: 0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "Index(['headphone_name', 'game_use', 'travel_use', 'exercise_use',\n       'office_use', 'phone_call_use', 'studio_use', 'wireless',\n       'noise_cancelling', 'mic_presence', 'frequency_response_consistency',\n       'bass_accuracy', 'mid_accuracy', 'treble_accuracy', 'peaks_dips',\n       'imaging', 'passive_soundstage', 'weighted_harmonic_distortion',\n       'noise_isolation', 'microphone_rating', 'mic_recording_quality',\n       'bluetooth', 'closed_back', 'open_back', 'in_ear', 'on_ear', 'over_ear',\n       'head_set'],\n      dtype='object')"
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "X=df[['travel_use', 'exercise_use', 'office_use',\n",
        "       'phone_call_use', 'studio_use', 'game_use']]\n",
        "y=df[[ 'wireless', 'noise_cancelling',\n",
        "       'mic_presence', 'frequency_response_consistency', 'bass_accuracy',\n",
        "       'mid_accuracy', 'treble_accuracy', 'peaks_dips', 'imaging',\n",
        "       'passive_soundstage', 'weighted_harmonic_distortion', 'noise_isolation',\n",
        "       'microphone_rating', 'mic_recording_quality', 'bluetooth',\n",
        "       'closed_back', 'open_back', 'in_ear', 'on_ear', 'over_ear', 'head_set']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        " X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "x1_train, x1_test, y1_train, y1_test = y_train, y_test, X_train, X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Put models in a dictionary\n",
        "models = {\"KNN\": KNeighborsRegressor(),\n",
        "          'KNN Multi' : MultiOutputRegressor(KNeighborsRegressor()),\n",
        "          \"Random Forest\": RandomForestRegressor(),\n",
        "          \"Random Forest Multi\": MultiOutputRegressor(RandomForestRegressor()),\n",
        "          \"Linear Regression\": LinearRegression(),\n",
        "          \"Linear Regression Multi\": MultiOutputRegressor(LinearRegression()),\n",
        "          'Decision Tree Regression': DecisionTreeRegressor(),\n",
        "          'Decision Tree Multi': MultiOutputRegressor(DecisionTreeRegressor()),\n",
        "          'Ridge Regressor Chain': RegressorChain(Ridge()),\n",
        "          'Ridge Regresor Multioutput': MultiOutputRegressor(Ridge())\n",
        "          }\n",
        "# Create function to fit and score models\n",
        "def fit_and_score(models, X_train, X_test, y_train, y_test):\n",
        "    \"\"\"\n",
        "    Fits and evaluates given machine learning models.\n",
        "    models : a dict of different Scikit-Learn machine learning models\n",
        "    X_train : training data\n",
        "    X_test : testing data\n",
        "    y_train : labels assosciated with training data\n",
        "    y_test : labels assosciated with test data\n",
        "    \"\"\"\n",
        "    # Random seed for reproducible results\n",
        "    np.random.seed(42)\n",
        "    # Make a list to keep model scores\n",
        "    model_scores = {}\n",
        "    # Loop through models\n",
        "    for name, model in models.items():\n",
        "        # Fit the model to the data\n",
        "        model.fit(X_train, y_train)\n",
        "        # Evaluate the model and append its score to model_scores\n",
        "        model_scores[name] = model.score(X_test, y_test)\n",
        "    return model_scores\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'KNN': 0.6089214434032404,\n 'KNN Multi': 0.6089214434032404,\n 'Random Forest': 0.6293297200585716,\n 'Random Forest Multi': 0.592364859836228,\n 'Linear Regression': 0.5186904551760366,\n 'Linear Regression Multi': 0.5186904551760367,\n 'Decision Tree Regression': 0.3693288209466513,\n 'Decision Tree Multi': 0.3630628683084099,\n 'Ridge Regressor Chain': 0.5182188732859243,\n 'Ridge Regresor Multioutput': 0.5182188732859243}"
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "#Test all models on one dataset\n",
        "model_scores = fit_and_score(models=models,\n",
        "                             X_train=X_train,\n",
        "                             X_test=X_test,\n",
        "                             y_train=y_train,\n",
        "                             y_test=y_test)\n",
        "model_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'KNN': 0.9011894872845104,\n 'KNN Multi': 0.9011894872845104,\n 'Random Forest': 0.8809325609291401,\n 'Random Forest Multi': 0.9328052756457968,\n 'Linear Regression': 0.9273341333653701,\n 'Linear Regression Multi': 0.9273341333653701,\n 'Decision Tree Regression': 0.7292913775028466,\n 'Decision Tree Multi': 0.8741505650247628,\n 'Ridge Regressor Chain': 0.9297809375844456,\n 'Ridge Regresor Multioutput': 0.9297809375844456}"
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "model_scores = fit_and_score(models=models,\n",
        "                             X_train=x1_train,\n",
        "                             X_test=x1_test,\n",
        "                             y_train=y1_train,\n",
        "                             y_test=y1_test)\n",
        "model_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "ANN = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(108, input_dim = 6, activation='relu'),\n",
        "  #tf.keras.layers.Dropout(.1),\n",
        "  tf.keras.layers.Dense(256, activation='relu'),\n",
        "  #tf.keras.layers.Dropout(.1),\n",
        "  tf.keras.layers.Dense(512, activation='relu'),\n",
        "  #tf.keras.layers.Dropout(.1),\n",
        "  tf.keras.layers.Dense(256, activation='relu'),\n",
        "  #tf.keras.layers.Dropout(.1),\n",
        "  tf.keras.layers.Dense(21, activation= 'linear')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "opt = tf.keras.optimizers.Adam(.00001)\n",
        "mae = tf.keras.losses.MeanAbsoluteError()\n",
        "ANN.compile(optimizer=opt,metrics=['accuracy'],loss='mse')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "tags": [
          "outputPrepend"
        ]
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[==============================] - 0s 3ms/step - loss: 0.0406 - accuracy: 0.3087 - val_loss: 0.0468 - val_accuracy: 0.2069\nEpoch 212/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0405 - accuracy: 0.3217 - val_loss: 0.0468 - val_accuracy: 0.2069\nEpoch 213/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0404 - accuracy: 0.3261 - val_loss: 0.0468 - val_accuracy: 0.2069\nEpoch 214/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0404 - accuracy: 0.3261 - val_loss: 0.0467 - val_accuracy: 0.2069\nEpoch 215/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0403 - accuracy: 0.3174 - val_loss: 0.0466 - val_accuracy: 0.2069\nEpoch 216/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0402 - accuracy: 0.3174 - val_loss: 0.0465 - val_accuracy: 0.2414\nEpoch 217/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0402 - accuracy: 0.3130 - val_loss: 0.0463 - val_accuracy: 0.2069\nEpoch 218/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0401 - accuracy: 0.3043 - val_loss: 0.0463 - val_accuracy: 0.2069\nEpoch 219/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0400 - accuracy: 0.3087 - val_loss: 0.0463 - val_accuracy: 0.2069\nEpoch 220/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0399 - accuracy: 0.3261 - val_loss: 0.0462 - val_accuracy: 0.2241\nEpoch 221/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0398 - accuracy: 0.3217 - val_loss: 0.0461 - val_accuracy: 0.2241\nEpoch 222/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0398 - accuracy: 0.3087 - val_loss: 0.0460 - val_accuracy: 0.2414\nEpoch 223/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0397 - accuracy: 0.3130 - val_loss: 0.0459 - val_accuracy: 0.2069\nEpoch 224/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0396 - accuracy: 0.3087 - val_loss: 0.0459 - val_accuracy: 0.2069\nEpoch 225/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0396 - accuracy: 0.3304 - val_loss: 0.0459 - val_accuracy: 0.2414\nEpoch 226/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0395 - accuracy: 0.3304 - val_loss: 0.0457 - val_accuracy: 0.2414\nEpoch 227/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0394 - accuracy: 0.3304 - val_loss: 0.0457 - val_accuracy: 0.2414\nEpoch 228/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0393 - accuracy: 0.3348 - val_loss: 0.0456 - val_accuracy: 0.2414\nEpoch 229/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0393 - accuracy: 0.3348 - val_loss: 0.0455 - val_accuracy: 0.2069\nEpoch 230/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0392 - accuracy: 0.3348 - val_loss: 0.0454 - val_accuracy: 0.2069\nEpoch 231/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0391 - accuracy: 0.3130 - val_loss: 0.0453 - val_accuracy: 0.2069\nEpoch 232/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0390 - accuracy: 0.3348 - val_loss: 0.0453 - val_accuracy: 0.2586\nEpoch 233/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0389 - accuracy: 0.3348 - val_loss: 0.0453 - val_accuracy: 0.2586\nEpoch 234/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0389 - accuracy: 0.3043 - val_loss: 0.0452 - val_accuracy: 0.2069\nEpoch 235/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0388 - accuracy: 0.3174 - val_loss: 0.0452 - val_accuracy: 0.2414\nEpoch 236/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0387 - accuracy: 0.3348 - val_loss: 0.0451 - val_accuracy: 0.2414\nEpoch 237/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0387 - accuracy: 0.3348 - val_loss: 0.0450 - val_accuracy: 0.2586\nEpoch 238/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0386 - accuracy: 0.3304 - val_loss: 0.0449 - val_accuracy: 0.2069\nEpoch 239/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0385 - accuracy: 0.3304 - val_loss: 0.0449 - val_accuracy: 0.2414\nEpoch 240/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0385 - accuracy: 0.3217 - val_loss: 0.0449 - val_accuracy: 0.2586\nEpoch 241/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0384 - accuracy: 0.3130 - val_loss: 0.0446 - val_accuracy: 0.2586\nEpoch 242/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0383 - accuracy: 0.3261 - val_loss: 0.0447 - val_accuracy: 0.2586\nEpoch 243/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0382 - accuracy: 0.3174 - val_loss: 0.0445 - val_accuracy: 0.2586\nEpoch 244/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0381 - accuracy: 0.3130 - val_loss: 0.0445 - val_accuracy: 0.2586\nEpoch 245/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0381 - accuracy: 0.3130 - val_loss: 0.0444 - val_accuracy: 0.2586\nEpoch 246/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0380 - accuracy: 0.3130 - val_loss: 0.0443 - val_accuracy: 0.2414\nEpoch 247/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0380 - accuracy: 0.3130 - val_loss: 0.0443 - val_accuracy: 0.2586\nEpoch 248/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0379 - accuracy: 0.3261 - val_loss: 0.0442 - val_accuracy: 0.2414\nEpoch 249/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0378 - accuracy: 0.3174 - val_loss: 0.0441 - val_accuracy: 0.2586\nEpoch 250/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0377 - accuracy: 0.3087 - val_loss: 0.0441 - val_accuracy: 0.2414\nEpoch 251/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0376 - accuracy: 0.3000 - val_loss: 0.0440 - val_accuracy: 0.2414\nEpoch 252/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0376 - accuracy: 0.3130 - val_loss: 0.0438 - val_accuracy: 0.2414\nEpoch 253/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0375 - accuracy: 0.3217 - val_loss: 0.0439 - val_accuracy: 0.2586\nEpoch 254/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0374 - accuracy: 0.3174 - val_loss: 0.0437 - val_accuracy: 0.2586\nEpoch 255/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0374 - accuracy: 0.3174 - val_loss: 0.0436 - val_accuracy: 0.2414\nEpoch 256/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0373 - accuracy: 0.3130 - val_loss: 0.0435 - val_accuracy: 0.2414\nEpoch 257/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0372 - accuracy: 0.3217 - val_loss: 0.0435 - val_accuracy: 0.2586\nEpoch 258/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0372 - accuracy: 0.3174 - val_loss: 0.0434 - val_accuracy: 0.2586\nEpoch 259/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0371 - accuracy: 0.3174 - val_loss: 0.0433 - val_accuracy: 0.2414\nEpoch 260/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0370 - accuracy: 0.3130 - val_loss: 0.0432 - val_accuracy: 0.2586\nEpoch 261/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0369 - accuracy: 0.3087 - val_loss: 0.0432 - val_accuracy: 0.2414\nEpoch 262/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0369 - accuracy: 0.3130 - val_loss: 0.0431 - val_accuracy: 0.2586\nEpoch 263/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0368 - accuracy: 0.3348 - val_loss: 0.0430 - val_accuracy: 0.2586\nEpoch 264/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0367 - accuracy: 0.3261 - val_loss: 0.0430 - val_accuracy: 0.2586\nEpoch 265/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0367 - accuracy: 0.3217 - val_loss: 0.0429 - val_accuracy: 0.2414\nEpoch 266/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0366 - accuracy: 0.3043 - val_loss: 0.0429 - val_accuracy: 0.2414\nEpoch 267/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0366 - accuracy: 0.3304 - val_loss: 0.0428 - val_accuracy: 0.2586\nEpoch 268/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0365 - accuracy: 0.3261 - val_loss: 0.0427 - val_accuracy: 0.2586\nEpoch 269/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0365 - accuracy: 0.3174 - val_loss: 0.0426 - val_accuracy: 0.2414\nEpoch 270/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.2957 - val_loss: 0.0426 - val_accuracy: 0.2414\nEpoch 271/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0363 - accuracy: 0.3130 - val_loss: 0.0425 - val_accuracy: 0.2586\nEpoch 272/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0362 - accuracy: 0.3261 - val_loss: 0.0425 - val_accuracy: 0.2586\nEpoch 273/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0362 - accuracy: 0.3087 - val_loss: 0.0423 - val_accuracy: 0.2414\nEpoch 274/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0361 - accuracy: 0.3130 - val_loss: 0.0423 - val_accuracy: 0.2414\nEpoch 275/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0361 - accuracy: 0.3000 - val_loss: 0.0422 - val_accuracy: 0.2414\nEpoch 276/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0360 - accuracy: 0.3000 - val_loss: 0.0421 - val_accuracy: 0.2414\nEpoch 277/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0360 - accuracy: 0.3217 - val_loss: 0.0421 - val_accuracy: 0.2586\nEpoch 278/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0359 - accuracy: 0.3348 - val_loss: 0.0422 - val_accuracy: 0.2586\nEpoch 279/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 0.3304 - val_loss: 0.0420 - val_accuracy: 0.2586\nEpoch 280/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 0.3043 - val_loss: 0.0419 - val_accuracy: 0.2414\nEpoch 281/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0357 - accuracy: 0.3000 - val_loss: 0.0418 - val_accuracy: 0.2414\nEpoch 282/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0356 - accuracy: 0.3087 - val_loss: 0.0417 - val_accuracy: 0.2414\nEpoch 283/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 0.3217 - val_loss: 0.0417 - val_accuracy: 0.2586\nEpoch 284/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0355 - accuracy: 0.3348 - val_loss: 0.0417 - val_accuracy: 0.2586\nEpoch 285/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 0.3348 - val_loss: 0.0417 - val_accuracy: 0.2586\nEpoch 286/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0354 - accuracy: 0.2957 - val_loss: 0.0415 - val_accuracy: 0.2414\nEpoch 287/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0353 - accuracy: 0.3130 - val_loss: 0.0415 - val_accuracy: 0.2586\nEpoch 288/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0353 - accuracy: 0.3130 - val_loss: 0.0413 - val_accuracy: 0.2414\nEpoch 289/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0352 - accuracy: 0.2783 - val_loss: 0.0412 - val_accuracy: 0.2414\nEpoch 290/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0351 - accuracy: 0.3087 - val_loss: 0.0413 - val_accuracy: 0.2414\nEpoch 291/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0350 - accuracy: 0.3261 - val_loss: 0.0413 - val_accuracy: 0.2586\nEpoch 292/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0350 - accuracy: 0.3391 - val_loss: 0.0413 - val_accuracy: 0.2586\nEpoch 293/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0350 - accuracy: 0.3391 - val_loss: 0.0410 - val_accuracy: 0.2414\nEpoch 294/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0349 - accuracy: 0.3043 - val_loss: 0.0411 - val_accuracy: 0.2414\nEpoch 295/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0349 - accuracy: 0.3217 - val_loss: 0.0410 - val_accuracy: 0.2414\nEpoch 296/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0348 - accuracy: 0.3174 - val_loss: 0.0409 - val_accuracy: 0.2414\nEpoch 297/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0347 - accuracy: 0.3043 - val_loss: 0.0408 - val_accuracy: 0.2414\nEpoch 298/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0347 - accuracy: 0.3043 - val_loss: 0.0407 - val_accuracy: 0.2414\nEpoch 299/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0346 - accuracy: 0.3087 - val_loss: 0.0407 - val_accuracy: 0.2414\nEpoch 300/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0346 - accuracy: 0.3087 - val_loss: 0.0407 - val_accuracy: 0.2414\nEpoch 301/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0345 - accuracy: 0.3217 - val_loss: 0.0405 - val_accuracy: 0.2414\nEpoch 302/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0346 - accuracy: 0.3391 - val_loss: 0.0407 - val_accuracy: 0.2586\nEpoch 303/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0344 - accuracy: 0.3174 - val_loss: 0.0403 - val_accuracy: 0.2414\nEpoch 304/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0344 - accuracy: 0.2913 - val_loss: 0.0402 - val_accuracy: 0.2414\nEpoch 305/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0343 - accuracy: 0.3130 - val_loss: 0.0403 - val_accuracy: 0.2414\nEpoch 306/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0343 - accuracy: 0.3304 - val_loss: 0.0403 - val_accuracy: 0.2586\nEpoch 307/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0342 - accuracy: 0.3391 - val_loss: 0.0403 - val_accuracy: 0.2586\nEpoch 308/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0341 - accuracy: 0.3348 - val_loss: 0.0401 - val_accuracy: 0.2414\nEpoch 309/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0341 - accuracy: 0.3217 - val_loss: 0.0401 - val_accuracy: 0.2414\nEpoch 310/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0341 - accuracy: 0.3217 - val_loss: 0.0401 - val_accuracy: 0.2414\nEpoch 311/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0340 - accuracy: 0.3174 - val_loss: 0.0401 - val_accuracy: 0.2414\nEpoch 312/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 0.3174 - val_loss: 0.0400 - val_accuracy: 0.2414\nEpoch 313/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0339 - accuracy: 0.3217 - val_loss: 0.0399 - val_accuracy: 0.2414\nEpoch 314/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0339 - accuracy: 0.3348 - val_loss: 0.0400 - val_accuracy: 0.2586\nEpoch 315/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0338 - accuracy: 0.3261 - val_loss: 0.0398 - val_accuracy: 0.2414\nEpoch 316/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0338 - accuracy: 0.3130 - val_loss: 0.0397 - val_accuracy: 0.2414\nEpoch 317/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0337 - accuracy: 0.3087 - val_loss: 0.0398 - val_accuracy: 0.2414\nEpoch 318/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0337 - accuracy: 0.3174 - val_loss: 0.0397 - val_accuracy: 0.2414\nEpoch 319/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0336 - accuracy: 0.3174 - val_loss: 0.0396 - val_accuracy: 0.2414\nEpoch 320/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0337 - accuracy: 0.3478 - val_loss: 0.0397 - val_accuracy: 0.2586\nEpoch 321/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0336 - accuracy: 0.3391 - val_loss: 0.0395 - val_accuracy: 0.2414\nEpoch 322/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0335 - accuracy: 0.3174 - val_loss: 0.0395 - val_accuracy: 0.2414\nEpoch 323/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0335 - accuracy: 0.3043 - val_loss: 0.0394 - val_accuracy: 0.2414\nEpoch 324/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0334 - accuracy: 0.3087 - val_loss: 0.0395 - val_accuracy: 0.2414\nEpoch 325/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0334 - accuracy: 0.3130 - val_loss: 0.0393 - val_accuracy: 0.2414\nEpoch 326/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0333 - accuracy: 0.3130 - val_loss: 0.0392 - val_accuracy: 0.2414\nEpoch 327/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0333 - accuracy: 0.3261 - val_loss: 0.0392 - val_accuracy: 0.2414\nEpoch 328/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0333 - accuracy: 0.3348 - val_loss: 0.0392 - val_accuracy: 0.2414\nEpoch 329/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0332 - accuracy: 0.3000 - val_loss: 0.0392 - val_accuracy: 0.2414\nEpoch 330/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0332 - accuracy: 0.3261 - val_loss: 0.0392 - val_accuracy: 0.2414\nEpoch 331/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0332 - accuracy: 0.3130 - val_loss: 0.0390 - val_accuracy: 0.2414\nEpoch 332/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0331 - accuracy: 0.3174 - val_loss: 0.0391 - val_accuracy: 0.2414\nEpoch 333/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0330 - accuracy: 0.3174 - val_loss: 0.0390 - val_accuracy: 0.2414\nEpoch 334/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0331 - accuracy: 0.3217 - val_loss: 0.0390 - val_accuracy: 0.2414\nEpoch 335/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0329 - accuracy: 0.3174 - val_loss: 0.0389 - val_accuracy: 0.2414\nEpoch 336/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0329 - accuracy: 0.2957 - val_loss: 0.0388 - val_accuracy: 0.2586\nEpoch 337/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0329 - accuracy: 0.3130 - val_loss: 0.0389 - val_accuracy: 0.2586\nEpoch 338/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0329 - accuracy: 0.3435 - val_loss: 0.0387 - val_accuracy: 0.2586\nEpoch 339/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0328 - accuracy: 0.3217 - val_loss: 0.0387 - val_accuracy: 0.2414\nEpoch 340/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0328 - accuracy: 0.3087 - val_loss: 0.0386 - val_accuracy: 0.2586\nEpoch 341/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0327 - accuracy: 0.3261 - val_loss: 0.0387 - val_accuracy: 0.2414\nEpoch 342/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0327 - accuracy: 0.3174 - val_loss: 0.0386 - val_accuracy: 0.2586\nEpoch 343/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0326 - accuracy: 0.3130 - val_loss: 0.0384 - val_accuracy: 0.2586\nEpoch 344/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0327 - accuracy: 0.3174 - val_loss: 0.0386 - val_accuracy: 0.2586\nEpoch 345/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0326 - accuracy: 0.3261 - val_loss: 0.0384 - val_accuracy: 0.2586\nEpoch 346/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0325 - accuracy: 0.3174 - val_loss: 0.0384 - val_accuracy: 0.2586\nEpoch 347/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0325 - accuracy: 0.3565 - val_loss: 0.0385 - val_accuracy: 0.2759\nEpoch 348/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0325 - accuracy: 0.3348 - val_loss: 0.0383 - val_accuracy: 0.2586\nEpoch 349/350\n15/15 [==============================] - 0s 2ms/step - loss: 0.0325 - accuracy: 0.3130 - val_loss: 0.0384 - val_accuracy: 0.2586\nEpoch 350/350\n15/15 [==============================] - 0s 3ms/step - loss: 0.0324 - accuracy: 0.3174 - val_loss: 0.0382 - val_accuracy: 0.2414\n"
        }
      ],
      "source": [
        "hp_model=ANN.fit(x=X_train,y=y_train, validation_data = (X_test, y_test), epochs=350 ,batch_size = 16)\n",
        "#hp_model=ANN.fit(x=x1_train,y=y1_train, validation_data = (x1_test, y1_test), epochs=100 ,batch_size = 16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "<matplotlib.legend.Legend at 0x7f407b1353d0>"
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 372.103125 248.518125\" width=\"372.103125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 372.103125 248.518125 \nL 372.103125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 224.64 \nL 364.903125 224.64 \nL 364.903125 7.2 \nL 30.103125 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m76854ad8a3\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.321307\" xlink:href=\"#m76854ad8a3\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(42.140057 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"88.926412\" xlink:href=\"#m76854ad8a3\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 50 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(82.563912 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"132.531518\" xlink:href=\"#m76854ad8a3\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 100 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(122.987768 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"176.136623\" xlink:href=\"#m76854ad8a3\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 150 -->\n      <g transform=\"translate(166.592873 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"219.741729\" xlink:href=\"#m76854ad8a3\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 200 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(210.197979 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"263.346834\" xlink:href=\"#m76854ad8a3\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 250 -->\n      <g transform=\"translate(253.803084 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"306.95194\" xlink:href=\"#m76854ad8a3\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 300 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(297.40819 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"350.557045\" xlink:href=\"#m76854ad8a3\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 350 -->\n      <g transform=\"translate(341.013295 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_9\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m16cfa31fa9\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m16cfa31fa9\" y=\"182.857612\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.1 -->\n      <defs>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n      </defs>\n      <g transform=\"translate(7.2 186.656831)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m16cfa31fa9\" y=\"135.670328\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.2 -->\n      <g transform=\"translate(7.2 139.469547)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m16cfa31fa9\" y=\"88.483044\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.3 -->\n      <g transform=\"translate(7.2 92.282262)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m16cfa31fa9\" y=\"41.295759\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.4 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(7.2 45.094978)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_13\">\n    <path clip-path=\"url(#p9ff0ffeff7)\" d=\"M 45.321307 17.083636 \nL 47.065511 47.70698 \nL 49.681817 88.602024 \nL 51.426022 112.330894 \nL 53.170226 131.889374 \nL 54.91443 148.017657 \nL 55.786532 154.470794 \nL 56.658634 159.826694 \nL 57.530736 164.480188 \nL 58.402838 168.241762 \nL 59.274941 171.459974 \nL 61.019145 176.560397 \nL 61.891247 178.400268 \nL 63.635451 181.307816 \nL 64.507553 182.421472 \nL 65.379655 183.354394 \nL 67.12386 184.808998 \nL 68.868064 186.007418 \nL 71.48437 187.425873 \nL 74.100676 188.586246 \nL 78.461187 190.413144 \nL 86.310106 193.862497 \nL 88.926412 195.071411 \nL 97.647433 198.748815 \nL 102.880046 200.507575 \nL 108.112659 202.064112 \nL 115.961578 203.798819 \nL 118.577884 204.277303 \nL 121.19419 204.668895 \nL 125.554701 205.255116 \nL 136.019926 206.263289 \nL 143.868845 206.822323 \nL 166.5435 208.019595 \nL 170.031909 208.185256 \nL 182.241338 208.756534 \nL 186.601849 208.972269 \nL 237.183771 211.251495 \nL 279.916774 212.876023 \nL 303.463531 213.656706 \nL 311.31245 213.879153 \nL 322.649778 214.191082 \nL 324.393982 214.206943 \nL 334.859207 214.459517 \nL 337.475514 214.507093 \nL 349.684943 214.756364 \nL 349.684943 214.756364 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_14\">\n    <path clip-path=\"url(#p9ff0ffeff7)\" d=\"M 45.321307 33.335533 \nL 47.065511 62.908363 \nL 48.809715 89.680031 \nL 50.553919 113.469553 \nL 52.298124 132.813292 \nL 54.042328 148.792734 \nL 54.91443 155.111704 \nL 55.786532 160.373193 \nL 56.658634 164.717281 \nL 57.530736 168.321471 \nL 58.402838 171.362859 \nL 59.274941 173.935998 \nL 60.147043 175.973699 \nL 61.891247 179.036548 \nL 63.635451 181.289485 \nL 64.507553 182.157121 \nL 65.379655 182.855811 \nL 69.740166 185.516939 \nL 70.612268 185.760839 \nL 71.48437 186.213482 \nL 73.228574 186.826062 \nL 74.972779 187.601473 \nL 76.716983 188.247533 \nL 79.333289 189.20971 \nL 82.821698 190.767887 \nL 83.6938 191.055548 \nL 85.438004 191.872789 \nL 87.182208 192.606939 \nL 95.903229 196.182922 \nL 97.647433 196.739817 \nL 98.519536 197.146404 \nL 102.007944 198.215649 \nL 108.112659 199.943625 \nL 116.83368 201.654864 \nL 119.449986 201.975555 \nL 122.066292 202.362065 \nL 126.426803 202.835308 \nL 128.171007 203.011601 \nL 132.531518 203.379998 \nL 136.019926 203.629709 \nL 140.380437 203.943128 \nL 177.880828 205.73391 \nL 179.625032 205.848481 \nL 184.857644 206.002443 \nL 186.601849 206.14489 \nL 280.788876 209.985925 \nL 283.405183 210.077564 \nL 297.358817 210.557208 \nL 303.463531 210.805735 \nL 306.95194 210.930515 \nL 307.824042 210.857372 \nL 308.696144 211.031525 \nL 309.568246 211.086253 \nL 310.440348 211.004916 \nL 322.649778 211.339714 \nL 323.52188 211.298096 \nL 326.138186 211.463715 \nL 327.88239 211.501703 \nL 329.626595 211.557047 \nL 332.242901 211.565689 \nL 333.987105 211.613596 \nL 340.963922 211.820674 \nL 342.708126 211.833923 \nL 343.580228 211.912167 \nL 344.452331 211.841905 \nL 346.196535 211.911483 \nL 347.068637 211.86541 \nL 349.684943 212.023067 \nL 349.684943 212.023067 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 224.64 \nL 30.103125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 364.903125 224.64 \nL 364.903125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 224.64 \nL 364.903125 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 7.2 \nL 364.903125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 302.628125 44.55625 \nL 357.903125 44.55625 \nQ 359.903125 44.55625 359.903125 42.55625 \nL 359.903125 14.2 \nQ 359.903125 12.2 357.903125 12.2 \nL 302.628125 12.2 \nQ 300.628125 12.2 300.628125 14.2 \nL 300.628125 42.55625 \nQ 300.628125 44.55625 302.628125 44.55625 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_15\">\n     <path d=\"M 304.628125 20.298437 \nL 324.628125 20.298437 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_16\"/>\n    <g id=\"text_13\">\n     <!-- train -->\n     <defs>\n      <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n      <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n      <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n      <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n     </defs>\n     <g transform=\"translate(332.628125 23.798437)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-110\"/>\n     </g>\n    </g>\n    <g id=\"line2d_17\">\n     <path d=\"M 304.628125 34.976562 \nL 324.628125 34.976562 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_18\"/>\n    <g id=\"text_14\">\n     <!-- val -->\n     <defs>\n      <path d=\"M 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 8.796875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nL 35.6875 0 \nL 23.484375 0 \nz\n\" id=\"DejaVuSans-118\"/>\n      <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n     </defs>\n     <g transform=\"translate(332.628125 38.476562)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-118\"/>\n      <use x=\"59.179688\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"120.458984\" xlink:href=\"#DejaVuSans-108\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p9ff0ffeff7\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"30.103125\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(hp_model.history['loss'],label='loss')\n",
        "plt.plot(hp_model.history['val_loss'],label='val_loss')\n",
        "plt.legend(['train','val'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "<matplotlib.legend.Legend at 0x7f3f504697c0>"
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 378.465625 248.518125\" width=\"378.465625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 378.465625 248.518125 \nL 378.465625 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 36.465625 224.64 \nL 371.265625 224.64 \nL 371.265625 7.2 \nL 36.465625 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m40b8a4dbd3\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"51.683807\" xlink:href=\"#m40b8a4dbd3\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(48.502557 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"95.288912\" xlink:href=\"#m40b8a4dbd3\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 50 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(88.926412 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"138.894018\" xlink:href=\"#m40b8a4dbd3\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 100 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(129.350268 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"182.499123\" xlink:href=\"#m40b8a4dbd3\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 150 -->\n      <g transform=\"translate(172.955373 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"226.104229\" xlink:href=\"#m40b8a4dbd3\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 200 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(216.560479 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"269.709334\" xlink:href=\"#m40b8a4dbd3\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 250 -->\n      <g transform=\"translate(260.165584 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"313.31444\" xlink:href=\"#m40b8a4dbd3\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 300 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(303.77069 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"356.919545\" xlink:href=\"#m40b8a4dbd3\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 350 -->\n      <g transform=\"translate(347.375795 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_9\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m1ea3a0c479\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m1ea3a0c479\" y=\"214.756364\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.00 -->\n      <defs>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n      </defs>\n      <g transform=\"translate(7.2 218.555582)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m1ea3a0c479\" y=\"187.033968\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.05 -->\n      <g transform=\"translate(7.2 190.833187)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m1ea3a0c479\" y=\"159.311572\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.10 -->\n      <g transform=\"translate(7.2 163.110791)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m1ea3a0c479\" y=\"131.589176\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.15 -->\n      <g transform=\"translate(7.2 135.388395)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m1ea3a0c479\" y=\"103.866781\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.20 -->\n      <g transform=\"translate(7.2 107.665999)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m1ea3a0c479\" y=\"76.144385\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.25 -->\n      <g transform=\"translate(7.2 79.943604)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m1ea3a0c479\" y=\"48.421989\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 0.30 -->\n      <g transform=\"translate(7.2 52.221208)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m1ea3a0c479\" y=\"20.699594\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 0.35 -->\n      <g transform=\"translate(7.2 24.498812)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_17\">\n    <path clip-path=\"url(#p6512898b91)\" d=\"M 51.683807 214.756364 \nL 57.788522 214.756364 \nL 58.660624 185.828647 \nL 59.532726 152.079642 \nL 60.404828 147.258359 \nL 69.125849 147.258359 \nL 69.997951 149.669 \nL 70.870053 149.669 \nL 71.742155 152.079642 \nL 72.614257 161.722217 \nL 73.48636 168.954146 \nL 75.230564 173.77543 \nL 76.102666 190.649932 \nL 76.974768 197.881862 \nL 77.84687 200.292505 \nL 78.718972 207.524434 \nL 80.463176 212.345721 \nL 81.335279 212.345721 \nL 82.207381 209.935078 \nL 83.079483 212.345721 \nL 86.567891 212.345721 \nL 87.439993 214.756364 \nL 88.312095 212.345721 \nL 89.184198 214.756364 \nL 97.905219 214.756364 \nL 99.649423 209.935078 \nL 100.521525 205.113792 \nL 148.487141 205.113792 \nL 149.359243 202.703148 \nL 150.231345 205.113792 \nL 151.103447 190.649932 \nL 151.975549 200.292505 \nL 152.847652 202.703148 \nL 153.719754 202.703148 \nL 154.591856 176.186076 \nL 155.463958 166.543501 \nL 156.33606 166.543501 \nL 157.208162 173.77543 \nL 158.080264 178.596717 \nL 158.952366 168.954146 \nL 159.824468 144.847717 \nL 160.696571 142.437071 \nL 161.568673 130.383858 \nL 162.440775 123.151929 \nL 163.312877 118.330638 \nL 164.184979 127.973213 \nL 165.929183 103.866779 \nL 166.801285 86.992283 \nL 167.673387 62.885841 \nL 168.54549 62.885841 \nL 169.417592 84.581637 \nL 170.289694 91.813566 \nL 171.161796 70.117779 \nL 172.033898 55.65392 \nL 172.906 65.296487 \nL 174.650204 89.402921 \nL 175.522306 86.992283 \nL 176.394409 86.992283 \nL 177.266511 72.528425 \nL 178.138613 53.243274 \nL 179.010715 53.243274 \nL 179.882817 74.93907 \nL 180.754919 84.581637 \nL 181.627021 86.992283 \nL 182.499123 62.885841 \nL 183.371225 48.421983 \nL 184.243328 48.421983 \nL 185.11543 41.190062 \nL 185.987532 53.243274 \nL 186.859634 53.243274 \nL 188.603838 48.421983 \nL 189.47594 48.421983 \nL 190.348042 50.832629 \nL 191.220144 50.832629 \nL 192.092247 62.885841 \nL 192.964349 48.421983 \nL 193.836451 53.243274 \nL 194.708553 48.421983 \nL 196.452757 48.421983 \nL 197.324859 46.011353 \nL 198.196961 46.011353 \nL 199.069063 55.65392 \nL 199.941166 55.65392 \nL 200.813268 43.600708 \nL 202.557472 48.421983 \nL 205.173778 48.421983 \nL 206.04588 50.832629 \nL 206.917982 46.011353 \nL 207.790084 46.011353 \nL 208.662187 36.36877 \nL 209.534289 46.011353 \nL 210.406391 41.190062 \nL 211.278493 43.600708 \nL 212.150595 50.832629 \nL 213.894799 46.011353 \nL 214.766901 38.779416 \nL 215.639003 38.779416 \nL 216.511106 46.011353 \nL 217.383208 38.779416 \nL 218.25531 46.011353 \nL 219.127412 46.011353 \nL 219.999514 38.779416 \nL 220.871616 46.011353 \nL 221.743718 43.600708 \nL 222.61582 43.600708 \nL 223.487922 33.958124 \nL 224.360025 31.547495 \nL 225.232127 43.600708 \nL 226.976331 33.958124 \nL 228.720535 38.779416 \nL 229.592637 48.421983 \nL 230.464739 48.421983 \nL 231.336841 43.600708 \nL 232.208944 33.958124 \nL 233.081046 33.958124 \nL 234.82525 43.600708 \nL 235.697352 36.36877 \nL 236.569454 33.958124 \nL 237.441556 33.958124 \nL 238.313658 38.779416 \nL 239.18576 38.779416 \nL 240.057863 41.190062 \nL 240.929965 46.011353 \nL 241.802067 43.600708 \nL 242.674169 33.958124 \nL 243.546271 36.36877 \nL 244.418373 43.600708 \nL 245.290475 41.190062 \nL 246.162577 43.600708 \nL 247.034679 31.547495 \nL 248.778884 31.547495 \nL 249.650986 29.136849 \nL 251.39519 29.136849 \nL 252.267292 41.190062 \nL 253.139394 29.136849 \nL 254.011496 29.136849 \nL 254.883598 46.011353 \nL 255.755701 38.779416 \nL 256.627803 29.136849 \nL 257.499905 29.136849 \nL 258.372007 31.547495 \nL 259.244109 31.547495 \nL 260.988313 41.190062 \nL 261.860415 33.958124 \nL 262.732517 38.779416 \nL 263.60462 41.190062 \nL 266.220926 41.190062 \nL 267.093028 33.958124 \nL 269.709334 48.421983 \nL 270.581436 41.190062 \nL 271.453539 36.36877 \nL 272.325641 38.779416 \nL 273.197743 38.779416 \nL 274.069845 41.190062 \nL 274.941947 36.36877 \nL 275.814049 38.779416 \nL 276.686151 38.779416 \nL 278.430355 43.600708 \nL 279.302458 41.190062 \nL 280.17456 29.136849 \nL 281.046662 33.958124 \nL 281.918764 36.36877 \nL 282.790866 46.011353 \nL 283.662968 31.547495 \nL 284.53507 33.958124 \nL 285.407172 38.779416 \nL 286.279274 50.832629 \nL 287.151376 41.190062 \nL 288.023479 33.958124 \nL 288.895581 43.600708 \nL 289.767683 41.190062 \nL 290.639785 48.421983 \nL 291.511887 48.421983 \nL 292.383989 36.36877 \nL 293.256091 29.136849 \nL 294.128193 31.547495 \nL 295.000295 46.011353 \nL 295.872398 48.421983 \nL 296.7445 43.600708 \nL 298.488704 29.136849 \nL 299.360806 29.136849 \nL 300.232908 50.832629 \nL 301.10501 41.190062 \nL 301.977112 41.190062 \nL 302.849214 60.475212 \nL 303.721317 43.600708 \nL 304.593419 33.958124 \nL 305.465521 26.726203 \nL 306.337623 26.726203 \nL 307.209725 46.011353 \nL 308.081827 36.36877 \nL 308.953929 38.779416 \nL 309.826031 46.011353 \nL 310.698133 46.011353 \nL 311.570236 43.600708 \nL 312.442338 43.600708 \nL 313.31444 36.36877 \nL 314.186542 26.726203 \nL 315.058644 38.779416 \nL 315.930746 53.243274 \nL 316.802848 41.190062 \nL 317.67495 31.547495 \nL 318.547052 26.726203 \nL 319.419155 29.136849 \nL 320.291257 36.36877 \nL 321.163359 36.36877 \nL 322.035461 38.779416 \nL 322.907563 38.779416 \nL 323.779665 36.36877 \nL 324.651767 29.136849 \nL 325.523869 33.958124 \nL 326.395971 41.190062 \nL 327.268074 43.600708 \nL 328.140176 38.779416 \nL 329.012278 38.779416 \nL 329.88438 21.904912 \nL 330.756482 26.726203 \nL 331.628584 38.779416 \nL 332.500686 46.011353 \nL 334.24489 41.190062 \nL 335.116993 41.190062 \nL 335.989095 33.958124 \nL 336.861197 29.136849 \nL 337.733299 48.421983 \nL 338.605401 33.958124 \nL 339.477503 41.190062 \nL 340.349605 38.779416 \nL 341.221707 38.779416 \nL 342.093809 36.36877 \nL 342.965912 38.779416 \nL 343.838014 50.832629 \nL 344.710116 41.190062 \nL 345.582218 24.315557 \nL 346.45432 36.36877 \nL 347.326422 43.600708 \nL 348.198524 33.958124 \nL 349.070626 38.779416 \nL 349.942728 41.190062 \nL 350.814831 38.779416 \nL 351.686933 33.958124 \nL 352.559035 38.779416 \nL 353.431137 17.083636 \nL 355.175341 41.190062 \nL 356.047443 38.779416 \nL 356.047443 38.779416 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_18\">\n    <path clip-path=\"url(#p6512898b91)\" d=\"M 51.683807 214.756364 \nL 56.916419 214.756364 \nL 57.788522 205.196917 \nL 58.660624 100.042998 \nL 60.404828 80.924111 \nL 68.253747 80.924111 \nL 69.125849 90.483555 \nL 69.997951 90.483555 \nL 70.870053 100.042998 \nL 71.742155 119.161894 \nL 72.614257 119.161894 \nL 73.48636 147.840237 \nL 74.358462 147.840237 \nL 76.102666 186.078022 \nL 79.591074 186.078022 \nL 80.463176 195.63747 \nL 81.335279 186.078022 \nL 82.207381 186.078022 \nL 83.079483 205.196917 \nL 84.823687 205.196917 \nL 85.695789 214.756364 \nL 150.231345 214.756364 \nL 151.103447 205.196917 \nL 151.975549 214.756364 \nL 152.847652 214.756364 \nL 153.719754 205.196917 \nL 154.591856 186.078022 \nL 157.208162 186.078022 \nL 158.080264 195.63747 \nL 158.952366 186.078022 \nL 160.696571 186.078022 \nL 161.568673 166.959129 \nL 162.440775 176.518577 \nL 163.312877 166.959129 \nL 165.057081 166.959129 \nL 167.673387 109.60245 \nL 168.54549 119.161894 \nL 169.417592 147.840237 \nL 170.289694 147.840237 \nL 171.161796 119.161894 \nL 172.906 119.161894 \nL 173.778102 138.28079 \nL 174.650204 147.840237 \nL 175.522306 138.28079 \nL 176.394409 119.161894 \nL 177.266511 119.161894 \nL 178.138613 100.042998 \nL 179.010715 109.60245 \nL 179.882817 128.721346 \nL 181.627021 128.721346 \nL 182.499123 100.042998 \nL 185.11543 100.042998 \nL 185.987532 109.60245 \nL 186.859634 109.60245 \nL 187.731736 100.042998 \nL 191.220144 100.042998 \nL 192.092247 119.161894 \nL 192.964349 100.042998 \nL 193.836451 109.60245 \nL 194.708553 100.042998 \nL 198.196961 100.042998 \nL 199.069063 119.161894 \nL 200.813268 100.042998 \nL 238.313658 100.042998 \nL 239.18576 80.924111 \nL 240.057863 100.042998 \nL 241.802067 100.042998 \nL 242.674169 90.483555 \nL 243.546271 90.483555 \nL 244.418373 80.924111 \nL 245.290475 100.042998 \nL 246.162577 100.042998 \nL 247.034679 80.924111 \nL 249.650986 80.924111 \nL 250.523088 100.042998 \nL 252.267292 100.042998 \nL 253.139394 71.364667 \nL 254.011496 71.364667 \nL 254.883598 100.042998 \nL 255.755701 80.924111 \nL 256.627803 80.924111 \nL 257.499905 71.364667 \nL 258.372007 100.042998 \nL 259.244109 80.924111 \nL 260.116211 71.364667 \nL 264.476722 71.364667 \nL 265.348824 80.924111 \nL 266.220926 71.364667 \nL 267.093028 80.924111 \nL 267.96513 71.364667 \nL 268.837232 80.924111 \nL 270.581436 80.924111 \nL 271.453539 71.364667 \nL 272.325641 71.364667 \nL 273.197743 80.924111 \nL 274.069845 80.924111 \nL 274.941947 71.364667 \nL 275.814049 71.364667 \nL 276.686151 80.924111 \nL 277.558253 71.364667 \nL 278.430355 80.924111 \nL 279.302458 71.364667 \nL 281.046662 71.364667 \nL 281.918764 80.924111 \nL 282.790866 80.924111 \nL 283.662968 71.364667 \nL 284.53507 71.364667 \nL 285.407172 80.924111 \nL 286.279274 80.924111 \nL 287.151376 71.364667 \nL 288.023479 71.364667 \nL 288.895581 80.924111 \nL 291.511887 80.924111 \nL 292.383989 71.364667 \nL 294.128193 71.364667 \nL 295.000295 80.924111 \nL 296.7445 80.924111 \nL 297.616602 71.364667 \nL 299.360806 71.364667 \nL 300.232908 80.924111 \nL 301.10501 71.364667 \nL 301.977112 80.924111 \nL 303.721317 80.924111 \nL 304.593419 71.364667 \nL 305.465521 71.364667 \nL 306.337623 80.924111 \nL 313.31444 80.924111 \nL 314.186542 71.364667 \nL 315.058644 80.924111 \nL 316.802848 80.924111 \nL 317.67495 71.364667 \nL 318.547052 71.364667 \nL 319.419155 80.924111 \nL 323.779665 80.924111 \nL 324.651767 71.364667 \nL 325.523869 80.924111 \nL 329.012278 80.924111 \nL 329.88438 71.364667 \nL 330.756482 80.924111 \nL 342.965912 80.924111 \nL 343.838014 71.364667 \nL 345.582218 71.364667 \nL 346.45432 80.924111 \nL 347.326422 71.364667 \nL 348.198524 80.924111 \nL 349.070626 71.364667 \nL 352.559035 71.364667 \nL 353.431137 61.805215 \nL 354.303239 71.364667 \nL 355.175341 71.364667 \nL 356.047443 80.924111 \nL 356.047443 80.924111 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 36.465625 224.64 \nL 36.465625 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 371.265625 224.64 \nL 371.265625 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 36.465625 224.64 \nL 371.265625 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 36.465625 7.2 \nL 371.265625 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 43.465625 44.55625 \nL 98.740625 44.55625 \nQ 100.740625 44.55625 100.740625 42.55625 \nL 100.740625 14.2 \nQ 100.740625 12.2 98.740625 12.2 \nL 43.465625 12.2 \nQ 41.465625 12.2 41.465625 14.2 \nL 41.465625 42.55625 \nQ 41.465625 44.55625 43.465625 44.55625 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_19\">\n     <path d=\"M 45.465625 20.298437 \nL 65.465625 20.298437 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_20\"/>\n    <g id=\"text_17\">\n     <!-- train -->\n     <defs>\n      <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n      <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n      <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n      <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n     </defs>\n     <g transform=\"translate(73.465625 23.798437)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-110\"/>\n     </g>\n    </g>\n    <g id=\"line2d_21\">\n     <path d=\"M 45.465625 34.976562 \nL 65.465625 34.976562 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_22\"/>\n    <g id=\"text_18\">\n     <!-- val -->\n     <defs>\n      <path d=\"M 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 8.796875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nL 35.6875 0 \nL 23.484375 0 \nz\n\" id=\"DejaVuSans-118\"/>\n      <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n     </defs>\n     <g transform=\"translate(73.465625 38.476562)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-118\"/>\n      <use x=\"59.179688\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"120.458984\" xlink:href=\"#DejaVuSans-108\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p6512898b91\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"36.465625\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(hp_model.history['accuracy'],label='accuracy')\n",
        "plt.plot(hp_model.history['val_accuracy'],label='val_accuracy')\n",
        "plt.legend(['train','val'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "userlist = np.array([[0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "userinputs = pd.DataFrame(data=userlist,columns = df.columns )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "   headphone_name  game_use  travel_use  exercise_use  office_use  \\\n0               0         0           0             0           0   \n1               0         1           0             0           0   \n2               0         0           1             0           0   \n3               0         0           0             1           0   \n4               0         0           0             0           1   \n5               0         0           0             0           0   \n\n   phone_call_use  studio_use  wireless  noise_cancelling  mic_presence  ...  \\\n0               1           0         0                 0             0  ...   \n1               0           0         0                 0             0  ...   \n2               0           0         0                 0             0  ...   \n3               0           0         0                 0             0  ...   \n4               0           0         0                 0             0  ...   \n5               0           1         0                 0             0  ...   \n\n   noise_isolation  microphone_rating  mic_recording_quality  bluetooth  \\\n0                0                  0                      0          0   \n1                0                  0                      0          0   \n2                0                  0                      0          0   \n3                0                  0                      0          0   \n4                0                  0                      0          0   \n5                0                  0                      0          0   \n\n   closed_back  open_back  in_ear  on_ear  over_ear  head_set  \n0            0          0       0       0         0         0  \n1            0          0       0       0         0         0  \n2            0          0       0       0         0         0  \n3            0          0       0       0         0         0  \n4            0          0       0       0         0         0  \n5            0          0       0       0         0         0  \n\n[6 rows x 28 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>headphone_name</th>\n      <th>game_use</th>\n      <th>travel_use</th>\n      <th>exercise_use</th>\n      <th>office_use</th>\n      <th>phone_call_use</th>\n      <th>studio_use</th>\n      <th>wireless</th>\n      <th>noise_cancelling</th>\n      <th>mic_presence</th>\n      <th>...</th>\n      <th>noise_isolation</th>\n      <th>microphone_rating</th>\n      <th>mic_recording_quality</th>\n      <th>bluetooth</th>\n      <th>closed_back</th>\n      <th>open_back</th>\n      <th>in_ear</th>\n      <th>on_ear</th>\n      <th>over_ear</th>\n      <th>head_set</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>6 rows  28 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "userinputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_pred=userinputs[['travel_use', 'exercise_use', 'office_use',\n",
        "       'phone_call_use', 'studio_use',  'game_use']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "y_pred=ANN.predict(X_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "annpreddf = pd.DataFrame(data=y_pred, columns =y.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "   wireless  noise_cancelling  mic_presence  frequency_response_consistency  \\\n0  0.202082         -0.066263      0.179919                        0.125222   \n1  0.054996         -0.020965      0.086440                        0.109339   \n2  0.160977          0.006247      0.108459                        0.127826   \n3  0.216502         -0.121272      0.161257                        0.232544   \n4  0.195436          0.017321      0.140609                        0.140817   \n5  0.100086         -0.014135      0.028946                        0.095056   \n\n   bass_accuracy  mid_accuracy  treble_accuracy  peaks_dips   imaging  \\\n0       0.100442      0.110505         0.192110    0.103356  0.166410   \n1       0.093311      0.153431         0.140458    0.097987  0.196154   \n2       0.063190      0.114624         0.145293    0.078732  0.159652   \n3       0.127295      0.175694         0.226345    0.108203  0.236148   \n4       0.089230      0.131331         0.123202    0.117552  0.170568   \n5       0.155228      0.156778         0.196671    0.051351  0.150046   \n\n   passive_soundstage  ...  noise_isolation  microphone_rating  \\\n0           -0.006604  ...         0.067506           0.109527   \n1            0.094896  ...         0.068430           0.039145   \n2           -0.026930  ...         0.130238           0.052387   \n3            0.025751  ...         0.086943           0.101603   \n4            0.045935  ...         0.097071           0.059153   \n5            0.034927  ...         0.031062           0.019676   \n\n   mic_recording_quality  bluetooth  closed_back  open_back    in_ear  \\\n0               0.145503   0.137837     0.127636   0.039211  0.198964   \n1               0.045232   0.036801     0.132205   0.070435  0.109691   \n2               0.044187   0.134013     0.118800   0.021939  0.151189   \n3               0.111665   0.155544     0.178150   0.099039  0.336376   \n4               0.055884   0.137045     0.161261   0.034578  0.172673   \n5               0.009355   0.045576     0.077652   0.094742  0.169457   \n\n     on_ear  over_ear  head_set  \n0 -0.006817 -0.111079  0.043249  \n1  0.005609  0.065065  0.030155  \n2 -0.022029 -0.037546 -0.008493  \n3 -0.038776 -0.137940  0.026508  \n4 -0.048490 -0.083490 -0.000259  \n5 -0.031543 -0.040632  0.038561  \n\n[6 rows x 21 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>wireless</th>\n      <th>noise_cancelling</th>\n      <th>mic_presence</th>\n      <th>frequency_response_consistency</th>\n      <th>bass_accuracy</th>\n      <th>mid_accuracy</th>\n      <th>treble_accuracy</th>\n      <th>peaks_dips</th>\n      <th>imaging</th>\n      <th>passive_soundstage</th>\n      <th>...</th>\n      <th>noise_isolation</th>\n      <th>microphone_rating</th>\n      <th>mic_recording_quality</th>\n      <th>bluetooth</th>\n      <th>closed_back</th>\n      <th>open_back</th>\n      <th>in_ear</th>\n      <th>on_ear</th>\n      <th>over_ear</th>\n      <th>head_set</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.202082</td>\n      <td>-0.066263</td>\n      <td>0.179919</td>\n      <td>0.125222</td>\n      <td>0.100442</td>\n      <td>0.110505</td>\n      <td>0.192110</td>\n      <td>0.103356</td>\n      <td>0.166410</td>\n      <td>-0.006604</td>\n      <td>...</td>\n      <td>0.067506</td>\n      <td>0.109527</td>\n      <td>0.145503</td>\n      <td>0.137837</td>\n      <td>0.127636</td>\n      <td>0.039211</td>\n      <td>0.198964</td>\n      <td>-0.006817</td>\n      <td>-0.111079</td>\n      <td>0.043249</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.054996</td>\n      <td>-0.020965</td>\n      <td>0.086440</td>\n      <td>0.109339</td>\n      <td>0.093311</td>\n      <td>0.153431</td>\n      <td>0.140458</td>\n      <td>0.097987</td>\n      <td>0.196154</td>\n      <td>0.094896</td>\n      <td>...</td>\n      <td>0.068430</td>\n      <td>0.039145</td>\n      <td>0.045232</td>\n      <td>0.036801</td>\n      <td>0.132205</td>\n      <td>0.070435</td>\n      <td>0.109691</td>\n      <td>0.005609</td>\n      <td>0.065065</td>\n      <td>0.030155</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.160977</td>\n      <td>0.006247</td>\n      <td>0.108459</td>\n      <td>0.127826</td>\n      <td>0.063190</td>\n      <td>0.114624</td>\n      <td>0.145293</td>\n      <td>0.078732</td>\n      <td>0.159652</td>\n      <td>-0.026930</td>\n      <td>...</td>\n      <td>0.130238</td>\n      <td>0.052387</td>\n      <td>0.044187</td>\n      <td>0.134013</td>\n      <td>0.118800</td>\n      <td>0.021939</td>\n      <td>0.151189</td>\n      <td>-0.022029</td>\n      <td>-0.037546</td>\n      <td>-0.008493</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.216502</td>\n      <td>-0.121272</td>\n      <td>0.161257</td>\n      <td>0.232544</td>\n      <td>0.127295</td>\n      <td>0.175694</td>\n      <td>0.226345</td>\n      <td>0.108203</td>\n      <td>0.236148</td>\n      <td>0.025751</td>\n      <td>...</td>\n      <td>0.086943</td>\n      <td>0.101603</td>\n      <td>0.111665</td>\n      <td>0.155544</td>\n      <td>0.178150</td>\n      <td>0.099039</td>\n      <td>0.336376</td>\n      <td>-0.038776</td>\n      <td>-0.137940</td>\n      <td>0.026508</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.195436</td>\n      <td>0.017321</td>\n      <td>0.140609</td>\n      <td>0.140817</td>\n      <td>0.089230</td>\n      <td>0.131331</td>\n      <td>0.123202</td>\n      <td>0.117552</td>\n      <td>0.170568</td>\n      <td>0.045935</td>\n      <td>...</td>\n      <td>0.097071</td>\n      <td>0.059153</td>\n      <td>0.055884</td>\n      <td>0.137045</td>\n      <td>0.161261</td>\n      <td>0.034578</td>\n      <td>0.172673</td>\n      <td>-0.048490</td>\n      <td>-0.083490</td>\n      <td>-0.000259</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.100086</td>\n      <td>-0.014135</td>\n      <td>0.028946</td>\n      <td>0.095056</td>\n      <td>0.155228</td>\n      <td>0.156778</td>\n      <td>0.196671</td>\n      <td>0.051351</td>\n      <td>0.150046</td>\n      <td>0.034927</td>\n      <td>...</td>\n      <td>0.031062</td>\n      <td>0.019676</td>\n      <td>0.009355</td>\n      <td>0.045576</td>\n      <td>0.077652</td>\n      <td>0.094742</td>\n      <td>0.169457</td>\n      <td>-0.031543</td>\n      <td>-0.040632</td>\n      <td>0.038561</td>\n    </tr>\n  </tbody>\n</table>\n<p>6 rows  21 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "annpreddf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "KNN = KNeighborsRegressor(n_neighbors=6,weights='distance',algorithm='brute')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "KNeighborsRegressor(algorithm='brute', n_neighbors=6, weights='distance')"
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "KNN.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "0.6220507667284976"
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "KNN.score(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "knny_pred = KNN.predict(X_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "knnpreddf = pd.DataFrame(data=knny_pred, columns =y.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "   wireless  noise_cancelling  mic_presence  frequency_response_consistency  \\\n0       1.0               0.0           1.0                        0.465352   \n1       1.0               0.0           1.0                        0.463151   \n2       1.0               0.0           1.0                        0.466598   \n3       1.0               0.0           1.0                        0.498736   \n4       1.0               0.0           1.0                        0.466173   \n5       1.0               0.0           1.0                        0.561034   \n\n   bass_accuracy  mid_accuracy  treble_accuracy  peaks_dips   imaging  \\\n0       0.190333      0.510046         0.573788    0.308005  0.600485   \n1       0.188978      0.509254         0.573782    0.306461  0.599129   \n2       0.190623      0.511477         0.574029    0.309598  0.603079   \n3       0.112388      0.490760         0.661125    0.336564  0.651810   \n4       0.190547      0.511115         0.574057    0.309238  0.602625   \n5       0.203641      0.590669         0.596079    0.413195  0.701208   \n\n   passive_soundstage  ...  noise_isolation  microphone_rating  \\\n0            0.250630  ...         0.291832           0.647728   \n1            0.251072  ...         0.289138           0.646990   \n2            0.249646  ...         0.294154           0.647016   \n3            0.252360  ...         0.289653           0.650652   \n4            0.250005  ...         0.293727           0.647146   \n5            0.202169  ...         0.305966           0.650786   \n\n   mic_recording_quality  bluetooth  closed_back  open_back    in_ear  on_ear  \\\n0               0.670773   0.825069     0.838319   0.161681  0.662120     0.0   \n1               0.670435   0.825486     0.839446   0.160554  0.660978     0.0   \n2               0.669802   0.824355     0.839424   0.160576  0.665335     0.0   \n3               0.679069   0.824936     0.839090   0.160910  0.663091     0.0   \n4               0.669917   0.824524     0.838662   0.161338  0.664514     0.0   \n5               0.677410   0.793316     1.000000   0.000000  0.826285     0.0   \n\n   over_ear  head_set  \n0       0.0  0.176199  \n1       0.0  0.178467  \n2       0.0  0.174089  \n3       0.0  0.175999  \n4       0.0  0.174148  \n5       0.0  0.173715  \n\n[6 rows x 21 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>wireless</th>\n      <th>noise_cancelling</th>\n      <th>mic_presence</th>\n      <th>frequency_response_consistency</th>\n      <th>bass_accuracy</th>\n      <th>mid_accuracy</th>\n      <th>treble_accuracy</th>\n      <th>peaks_dips</th>\n      <th>imaging</th>\n      <th>passive_soundstage</th>\n      <th>...</th>\n      <th>noise_isolation</th>\n      <th>microphone_rating</th>\n      <th>mic_recording_quality</th>\n      <th>bluetooth</th>\n      <th>closed_back</th>\n      <th>open_back</th>\n      <th>in_ear</th>\n      <th>on_ear</th>\n      <th>over_ear</th>\n      <th>head_set</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.465352</td>\n      <td>0.190333</td>\n      <td>0.510046</td>\n      <td>0.573788</td>\n      <td>0.308005</td>\n      <td>0.600485</td>\n      <td>0.250630</td>\n      <td>...</td>\n      <td>0.291832</td>\n      <td>0.647728</td>\n      <td>0.670773</td>\n      <td>0.825069</td>\n      <td>0.838319</td>\n      <td>0.161681</td>\n      <td>0.662120</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.176199</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.463151</td>\n      <td>0.188978</td>\n      <td>0.509254</td>\n      <td>0.573782</td>\n      <td>0.306461</td>\n      <td>0.599129</td>\n      <td>0.251072</td>\n      <td>...</td>\n      <td>0.289138</td>\n      <td>0.646990</td>\n      <td>0.670435</td>\n      <td>0.825486</td>\n      <td>0.839446</td>\n      <td>0.160554</td>\n      <td>0.660978</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.178467</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.466598</td>\n      <td>0.190623</td>\n      <td>0.511477</td>\n      <td>0.574029</td>\n      <td>0.309598</td>\n      <td>0.603079</td>\n      <td>0.249646</td>\n      <td>...</td>\n      <td>0.294154</td>\n      <td>0.647016</td>\n      <td>0.669802</td>\n      <td>0.824355</td>\n      <td>0.839424</td>\n      <td>0.160576</td>\n      <td>0.665335</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.174089</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.498736</td>\n      <td>0.112388</td>\n      <td>0.490760</td>\n      <td>0.661125</td>\n      <td>0.336564</td>\n      <td>0.651810</td>\n      <td>0.252360</td>\n      <td>...</td>\n      <td>0.289653</td>\n      <td>0.650652</td>\n      <td>0.679069</td>\n      <td>0.824936</td>\n      <td>0.839090</td>\n      <td>0.160910</td>\n      <td>0.663091</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.175999</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.466173</td>\n      <td>0.190547</td>\n      <td>0.511115</td>\n      <td>0.574057</td>\n      <td>0.309238</td>\n      <td>0.602625</td>\n      <td>0.250005</td>\n      <td>...</td>\n      <td>0.293727</td>\n      <td>0.647146</td>\n      <td>0.669917</td>\n      <td>0.824524</td>\n      <td>0.838662</td>\n      <td>0.161338</td>\n      <td>0.664514</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.174148</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.561034</td>\n      <td>0.203641</td>\n      <td>0.590669</td>\n      <td>0.596079</td>\n      <td>0.413195</td>\n      <td>0.701208</td>\n      <td>0.202169</td>\n      <td>...</td>\n      <td>0.305966</td>\n      <td>0.650786</td>\n      <td>0.677410</td>\n      <td>0.793316</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.826285</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.173715</td>\n    </tr>\n  </tbody>\n</table>\n<p>6 rows  21 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "knnpreddf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "RF = RandomForestRegressor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "RandomForestRegressor()"
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "RF.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "0.6293297200585716"
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "RF.score(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "rf_pred = RF.predict(X_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "rfpreddf = pd.DataFrame(data=rf_pred, columns =y.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "   wireless  noise_cancelling  mic_presence  frequency_response_consistency  \\\n0      0.09              0.00          0.93                        0.168085   \n1      0.03              0.00          0.03                        0.487872   \n2      0.06              0.03          0.06                        0.471915   \n3      0.80              0.00          0.81                        0.499574   \n4      0.03              0.02          0.03                        0.456596   \n5      0.03              0.00          0.03                        0.488298   \n\n   bass_accuracy  mid_accuracy  treble_accuracy  peaks_dips   imaging  \\\n0       0.589770      0.660612         0.526420    0.357778  0.791368   \n1       0.667701      0.845918         0.711852    0.638444  0.892211   \n2       0.699540      0.793061         0.685802    0.601556  0.893053   \n3       0.177011      0.617347         0.593580    0.278000  0.344842   \n4       0.704253      0.824694         0.702963    0.635111  0.901684   \n5       0.703218      0.902449         0.747901    0.679333  0.902842   \n\n   passive_soundstage  ...  noise_isolation  microphone_rating  \\\n0            0.565333  ...         0.405213           0.862584   \n1            0.695444  ...         0.220851           0.022360   \n2            0.567000  ...         0.366170           0.041124   \n3            0.348444  ...         0.077872           0.518989   \n4            0.592444  ...         0.345638           0.018090   \n5            0.755111  ...         0.195745           0.020899   \n\n   mic_recording_quality  bluetooth  closed_back  open_back  in_ear  on_ear  \\\n0               0.880444   0.086136         0.86       0.14    0.05    0.01   \n1               0.023222   0.029091         0.17       0.31    0.12    0.00   \n2               0.039667   0.050909         0.46       0.12    0.28    0.02   \n3               0.523111   0.718636         0.84       0.08    0.25    0.00   \n4               0.015667   0.023636         0.42       0.13    0.25    0.02   \n5               0.021444   0.024659         0.09       0.40    0.05    0.01   \n\n   over_ear  head_set  \n0      0.86      0.03  \n1      0.85      0.02  \n2      0.68      0.01  \n3      0.14      0.59  \n4      0.73      0.00  \n5      0.93      0.00  \n\n[6 rows x 21 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>wireless</th>\n      <th>noise_cancelling</th>\n      <th>mic_presence</th>\n      <th>frequency_response_consistency</th>\n      <th>bass_accuracy</th>\n      <th>mid_accuracy</th>\n      <th>treble_accuracy</th>\n      <th>peaks_dips</th>\n      <th>imaging</th>\n      <th>passive_soundstage</th>\n      <th>...</th>\n      <th>noise_isolation</th>\n      <th>microphone_rating</th>\n      <th>mic_recording_quality</th>\n      <th>bluetooth</th>\n      <th>closed_back</th>\n      <th>open_back</th>\n      <th>in_ear</th>\n      <th>on_ear</th>\n      <th>over_ear</th>\n      <th>head_set</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.09</td>\n      <td>0.00</td>\n      <td>0.93</td>\n      <td>0.168085</td>\n      <td>0.589770</td>\n      <td>0.660612</td>\n      <td>0.526420</td>\n      <td>0.357778</td>\n      <td>0.791368</td>\n      <td>0.565333</td>\n      <td>...</td>\n      <td>0.405213</td>\n      <td>0.862584</td>\n      <td>0.880444</td>\n      <td>0.086136</td>\n      <td>0.86</td>\n      <td>0.14</td>\n      <td>0.05</td>\n      <td>0.01</td>\n      <td>0.86</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.03</td>\n      <td>0.00</td>\n      <td>0.03</td>\n      <td>0.487872</td>\n      <td>0.667701</td>\n      <td>0.845918</td>\n      <td>0.711852</td>\n      <td>0.638444</td>\n      <td>0.892211</td>\n      <td>0.695444</td>\n      <td>...</td>\n      <td>0.220851</td>\n      <td>0.022360</td>\n      <td>0.023222</td>\n      <td>0.029091</td>\n      <td>0.17</td>\n      <td>0.31</td>\n      <td>0.12</td>\n      <td>0.00</td>\n      <td>0.85</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.06</td>\n      <td>0.03</td>\n      <td>0.06</td>\n      <td>0.471915</td>\n      <td>0.699540</td>\n      <td>0.793061</td>\n      <td>0.685802</td>\n      <td>0.601556</td>\n      <td>0.893053</td>\n      <td>0.567000</td>\n      <td>...</td>\n      <td>0.366170</td>\n      <td>0.041124</td>\n      <td>0.039667</td>\n      <td>0.050909</td>\n      <td>0.46</td>\n      <td>0.12</td>\n      <td>0.28</td>\n      <td>0.02</td>\n      <td>0.68</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.80</td>\n      <td>0.00</td>\n      <td>0.81</td>\n      <td>0.499574</td>\n      <td>0.177011</td>\n      <td>0.617347</td>\n      <td>0.593580</td>\n      <td>0.278000</td>\n      <td>0.344842</td>\n      <td>0.348444</td>\n      <td>...</td>\n      <td>0.077872</td>\n      <td>0.518989</td>\n      <td>0.523111</td>\n      <td>0.718636</td>\n      <td>0.84</td>\n      <td>0.08</td>\n      <td>0.25</td>\n      <td>0.00</td>\n      <td>0.14</td>\n      <td>0.59</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.03</td>\n      <td>0.02</td>\n      <td>0.03</td>\n      <td>0.456596</td>\n      <td>0.704253</td>\n      <td>0.824694</td>\n      <td>0.702963</td>\n      <td>0.635111</td>\n      <td>0.901684</td>\n      <td>0.592444</td>\n      <td>...</td>\n      <td>0.345638</td>\n      <td>0.018090</td>\n      <td>0.015667</td>\n      <td>0.023636</td>\n      <td>0.42</td>\n      <td>0.13</td>\n      <td>0.25</td>\n      <td>0.02</td>\n      <td>0.73</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.03</td>\n      <td>0.00</td>\n      <td>0.03</td>\n      <td>0.488298</td>\n      <td>0.703218</td>\n      <td>0.902449</td>\n      <td>0.747901</td>\n      <td>0.679333</td>\n      <td>0.902842</td>\n      <td>0.755111</td>\n      <td>...</td>\n      <td>0.195745</td>\n      <td>0.020899</td>\n      <td>0.021444</td>\n      <td>0.024659</td>\n      <td>0.09</td>\n      <td>0.40</td>\n      <td>0.05</td>\n      <td>0.01</td>\n      <td>0.93</td>\n      <td>0.00</td>\n    </tr>\n  </tbody>\n</table>\n<p>6 rows  21 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "rfpreddf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "rfdf = pd.DataFrame(columns = ['game_use', 'travel_use', 'exercise_use',\n",
        "       'office_use', 'phone_call_use', 'studio_use', 'wireless',\n",
        "       'noise_cancelling', 'mic_presence', 'frequency_response_consistency',\n",
        "       'bass_accuracy', 'mid_accuracy', 'treble_accuracy', 'peaks_dips',\n",
        "       'imaging', 'passive_soundstage', 'weighted_harmonic_distortion',\n",
        "       'noise_isolation', 'microphone_rating', 'mic_recording_quality',\n",
        "       'bluetooth', 'closed_back', 'open_back', 'in_ear', 'on_ear', 'over_ear',\n",
        "       'head_set'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "rfdf[['game_use', 'travel_use', 'exercise_use',\n",
        "       'office_use', 'phone_call_use', 'studio_use']] = X_pred[['game_use', 'travel_use', 'exercise_use',\n",
        "       'office_use', 'phone_call_use', 'studio_use']]\n",
        "rfdf[['wireless',\n",
        "       'noise_cancelling', 'mic_presence', 'frequency_response_consistency',\n",
        "       'bass_accuracy', 'mid_accuracy', 'treble_accuracy', 'peaks_dips',\n",
        "       'imaging', 'passive_soundstage', 'weighted_harmonic_distortion',\n",
        "       'noise_isolation', 'microphone_rating', 'mic_recording_quality',\n",
        "       'bluetooth', 'closed_back', 'open_back', 'in_ear', 'on_ear', 'over_ear',\n",
        "       'head_set']] = rfpreddf[['wireless',\n",
        "       'noise_cancelling', 'mic_presence', 'frequency_response_consistency',\n",
        "       'bass_accuracy', 'mid_accuracy', 'treble_accuracy', 'peaks_dips',\n",
        "       'imaging', 'passive_soundstage', 'weighted_harmonic_distortion',\n",
        "       'noise_isolation', 'microphone_rating', 'mic_recording_quality',\n",
        "       'bluetooth', 'closed_back', 'open_back', 'in_ear', 'on_ear', 'over_ear',\n",
        "       'head_set']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "   game_use  travel_use  exercise_use  office_use  phone_call_use  studio_use  \\\n0         0           0             0           0               1           0   \n1         1           0             0           0               0           0   \n2         0           1             0           0               0           0   \n3         0           0             1           0               0           0   \n4         0           0             0           1               0           0   \n5         0           0             0           0               0           1   \n\n   wireless  noise_cancelling  mic_presence  frequency_response_consistency  \\\n0      0.09              0.00          0.93                        0.168085   \n1      0.03              0.00          0.03                        0.487872   \n2      0.06              0.03          0.06                        0.471915   \n3      0.80              0.00          0.81                        0.499574   \n4      0.03              0.02          0.03                        0.456596   \n5      0.03              0.00          0.03                        0.488298   \n\n   ...  noise_isolation  microphone_rating  mic_recording_quality  bluetooth  \\\n0  ...         0.405213           0.862584               0.880444   0.086136   \n1  ...         0.220851           0.022360               0.023222   0.029091   \n2  ...         0.366170           0.041124               0.039667   0.050909   \n3  ...         0.077872           0.518989               0.523111   0.718636   \n4  ...         0.345638           0.018090               0.015667   0.023636   \n5  ...         0.195745           0.020899               0.021444   0.024659   \n\n   closed_back  open_back  in_ear  on_ear  over_ear  head_set  \n0         0.86       0.14    0.05    0.01      0.86      0.03  \n1         0.17       0.31    0.12    0.00      0.85      0.02  \n2         0.46       0.12    0.28    0.02      0.68      0.01  \n3         0.84       0.08    0.25    0.00      0.14      0.59  \n4         0.42       0.13    0.25    0.02      0.73      0.00  \n5         0.09       0.40    0.05    0.01      0.93      0.00  \n\n[6 rows x 27 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>game_use</th>\n      <th>travel_use</th>\n      <th>exercise_use</th>\n      <th>office_use</th>\n      <th>phone_call_use</th>\n      <th>studio_use</th>\n      <th>wireless</th>\n      <th>noise_cancelling</th>\n      <th>mic_presence</th>\n      <th>frequency_response_consistency</th>\n      <th>...</th>\n      <th>noise_isolation</th>\n      <th>microphone_rating</th>\n      <th>mic_recording_quality</th>\n      <th>bluetooth</th>\n      <th>closed_back</th>\n      <th>open_back</th>\n      <th>in_ear</th>\n      <th>on_ear</th>\n      <th>over_ear</th>\n      <th>head_set</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.09</td>\n      <td>0.00</td>\n      <td>0.93</td>\n      <td>0.168085</td>\n      <td>...</td>\n      <td>0.405213</td>\n      <td>0.862584</td>\n      <td>0.880444</td>\n      <td>0.086136</td>\n      <td>0.86</td>\n      <td>0.14</td>\n      <td>0.05</td>\n      <td>0.01</td>\n      <td>0.86</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.03</td>\n      <td>0.00</td>\n      <td>0.03</td>\n      <td>0.487872</td>\n      <td>...</td>\n      <td>0.220851</td>\n      <td>0.022360</td>\n      <td>0.023222</td>\n      <td>0.029091</td>\n      <td>0.17</td>\n      <td>0.31</td>\n      <td>0.12</td>\n      <td>0.00</td>\n      <td>0.85</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.06</td>\n      <td>0.03</td>\n      <td>0.06</td>\n      <td>0.471915</td>\n      <td>...</td>\n      <td>0.366170</td>\n      <td>0.041124</td>\n      <td>0.039667</td>\n      <td>0.050909</td>\n      <td>0.46</td>\n      <td>0.12</td>\n      <td>0.28</td>\n      <td>0.02</td>\n      <td>0.68</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.80</td>\n      <td>0.00</td>\n      <td>0.81</td>\n      <td>0.499574</td>\n      <td>...</td>\n      <td>0.077872</td>\n      <td>0.518989</td>\n      <td>0.523111</td>\n      <td>0.718636</td>\n      <td>0.84</td>\n      <td>0.08</td>\n      <td>0.25</td>\n      <td>0.00</td>\n      <td>0.14</td>\n      <td>0.59</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.03</td>\n      <td>0.02</td>\n      <td>0.03</td>\n      <td>0.456596</td>\n      <td>...</td>\n      <td>0.345638</td>\n      <td>0.018090</td>\n      <td>0.015667</td>\n      <td>0.023636</td>\n      <td>0.42</td>\n      <td>0.13</td>\n      <td>0.25</td>\n      <td>0.02</td>\n      <td>0.73</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.03</td>\n      <td>0.00</td>\n      <td>0.03</td>\n      <td>0.488298</td>\n      <td>...</td>\n      <td>0.195745</td>\n      <td>0.020899</td>\n      <td>0.021444</td>\n      <td>0.024659</td>\n      <td>0.09</td>\n      <td>0.40</td>\n      <td>0.05</td>\n      <td>0.01</td>\n      <td>0.93</td>\n      <td>0.00</td>\n    </tr>\n  </tbody>\n</table>\n<p>6 rows  27 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "rfdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "randomdf = rfdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "LR = LinearRegression()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "LinearRegression()"
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "LR.fit(x1_train,y1_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "0.9273341333653701"
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "LR.score(x1_test,y1_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "randomdf[['game_use', 'travel_use', 'exercise_use',\n",
        "       'office_use', 'phone_call_use', 'studio_use']]=LR.predict(rfpreddf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "knnhpx=df[['travel_use', 'exercise_use', 'office_use',\n",
        "       'phone_call_use', 'studio_use', 'game_use', 'wireless', 'noise_cancelling',\n",
        "       'mic_presence', 'frequency_response_consistency', 'bass_accuracy',\n",
        "       'mid_accuracy', 'treble_accuracy', 'peaks_dips', 'imaging',\n",
        "       'passive_soundstage', 'weighted_harmonic_distortion', 'noise_isolation',\n",
        "       'microphone_rating', 'mic_recording_quality', 'bluetooth',\n",
        "       'closed_back', 'open_back', 'in_ear', 'on_ear', 'over_ear', 'head_set']]\n",
        "knnhpy=df['headphone_name']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "288"
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "len(knnhpy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "knnhp = KNeighborsRegressor(n_neighbors=288,weights='distance')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "KNeighborsRegressor(n_neighbors=288, weights='distance')"
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "knnhp.fit(knnhpx,knnhpy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "targets = knnhp.predict(randomdf).round()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([144., 139., 140., 146., 139., 138.])"
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "     headphone_name  game_use  travel_use  exercise_use  office_use  \\\n115             144       5.6    0.911111      0.918919    0.771429   \n\n     phone_call_use  studio_use  wireless  noise_cancelling  mic_presence  \\\n115        0.830769       0.575         1                 0             1   \n\n     ...  noise_isolation  microphone_rating  mic_recording_quality  \\\n115  ...         0.829787           0.730337               0.766667   \n\n     bluetooth  closed_back  open_back  in_ear  on_ear  over_ear  head_set  \n115   0.920455            1          0       1       0         0         0  \n\n[1 rows x 28 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>headphone_name</th>\n      <th>game_use</th>\n      <th>travel_use</th>\n      <th>exercise_use</th>\n      <th>office_use</th>\n      <th>phone_call_use</th>\n      <th>studio_use</th>\n      <th>wireless</th>\n      <th>noise_cancelling</th>\n      <th>mic_presence</th>\n      <th>...</th>\n      <th>noise_isolation</th>\n      <th>microphone_rating</th>\n      <th>mic_recording_quality</th>\n      <th>bluetooth</th>\n      <th>closed_back</th>\n      <th>open_back</th>\n      <th>in_ear</th>\n      <th>on_ear</th>\n      <th>over_ear</th>\n      <th>head_set</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>115</th>\n      <td>144</td>\n      <td>5.6</td>\n      <td>0.911111</td>\n      <td>0.918919</td>\n      <td>0.771429</td>\n      <td>0.830769</td>\n      <td>0.575</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.829787</td>\n      <td>0.730337</td>\n      <td>0.766667</td>\n      <td>0.920455</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows  28 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "df.loc[df['headphone_name'] == targets[0]]"
      ]
    }
  ]
}